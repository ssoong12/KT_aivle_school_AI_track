{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"0_2_Attention_Basics.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMxC2ARjikWiYrH5HZtWYiy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"IGlWW9jN5e9a"},"source":["# Sequence to Sequence (a.k.a. seq2seq)\r\n","\r\n","**학습목표**\r\n","* Encoder Decoder 구조를 이해하고 구현할 줄 안다.\r\n","* Seq2Seq에 필요한 전처리를 이해한다.\r\n","* **데이터 부족**과, **긴 문장**을 겪어본다.\r\n","\r\n","![이런거](https://raw.githubusercontent.com/KerasKorea/KEKOxTutorial/master/media/28_1.png)\r\n","---------------------------------\r\n","edu.rayleigh@gmail.com\r\n","Special Thanks to : 숙번님 ( [봉수골 개발자 이선비](https://www.youtube.com/channel/UCOAyyrvi7tnCAz7RhH98QCQ) )"]},{"cell_type":"code","metadata":{"id":"ObiFUtaC8pHk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612637131617,"user_tz":-540,"elapsed":993,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}},"outputId":"0acbf3c0-ad92-4a45-d4d1-adb0d74b3e02"},"source":["!wget http://www.manythings.org/anki/kor-eng.zip"],"execution_count":58,"outputs":[{"output_type":"stream","text":["--2021-02-06 18:45:29--  http://www.manythings.org/anki/kor-eng.zip\n","Resolving www.manythings.org (www.manythings.org)... 172.67.173.198, 104.21.55.222, 2606:4700:3036::ac43:adc6, ...\n","Connecting to www.manythings.org (www.manythings.org)|172.67.173.198|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 143703 (140K) [application/zip]\n","Saving to: ‘kor-eng.zip.2’\n","\n","kor-eng.zip.2       100%[===================>] 140.33K  --.-KB/s    in 0.1s    \n","\n","2021-02-06 18:45:29 (1.26 MB/s) - ‘kor-eng.zip.2’ saved [143703/143703]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VeblRhOP9CxX","executionInfo":{"status":"ok","timestamp":1612637131618,"user_tz":-540,"elapsed":986,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}}},"source":["import zipfile\r\n","kor_eng = zipfile.ZipFile('kor-eng.zip')\r\n","kor_eng.extractall()\r\n","kor_eng.close()"],"execution_count":59,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z-A2Uf0V-y-W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612637131619,"user_tz":-540,"elapsed":980,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}},"outputId":"7fa5ff64-9545-4db8-b2ca-8069ff8c2e5c"},"source":["import pandas as pd\r\n","temp = pd.read_table('kor.txt', names=['Eng', 'Kor', 'license'])\r\n","temp.shape"],"execution_count":60,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3648, 3)"]},"metadata":{"tags":[]},"execution_count":60}]},{"cell_type":"code","metadata":{"id":"0n8j-x_j8rTj","colab":{"base_uri":"https://localhost:8080/","height":198},"executionInfo":{"status":"ok","timestamp":1612637131619,"user_tz":-540,"elapsed":972,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}},"outputId":"a0f97a71-d48b-4e65-8a0a-8cab3ea5f3bc"},"source":["temp.head()"],"execution_count":61,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Eng</th>\n","      <th>Kor</th>\n","      <th>license</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Go.</td>\n","      <td>가.</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Hi.</td>\n","      <td>안녕.</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Run!</td>\n","      <td>뛰어!</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Run.</td>\n","      <td>뛰어.</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Who?</td>\n","      <td>누구?</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    Eng  Kor                                            license\n","0   Go.   가.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n","1   Hi.  안녕.  CC-BY 2.0 (France) Attribution: tatoeba.org #5...\n","2  Run!  뛰어!  CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n","3  Run.  뛰어.  CC-BY 2.0 (France) Attribution: tatoeba.org #4...\n","4  Who?  누구?  CC-BY 2.0 (France) Attribution: tatoeba.org #2..."]},"metadata":{"tags":[]},"execution_count":61}]},{"cell_type":"code","metadata":{"id":"VHEF-9_1AHF2","executionInfo":{"status":"ok","timestamp":1612637131620,"user_tz":-540,"elapsed":965,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}}},"source":["eng_sent = temp['Eng'].tolist()\r\n","kor_sent = temp['Kor'].tolist()"],"execution_count":62,"outputs":[]},{"cell_type":"code","metadata":{"id":"qntWaQtjSo0U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612637131620,"user_tz":-540,"elapsed":959,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}},"outputId":"66c9a43d-2411-4390-f83e-f2734a585bd5"},"source":["print(eng_sent[1000])\r\n","print(kor_sent[1000])"],"execution_count":63,"outputs":[{"output_type":"stream","text":["I don't sleep a lot.\n","나는 잠이 별로 없어.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aPU1CYykAdXU"},"source":["# 데이터 준비\r\n","0. 단어와 구두점 사이 공백 만들기\r\n","1. sos 와 eos\r\n","1. tokenizing, idx_seq, padding"]},{"cell_type":"markdown","metadata":{"id":"Fj9FhCC9IgaO"},"source":["## 0. 단어와 구두점 사이 공백 만들기\r\n"]},{"cell_type":"code","metadata":{"id":"Wi0kBaQRIjwB","executionInfo":{"status":"ok","timestamp":1612637131621,"user_tz":-540,"elapsed":953,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}}},"source":["import unicodedata\r\n","import re\r\n","def unicode_to_ascii(s):\r\n","  return ''.join(c for c in unicodedata.normalize('NFD', s)\r\n","      if unicodedata.category(c) != 'Mn')\r\n","def eng_preprocessor(sent):\r\n","    # 위에서 구현한 함수를 내부적으로 호출\r\n","    sent = unicode_to_ascii(sent.lower())\r\n","\r\n","    # 단어와 구두점 사이에 공백을 만듭니다.\r\n","    # Ex) \"he is a boy.\" => \"he is a boy .\"\r\n","    sent = re.sub(r\"([?.!,'¿])\", r\" \\1 \", sent)\r\n","\r\n","    # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 이들을 제외하고는 전부 공백으로 변환합니다.\r\n","    sent = re.sub(r\"[^a-zA-Z!.?']+\", r\" \", sent)\r\n","\r\n","    sent = re.sub(r\"\\s+\", \" \", sent)\r\n","    return sent\r\n","\r\n","def kor_preprocessor(sent):\r\n","    # 위에서 구현한 함수를 내부적으로 호출\r\n","    sent = unicode_to_ascii(sent.lower())\r\n","\r\n","    # 단어와 구두점 사이에 공백을 만듭니다.\r\n","    # Ex) \"he is a boy.\" => \"he is a boy .\"\r\n","    sent = re.sub(r\"([?.!,'¿])\", r\" \\1 \", sent)\r\n","\r\n","    sent = re.sub(r\"\\s+\", \" \", sent)\r\n","    return sent"],"execution_count":64,"outputs":[]},{"cell_type":"code","metadata":{"id":"PjAoavx2IsTj","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1612637131621,"user_tz":-540,"elapsed":946,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}},"outputId":"cb1203b2-f427-4a3b-988e-1c6b34061369"},"source":["eng_preprocessor(\"I'm just a poor boy.\")"],"execution_count":65,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"i ' m just a poor boy . \""]},"metadata":{"tags":[]},"execution_count":65}]},{"cell_type":"code","metadata":{"id":"yjr_CjB6JFlj","executionInfo":{"status":"ok","timestamp":1612637131866,"user_tz":-540,"elapsed":1184,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}}},"source":["eng_sent = [ eng_preprocessor(sent) for sent in eng_sent ]\r\n","kor_sent = [ kor_preprocessor(sent) for sent in kor_sent ]"],"execution_count":66,"outputs":[]},{"cell_type":"code","metadata":{"id":"2MIrvRfKJOB3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612637131870,"user_tz":-540,"elapsed":1181,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}},"outputId":"4d2a5d8f-b002-43a0-aa54-5b1fcb4a3dc7"},"source":["print(eng_sent[1000])\r\n","print(kor_sent[1000])"],"execution_count":67,"outputs":[{"output_type":"stream","text":["i don ' t sleep a lot . \n","나는 잠이 별로 없어 . \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3LR2w3i3EJ6c"},"source":["## 1. sos 와 eos\r\n","1. sos : start of speech\r\n","2. eos : end of speech"]},{"cell_type":"code","metadata":{"id":"RFkzszhyDq6E","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1612637131871,"user_tz":-540,"elapsed":1174,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}},"outputId":"23f2613c-77f0-4b31-9c22-8acfe193802d"},"source":["######################\r\n","### Your Code here ###\r\n","######################\r\n","\r\n","## 영어 문장 전 후에 <sos>와 <eos>를 추가할 것\r\n","## 띄어쓰기 주의!\r\n","\r\n","eng_sent = [f\"<sos> {eng} <eos>\" for eng in eng_sent]\r\n","eng_sent[1000]"],"execution_count":68,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"<sos> i don ' t sleep a lot .  <eos>\""]},"metadata":{"tags":[]},"execution_count":68}]},{"cell_type":"markdown","metadata":{"id":"zrEhHIQlEU8F"},"source":["## 2. Tokenizing, idx_seq, padding"]},{"cell_type":"code","metadata":{"id":"4-C-zqpSEewe","executionInfo":{"status":"ok","timestamp":1612637131872,"user_tz":-540,"elapsed":1167,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}}},"source":["from tensorflow.keras.preprocessing.text import Tokenizer\r\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"],"execution_count":69,"outputs":[]},{"cell_type":"code","metadata":{"id":"bbf-Y--TEj7Y","executionInfo":{"status":"ok","timestamp":1612637131873,"user_tz":-540,"elapsed":1163,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}}},"source":["######################\r\n","### Your Code here ###\r\n","######################\r\n","\r\n","# Tokenizing    # 한국어는 lower = False\r\n","tokenizer_en = Tokenizer(filters=\"\", lower=True)\r\n","tokenizer_en.fit_on_texts(eng_sent)\r\n","tokenizer_kr = Tokenizer(filters=\"\", lower=False)\r\n","tokenizer_kr.fit_on_texts(kor_sent)"],"execution_count":70,"outputs":[]},{"cell_type":"code","metadata":{"id":"OvDe7BY-F3jB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612637131874,"user_tz":-540,"elapsed":1158,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}},"outputId":"f53abc46-bdf3-4066-8f47-96d851c14673"},"source":["######################\r\n","### Your Code here ###\r\n","######################\r\n","\r\n","# Index Sequence\r\n","eng_seq = tokenizer_en.texts_to_sequences(eng_sent)\r\n","kor_seq = tokenizer_kr.texts_to_sequences(kor_sent)\r\n","\r\n","print(eng_seq[1000])\r\n","print(kor_seq[1000])"],"execution_count":71,"outputs":[{"output_type":"stream","text":["[1, 4, 22, 5, 13, 252, 11, 148, 3, 2]\n","[7, 714, 445, 19, 1]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sadRsDiaJ7p5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612637131874,"user_tz":-540,"elapsed":1151,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}},"outputId":"1a280680-9ce6-43a0-81a4-4e6ca74db35e"},"source":["######################\r\n","### Your Code here ###\r\n","######################\r\n","## 최대 문장 길이에 맞춰지도록 할 것.\r\n","# padding\r\n","eng_pad = pad_sequences(eng_seq) # 최대 문장 길이에 패딩에 맞춰지게 됨.\r\n","kor_pad = pad_sequences(kor_seq)\r\n","\r\n","print(eng_pad.shape)\r\n","print(kor_pad.shape)"],"execution_count":72,"outputs":[{"output_type":"stream","text":["(3648, 104)\n","(3648, 95)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kW-52MAiKjLW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612637131875,"user_tz":-540,"elapsed":1145,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}},"outputId":"054f65ff-4ea8-41c8-ef1e-d2991c8da3ff"},"source":["# tokenizer에서 0 index가 구성되어있지 않지만, \r\n","# pad_sequence에서 pad의 의미로 0을 사용하고 있어서, 전체 사이즈를 구할 때, +1을 해준다.\r\n","\r\n","eng_vocab_size = len(tokenizer_en.word_index) + 1\r\n","kor_vocab_size = len(tokenizer_kr.word_index) + 1\r\n","print(\"영어 단어 집합의 크기: {:d}\\n한국어 단어 집합의 크기: {:d}\".format(eng_vocab_size, kor_vocab_size))"],"execution_count":73,"outputs":[{"output_type":"stream","text":["영어 단어 집합의 크기: 2484\n","한국어 단어 집합의 크기: 5551\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"faI0SNWRKr7O"},"source":["# 모델링!\r\n","\r\n","1. 모든 임베딩 레이어는 128개 차원으로 구성.\r\n","2. 인코더도 디코더도 GRU, 히든스테이트 512로 구성.\r\n","3. 디코더의 GRU 뒤에는 Fully Conneceted layer 사용. 노드 512개\r\n","4. 적절한 아웃풋레이어\r\n","    * 매 시점, 가장 적절한 단어가 무엇일지 분류 한다고 생각하면 됨!"]},{"cell_type":"code","metadata":{"id":"daSlqB5TK-ua","executionInfo":{"status":"ok","timestamp":1612637131875,"user_tz":-540,"elapsed":1139,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}}},"source":["import tensorflow as tf\r\n","from tensorflow.keras.layers import Input, Embedding, GRU"],"execution_count":74,"outputs":[]},{"cell_type":"code","metadata":{"id":"qHPZhTlXK8Gy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612637132615,"user_tz":-540,"elapsed":1872,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}},"outputId":"59793924-797b-4846-8eac-55e2907bae0b"},"source":["######################\r\n","### Your Code here ###\r\n","######################\r\n","\r\n","# 혹시 이미 그려둔 그래프가 있다면 날려줘!\r\n","tf.keras.backend.clear_session()\r\n","\r\n","# 한국어 단어 집합의 크기 : 5551, (50000, 95)\r\n","# 영어 단어 집합의 크기 : 2484, (50000, 104)\r\n","# 영어 문장은 길이가 104이지만,\r\n","# 디코더의 인풋으로 넣을때는 맨 뒤의 <eos>를 떼고 길이 103의 문장을\r\n","# 디코더의 아웃풋은 맨 앞의 <eos>를 떼고 길이 103의 문장으로 준비해야 함.\r\n","\r\n","# Encoder\r\n","enc_X = tf.keras.layers.Input(shape=[kor_pad.shape[1]])\r\n","enc_E = tf.keras.layers.Embedding(kor_vocab_size, 128)(enc_X) # 토큰수, 차원수\r\n","enc_S_full, enc_S = tf.keras.layers.GRU(512, return_sequences=True, return_state=True)(enc_E)\r\n","## 이제는 enc_S_full을 쓴다!\r\n","\r\n","# Decoder\r\n","dec_X = tf.keras.layers.Input(shape=[eng_pad.shape[1]-1])\r\n","dec_E = tf.keras.layers.Embedding(eng_vocab_size, 128)(dec_X) # 토큰수, 차원수\r\n","dec_H = tf.keras.layers.GRU(512, return_sequences=True)(dec_E, initial_state=enc_S)\r\n","\r\n","#####################\r\n","## Attention layer ##\r\n","#####################\r\n","key = enc_S_full  # 인코더의 히든스테이트를 key로 활용한다. (95, 512)\r\n","value = enc_S_full  # 인코더의 히든스테이트를 value로 활용한다. (95, 512)\r\n","query = dec_H  # 디코더의 히든스테이트를 query로 활용한다. (103, 256)\r\n","\r\n","# 1. 어텐션 스코어(Attention Score)를 구한다.\r\n","score = tf.matmul(query, key, transpose_b=True)\r\n","# 연산 결과: (103, 512) * (512, 95) => (103, 95)\r\n","# 영어 103개 step 각각에서  한국어 95개 step 전부의 스코어\r\n","\r\n","# 2. 소프트맥스(softmax) 함수를 통해 어텐션 분포(Attention Distribution)를 구한다.\r\n","att_dist = tf.nn.softmax(score, axis=-1)\r\n","# 연산 결과 : (103, 95) 그대로\r\n","# 위의 영어 103개 step 각각에서의 attention score들이 softmax를 통과하여 합계 1이 되었음.\r\n","\r\n","# 3. 각 인코더의 어텐션 가중치와 은닉 상태를 가중합하여 어텐션 값(Attention Value)을 구한다.\r\n","att_value = tf.matmul(att_dist, value)\r\n","# 연산 결과: (103, 95) * (95, 512) => (103,512)\r\n","# value의 row 들은  att_dist(softmax)값이 높은 것들이 더 가중되어 합산됨.\r\n","\r\n","### 사실은, 아래 한줄의 코드로도 가능.\r\n","# att_value = tf.keras.layers.Attention()([query, key])\r\n","\r\n","\r\n","# 4. 어텐션 값과 디코더의 t 시점의 은닉 상태를 연결한다.(Concatenate)\r\n","\r\n","dec_H = tf.keras.layers.Concatenate()([att_value, dec_H])\r\n","# 5. 출력층 연산의 입력이 되는 dec_H를 계산.\r\n","dec_H = tf.keras.layers.Dense(512, activation='tanh')(dec_H)\r\n","\r\n","dec_Y = tf.keras.layers.Dense(kor_vocab_size, activation=\"softmax\")(dec_H)\r\n","model = tf.keras.models.Model([enc_X, dec_X], dec_Y)\r\n","# 텍스트는 index이고(원핫인코딩을 안했고)\r\n","# 아웃풋레이어는 분류문제 처럼 노드가 준비되어 있다면\r\n","# sparse categorical crossentropy\r\n","model.compile(loss='sparse_categorical_crossentropy',\r\n","              optimizer = tf.keras.optimizers.RMSprop(),\r\n","              metrics=['accuracy'])\r\n","model.summary()"],"execution_count":75,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 95)]         0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            [(None, 103)]        0                                            \n","__________________________________________________________________________________________________\n","embedding (Embedding)           (None, 95, 128)      710528      input_1[0][0]                    \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, 103, 128)     317952      input_2[0][0]                    \n","__________________________________________________________________________________________________\n","gru (GRU)                       [(None, 95, 512), (N 986112      embedding[0][0]                  \n","__________________________________________________________________________________________________\n","gru_1 (GRU)                     (None, 103, 512)     986112      embedding_1[0][0]                \n","                                                                 gru[0][1]                        \n","__________________________________________________________________________________________________\n","tf.linalg.matmul (TFOpLambda)   (None, 103, 95)      0           gru_1[0][0]                      \n","                                                                 gru[0][0]                        \n","__________________________________________________________________________________________________\n","tf.nn.softmax (TFOpLambda)      (None, 103, 95)      0           tf.linalg.matmul[0][0]           \n","__________________________________________________________________________________________________\n","tf.linalg.matmul_1 (TFOpLambda) (None, 103, 512)     0           tf.nn.softmax[0][0]              \n","                                                                 gru[0][0]                        \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 103, 1024)    0           tf.linalg.matmul_1[0][0]         \n","                                                                 gru_1[0][0]                      \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 103, 512)     524800      concatenate[0][0]                \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 103, 5551)    2847663     dense[0][0]                      \n","==================================================================================================\n","Total params: 6,373,167\n","Trainable params: 6,373,167\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ceSiL3RxNuQE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612637343535,"user_tz":-540,"elapsed":212786,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}},"outputId":"4b17f95c-6335-4743-8b42-94513a06dc60"},"source":["######################\r\n","### Your Code here ###\r\n","######################\r\n","## 학습 시킬 것!\r\n","\r\n","# decoder의 인풋은 마지막 <eos>를 뗀다.\r\n","# decoder의 아웃풋 학습시엔 처음의 <sos>를 뗀다.\r\n","model.fit([kor_pad, eng_pad[:, :-1]], eng_pad[:, 1:], shuffle=True, \r\n","          batch_size=128, epochs=40)"],"execution_count":76,"outputs":[{"output_type":"stream","text":["Epoch 1/40\n","29/29 [==============================] - 8s 171ms/step - loss: 2.5990 - accuracy: 0.7911\n","Epoch 2/40\n","29/29 [==============================] - 5s 174ms/step - loss: 0.6553 - accuracy: 0.9141\n","Epoch 3/40\n","29/29 [==============================] - 5s 177ms/step - loss: 0.4750 - accuracy: 0.9220\n","Epoch 4/40\n","29/29 [==============================] - 5s 180ms/step - loss: 0.4464 - accuracy: 0.9260\n","Epoch 5/40\n","29/29 [==============================] - 5s 180ms/step - loss: 0.4096 - accuracy: 0.9324\n","Epoch 6/40\n","29/29 [==============================] - 5s 180ms/step - loss: 0.3979 - accuracy: 0.9338\n","Epoch 7/40\n","29/29 [==============================] - 5s 183ms/step - loss: 0.3720 - accuracy: 0.9364\n","Epoch 8/40\n","29/29 [==============================] - 5s 184ms/step - loss: 0.3691 - accuracy: 0.9357\n","Epoch 9/40\n","29/29 [==============================] - 5s 181ms/step - loss: 0.3492 - accuracy: 0.9384\n","Epoch 10/40\n","29/29 [==============================] - 5s 180ms/step - loss: 0.3429 - accuracy: 0.9386\n","Epoch 11/40\n","29/29 [==============================] - 5s 180ms/step - loss: 0.3299 - accuracy: 0.9404\n","Epoch 12/40\n","29/29 [==============================] - 5s 180ms/step - loss: 0.3229 - accuracy: 0.9410\n","Epoch 13/40\n","29/29 [==============================] - 5s 180ms/step - loss: 0.3131 - accuracy: 0.9414\n","Epoch 14/40\n","29/29 [==============================] - 5s 179ms/step - loss: 0.3157 - accuracy: 0.9412\n","Epoch 15/40\n","29/29 [==============================] - 5s 179ms/step - loss: 0.2999 - accuracy: 0.9422\n","Epoch 16/40\n","29/29 [==============================] - 5s 178ms/step - loss: 0.2963 - accuracy: 0.9429\n","Epoch 17/40\n","29/29 [==============================] - 5s 180ms/step - loss: 0.2796 - accuracy: 0.9444\n","Epoch 18/40\n","29/29 [==============================] - 5s 180ms/step - loss: 0.2739 - accuracy: 0.9453\n","Epoch 19/40\n","29/29 [==============================] - 5s 180ms/step - loss: 0.2689 - accuracy: 0.9457\n","Epoch 20/40\n","29/29 [==============================] - 5s 180ms/step - loss: 0.2620 - accuracy: 0.9462\n","Epoch 21/40\n","29/29 [==============================] - 5s 180ms/step - loss: 0.2626 - accuracy: 0.9466\n","Epoch 22/40\n","29/29 [==============================] - 5s 180ms/step - loss: 0.2524 - accuracy: 0.9474\n","Epoch 23/40\n","29/29 [==============================] - 5s 179ms/step - loss: 0.2437 - accuracy: 0.9483\n","Epoch 24/40\n","29/29 [==============================] - 5s 179ms/step - loss: 0.2406 - accuracy: 0.9486\n","Epoch 25/40\n","29/29 [==============================] - 5s 179ms/step - loss: 0.2327 - accuracy: 0.9494\n","Epoch 26/40\n","29/29 [==============================] - 5s 179ms/step - loss: 0.2268 - accuracy: 0.9504\n","Epoch 27/40\n","29/29 [==============================] - 5s 180ms/step - loss: 0.2257 - accuracy: 0.9506\n","Epoch 28/40\n","29/29 [==============================] - 5s 180ms/step - loss: 0.2185 - accuracy: 0.9518\n","Epoch 29/40\n","29/29 [==============================] - 5s 180ms/step - loss: 0.2161 - accuracy: 0.9524\n","Epoch 30/40\n","29/29 [==============================] - 5s 180ms/step - loss: 0.2063 - accuracy: 0.9535\n","Epoch 31/40\n","29/29 [==============================] - 5s 180ms/step - loss: 0.2041 - accuracy: 0.9540\n","Epoch 32/40\n","29/29 [==============================] - 5s 180ms/step - loss: 0.1968 - accuracy: 0.9555\n","Epoch 33/40\n","29/29 [==============================] - 5s 180ms/step - loss: 0.1930 - accuracy: 0.9558\n","Epoch 34/40\n","29/29 [==============================] - 5s 180ms/step - loss: 0.1919 - accuracy: 0.9563\n","Epoch 35/40\n","29/29 [==============================] - 5s 180ms/step - loss: 0.1828 - accuracy: 0.9581\n","Epoch 36/40\n","29/29 [==============================] - 5s 180ms/step - loss: 0.1816 - accuracy: 0.9593\n","Epoch 37/40\n","29/29 [==============================] - 5s 180ms/step - loss: 0.1736 - accuracy: 0.9599\n","Epoch 38/40\n","29/29 [==============================] - 5s 180ms/step - loss: 0.1717 - accuracy: 0.9603\n","Epoch 39/40\n","29/29 [==============================] - 5s 179ms/step - loss: 0.1674 - accuracy: 0.9615\n","Epoch 40/40\n","29/29 [==============================] - 5s 179ms/step - loss: 0.1640 - accuracy: 0.9625\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fc76769abe0>"]},"metadata":{"tags":[]},"execution_count":76}]},{"cell_type":"code","metadata":{"id":"2cHRRLWbOO8Z","executionInfo":{"status":"ok","timestamp":1612637343536,"user_tz":-540,"elapsed":212780,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}}},"source":["import numpy as np\r\n","\r\n","# 한국어 단어 집합의 크기 : 5551, (50000, 95)\r\n","# 영어 단어 집합의 크기 : 2484, (50000, 104)\r\n","\r\n","def translate(kor):\r\n","    # eng => index => pad\r\n","    kor_seq = tokenizer_kr.texts_to_sequences([kor])\r\n","    kor_pad = tf.keras.preprocessing.sequence.pad_sequences(kor_seq, maxlen=95)\r\n","\r\n","    eng = []\r\n","    for n in range(104-1):\r\n","        # kor => index => pad\r\n","        eng_seq = tokenizer_en.texts_to_sequences([['<sos>'] + eng])\r\n","        eng_pad = tf.keras.preprocessing.sequence.pad_sequences(eng_seq, maxlen=104-1)\r\n","        eng_next = model.predict([kor_pad, eng_pad])\r\n","\r\n","        # onehot -> index -> word\r\n","        eng = [tokenizer_en.index_word[i] for i in np.argmax(eng_next[0], axis=1) if i != 0]\r\n","        # 번역된 word 선택\r\n","        eng = eng[:n+1]\r\n","        \r\n","        if eng[-1] == '<eos>':\r\n","            break\r\n","\r\n","    return eng"],"execution_count":77,"outputs":[]},{"cell_type":"code","metadata":{"id":"GUglKyFVQW4y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612637364192,"user_tz":-540,"elapsed":4574,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}},"outputId":"287fe36a-ca93-489d-c863-576b27813c0e"},"source":["import random\r\n","\r\n","# 랜덤 10개\r\n","indices = list(range(3648))\r\n","random.shuffle(indices)\r\n","\r\n","for n in indices[:10]:\r\n","    print(f\"한국어: {kor_sent[n]}\\n영어: {eng_sent[n]}\")\r\n","    print(f\"번역: {' '.join(translate(kor_sent[n])[:-1])}\")\r\n","    print()"],"execution_count":79,"outputs":[{"output_type":"stream","text":["한국어: 난 내 집이 좋아 . \n","영어: <sos> i love my home .  <eos>\n","번역: i ' m not sure i can go to the party .\n","\n","한국어: 나는 약을 여섯 시간마다 먹어야 해 . \n","영어: <sos> i have to take my medicine every six hours .  <eos>\n","번역: i ' m not sure i can go to the party .\n","\n","한국어: 톰은 잊어버려 . \n","영어: <sos> forget tom .  <eos>\n","번역: tom was diagnosed with asd .\n","\n","한국어: 나는 뭔가가 잘못되었다고 생각했다 . \n","영어: <sos> i thought something was wrong .  <eos>\n","번역: i ' m sorry .\n","\n","한국어: 법 이전에 모두는 평등해 . \n","영어: <sos> everybody is equal before the law .  <eos>\n","번역: i ' m going to do my best .\n","\n","한국어: 톰은 개를 쫓아갔어 . \n","영어: <sos> tom ran after the dog .  <eos>\n","번역: i ' ve never seen anything to take you .\n","\n","한국어: 조심해 ! \n","영어: <sos> look out !  <eos>\n","번역: tom was diagnosed with asd .\n","\n","한국어: 너 한때 여기서 일했었지 ? \n","영어: <sos> you used to work here didn ' t you ?  <eos>\n","번역: what ' s the subway station ?\n","\n","한국어: 톰은 알코올이라면 전혀 입에 대지 않아 . \n","영어: <sos> tom doesn ' t drink alcoholic drinks at all .  <eos>\n","번역: i ' m sorry i can go to the party .\n","\n","한국어: 지구상의 인구는 60억 이상이야 . \n","영어: <sos> there are more than six billion people in the world .  <eos>\n","번역: i ' m not sure i can go to the party .\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3mZSvqaFUdwV","executionInfo":{"status":"ok","timestamp":1612637348362,"user_tz":-540,"elapsed":217595,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}}},"source":[""],"execution_count":78,"outputs":[]}]}