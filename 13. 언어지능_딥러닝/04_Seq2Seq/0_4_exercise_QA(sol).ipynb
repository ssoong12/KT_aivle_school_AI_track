{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGlWW9jN5e9a"
      },
      "source": [
        "# Sequence to Sequence (a.k.a. seq2seq)\n",
        "\n",
        "**학습목표**\n",
        "* Encoder Decoder 구조를 이해하고 구현할 줄 안다.\n",
        "* Seq2Seq에 필요한 전처리를 이해한다.\n",
        "* **데이터 부족**과, **긴 문장**을 겪어본다.\n",
        "\n",
        "![이런거](https://raw.githubusercontent.com/KerasKorea/KEKOxTutorial/master/media/28_1.png)\n",
        "---------------------------------\n",
        "edu.rayleigh@gmail.com\n",
        "Special Thanks to : 숙번님 ( [봉수골 개발자 이선비](https://www.youtube.com/channel/UCOAyyrvi7tnCAz7RhH98QCQ) )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vpud2H-Js6fN"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/kitae104/New_Python/master/Chatbot/data/ChatbotData%20.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-A2Uf0V-y-W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dde3d58-5ed4-46cb-c2c0-7eb2b123fd39"
      },
      "source": [
        "import pandas as pd\n",
        "temp = pd.read_csv(url, usecols=[0,1])\n",
        "temp.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11823, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0n8j-x_j8rTj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "67351267-758b-4021-c39b-68ec00bb59a5"
      },
      "source": [
        "temp.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12시 땡!</td>\n",
              "      <td>하루가 또 가네요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1지망 학교 떨어졌어</td>\n",
              "      <td>위로해 드립니다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3박4일 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3박4일 정도 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PPL 심하네</td>\n",
              "      <td>눈살이 찌푸려지죠.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Q            A\n",
              "0           12시 땡!   하루가 또 가네요.\n",
              "1      1지망 학교 떨어졌어    위로해 드립니다.\n",
              "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.\n",
              "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.\n",
              "4          PPL 심하네   눈살이 찌푸려지죠."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTTke03auDnt"
      },
      "source": [
        "Q_sent = temp['Q'].tolist()\n",
        "A_sent = temp['A'].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qntWaQtjSo0U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba89f243-80ce-4487-8558-98f33b9b2221"
      },
      "source": [
        "print(Q_sent[1000])\n",
        "print(A_sent[1000])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "노래방 걸 거 같은데 뭐 부르지\n",
            "달달한 노래요.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPU1CYykAdXU"
      },
      "source": [
        "# 데이터 준비\n",
        "0. 단어와 구두점 사이 공백 만들기\n",
        "1. sos 와 eos\n",
        "1. tokenizing, idx_seq, padding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fj9FhCC9IgaO"
      },
      "source": [
        "## 0. 단어와 구두점 사이 공백 만들기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wi0kBaQRIjwB"
      },
      "source": [
        "import unicodedata\n",
        "import re\n",
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def preprocessor(sent):\n",
        "    # 위에서 구현한 함수를 내부적으로 호출\n",
        "    sent = unicode_to_ascii(sent.lower())\n",
        "\n",
        "    # 단어와 구두점 사이에 공백을 만듭니다.\n",
        "    # Ex) \"he is a boy.\" => \"he is a boy .\"\n",
        "    sent = re.sub(r\"([?.!,'¿])\", r\" \\1 \", sent)\n",
        "\n",
        "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
        "    return sent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjAoavx2IsTj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c2d6c23e-66ac-4465-c4af-22be33a821b6"
      },
      "source": [
        "preprocessor(\"나는 멋있어.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'나는 멋있어 . '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjr_CjB6JFlj"
      },
      "source": [
        "A_sent = [ preprocessor(sent) for sent in A_sent ]\n",
        "Q_sent = [ preprocessor(sent) for sent in Q_sent ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MIrvRfKJOB3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2286b352-b07c-4506-b7c3-8d8db55c2bc7"
      },
      "source": [
        "print(A_sent[1000])\n",
        "print(Q_sent[1000])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "달달한 노래요 . \n",
            "노래방 걸 거 같은데 뭐 부르지\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LR2w3i3EJ6c"
      },
      "source": [
        "## 1. sos 와 eos\n",
        "1. sos : start of speech\n",
        "2. eos : end of speech"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFkzszhyDq6E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f3322217-1521-440e-8aea-1ee06c8dfb97"
      },
      "source": [
        "######################\n",
        "### Your Code here ###\n",
        "######################\n",
        "\n",
        "## 답변 문장 전 후에 <sos>와 <eos>를 추가할 것\n",
        "## 띄어쓰기 주의!\n",
        "\n",
        "A_sent = [f\"<sos> {A} <eos>\" for A in A_sent]\n",
        "A_sent[1000]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<sos> 달달한 노래요 .  <eos>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrEhHIQlEU8F"
      },
      "source": [
        "## 2. Tokenizing, idx_seq, padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-C-zqpSEewe"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbf-Y--TEj7Y"
      },
      "source": [
        "######################\n",
        "### Your Code here ###\n",
        "######################\n",
        "\n",
        "# Tokenizing    # 한국어는 lower = False\n",
        "tokenizer_A = Tokenizer(filters=\"\", lower=False)\n",
        "tokenizer_A.fit_on_texts(A_sent)\n",
        "tokenizer_Q = Tokenizer(filters=\"\", lower=False)\n",
        "tokenizer_Q.fit_on_texts(Q_sent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvDe7BY-F3jB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0d8787e-d5a3-457d-c005-cc88288725cf"
      },
      "source": [
        "######################\n",
        "### Your Code here ###\n",
        "######################\n",
        "\n",
        "# Index Sequence\n",
        "A_seq = tokenizer_A.texts_to_sequences(A_sent)\n",
        "Q_seq = tokenizer_Q.texts_to_sequences(Q_sent)\n",
        "\n",
        "print(A_seq[1000])\n",
        "print(Q_seq[1000])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1783, 3475, 3, 2]\n",
            "[650, 142, 5, 77, 44, 2835]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sadRsDiaJ7p5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff6f5c9e-d027-4476-a2b2-abed7c444178"
      },
      "source": [
        "######################\n",
        "### Your Code here ###\n",
        "######################\n",
        "## 최대 문장 길이에 맞춰지도록 할 것.\n",
        "# padding\n",
        "A_pad = pad_sequences(A_seq, padding='post') # 최대 문장 길이에 패딩에 맞춰지게 됨.\n",
        "Q_pad = pad_sequences(Q_seq)\n",
        "\n",
        "print(Q_pad.shape)\n",
        "print(A_pad.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11823, 16)\n",
            "(11823, 26)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW-52MAiKjLW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2abf008-186c-44dc-e619-3d0cb4f45e4d"
      },
      "source": [
        "# tokenizer에서 0 index가 구성되어있지 않지만, \n",
        "# pad_sequence에서 pad의 의미로 0을 사용하고 있어서, 전체 사이즈를 구할 때, +1을 해준다.\n",
        "\n",
        "A_vocab_size = len(tokenizer_A.word_index) + 1\n",
        "Q_vocab_size = len(tokenizer_Q.word_index) + 1\n",
        "print(\"질문 단어 집합의 크기: {:d}\\n답변 단어 집합의 크기: {:d}\".format(Q_vocab_size, A_vocab_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "질문 단어 집합의 크기: 13418\n",
            "답변 단어 집합의 크기: 9855\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faI0SNWRKr7O"
      },
      "source": [
        "# 모델링!\n",
        "\n",
        "1. 모든 임베딩 레이어는 128개 차원으로 구성.\n",
        "2. 인코더도 디코더도 GRU, 히든스테이트 512로 구성.\n",
        "3. 디코더의 GRU 뒤에는 Fully Conneceted layer 사용. 노드 512개\n",
        "4. 적절한 아웃풋레이어\n",
        "    * 매 시점, 가장 적절한 단어가 무엇일지 분류 한다고 생각하면 됨!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daSlqB5TK-ua"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, GRU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHPZhTlXK8Gy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49cccab4-b67e-473c-edcb-02cfcbfad475"
      },
      "source": [
        "######################\n",
        "### Your Code here ###\n",
        "######################\n",
        "\n",
        "# 혹시 이미 그려둔 그래프가 있다면 날려줘!\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# 질문 단어 집합의 크기 : 13418, (11823, 16)\n",
        "# 답변 단어 집합의 크기 : 9855, (11823, 26)\n",
        "# 디코더의 인풋으로 넣을때는 맨 뒤의 <eos>를 떼고 길이 103의 문장을\n",
        "# 디코더의 아웃풋은 맨 앞의 <eos>를 떼고 길이 103의 문장으로 준비해야 함.\n",
        "\n",
        "# Encoder\n",
        "enc_X = tf.keras.layers.Input(shape=[Q_pad.shape[1]])\n",
        "enc_E = tf.keras.layers.Embedding(Q_vocab_size, 128)(enc_X) # 토큰수, 차원수\n",
        "enc_S_full, enc_S = tf.keras.layers.GRU(512, return_sequences=True, return_state=True)(enc_E)\n",
        "## 이제는 enc_S_full을 쓴다!\n",
        "\n",
        "# Decoder\n",
        "dec_X = tf.keras.layers.Input(shape=[A_pad.shape[1]-1])\n",
        "dec_E = tf.keras.layers.Embedding(A_vocab_size, 128)(dec_X) # 토큰수, 차원수\n",
        "dec_H = tf.keras.layers.GRU(512, return_sequences=True)(dec_E, initial_state=enc_S)\n",
        "\n",
        "#####################\n",
        "## Attention layer ##\n",
        "#####################\n",
        "key = enc_S_full  # 인코더의 히든스테이트를 key로 활용한다. \n",
        "value = enc_S_full  # 인코더의 히든스테이트를 value로 활용한다. \n",
        "query = dec_H  # 디코더의 히든스테이트를 query로 활용한다.\n",
        "\n",
        "# 1. 어텐션 스코어(Attention Score)를 구한다.\n",
        "score = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "# 2. 소프트맥스(softmax) 함수를 통해 어텐션 분포(Attention Distribution)를 구한다.\n",
        "att_dist = tf.nn.softmax(score, axis=-1)\n",
        "\n",
        "# 3. 각 인코더의 어텐션 가중치와 은닉 상태를 가중합하여 어텐션 값(Attention Value)을 구한다.\n",
        "att_value = tf.matmul(att_dist, value)\n",
        "\n",
        "### 사실은, 아래 한줄의 코드로도 가능.\n",
        "# att_value = tf.keras.layers.Attention()([query, key])\n",
        "\n",
        "# 4. 어텐션 값과 디코더의 t 시점의 은닉 상태를 연결한다.(Concatenate)\n",
        "\n",
        "dec_H = tf.keras.layers.Concatenate()([att_value, dec_H])\n",
        "# 5. 출력층 연산의 입력이 되는 dec_H를 계산.\n",
        "dec_H = tf.keras.layers.Dense(512, activation='tanh')(dec_H)\n",
        "\n",
        "dec_Y = tf.keras.layers.Dense(Q_vocab_size, activation=\"softmax\")(dec_H)\n",
        "model = tf.keras.models.Model([enc_X, dec_X], dec_Y)\n",
        "# 텍스트는 index이고(원핫인코딩을 안했고)\n",
        "# 아웃풋레이어는 분류문제 처럼 노드가 준비되어 있다면\n",
        "# sparse categorical crossentropy\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer = tf.keras.optimizers.RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 16)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 25)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 16, 128)      1717504     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 25, 128)      1261440     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gru (GRU)                       [(None, 16, 512), (N 986112      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "gru_1 (GRU)                     (None, 25, 512)      986112      embedding_1[0][0]                \n",
            "                                                                 gru[0][1]                        \n",
            "__________________________________________________________________________________________________\n",
            "tf.linalg.matmul (TFOpLambda)   (None, 25, 16)       0           gru_1[0][0]                      \n",
            "                                                                 gru[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.softmax (TFOpLambda)      (None, 25, 16)       0           tf.linalg.matmul[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf.linalg.matmul_1 (TFOpLambda) (None, 25, 512)      0           tf.nn.softmax[0][0]              \n",
            "                                                                 gru[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 25, 1024)     0           tf.linalg.matmul_1[0][0]         \n",
            "                                                                 gru_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 25, 512)      524800      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 25, 13418)    6883434     dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 12,359,402\n",
            "Trainable params: 12,359,402\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceSiL3RxNuQE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cdbbca2-f671-4630-98d9-da759bbb014c"
      },
      "source": [
        "######################\n",
        "### Your Code here ###\n",
        "######################\n",
        "## 학습 시킬 것!\n",
        "\n",
        "# decoder의 인풋은 마지막 <eos>를 뗀다.\n",
        "# decoder의 아웃풋 학습시엔 처음의 <sos>를 뗀다.\n",
        "model.fit([Q_pad, A_pad[:, :-1]], A_pad[:, 1:], shuffle=True, \n",
        "          batch_size=128, epochs=40)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "93/93 [==============================] - 17s 84ms/step - loss: 2.9734 - accuracy: 0.6901\n",
            "Epoch 2/40\n",
            "93/93 [==============================] - 8s 84ms/step - loss: 1.4790 - accuracy: 0.7810\n",
            "Epoch 3/40\n",
            "93/93 [==============================] - 8s 85ms/step - loss: 1.3161 - accuracy: 0.8078\n",
            "Epoch 4/40\n",
            "93/93 [==============================] - 8s 85ms/step - loss: 1.2303 - accuracy: 0.8149\n",
            "Epoch 5/40\n",
            "93/93 [==============================] - 8s 86ms/step - loss: 1.1881 - accuracy: 0.8188\n",
            "Epoch 6/40\n",
            "93/93 [==============================] - 8s 86ms/step - loss: 1.1364 - accuracy: 0.8206\n",
            "Epoch 7/40\n",
            "93/93 [==============================] - 8s 87ms/step - loss: 1.1039 - accuracy: 0.8237\n",
            "Epoch 8/40\n",
            "93/93 [==============================] - 8s 88ms/step - loss: 1.0562 - accuracy: 0.8281\n",
            "Epoch 9/40\n",
            "93/93 [==============================] - 8s 89ms/step - loss: 1.0217 - accuracy: 0.8307\n",
            "Epoch 10/40\n",
            "93/93 [==============================] - 8s 90ms/step - loss: 0.9693 - accuracy: 0.8358\n",
            "Epoch 11/40\n",
            "93/93 [==============================] - 8s 91ms/step - loss: 0.9433 - accuracy: 0.8367\n",
            "Epoch 12/40\n",
            "93/93 [==============================] - 9s 92ms/step - loss: 0.8896 - accuracy: 0.8427\n",
            "Epoch 13/40\n",
            "93/93 [==============================] - 9s 93ms/step - loss: 0.8602 - accuracy: 0.8460\n",
            "Epoch 14/40\n",
            "93/93 [==============================] - 9s 93ms/step - loss: 0.8092 - accuracy: 0.8539\n",
            "Epoch 15/40\n",
            "93/93 [==============================] - 9s 92ms/step - loss: 0.7926 - accuracy: 0.8539\n",
            "Epoch 16/40\n",
            "93/93 [==============================] - 8s 91ms/step - loss: 0.7548 - accuracy: 0.8582\n",
            "Epoch 17/40\n",
            "93/93 [==============================] - 8s 90ms/step - loss: 0.7198 - accuracy: 0.8634\n",
            "Epoch 18/40\n",
            "93/93 [==============================] - 8s 90ms/step - loss: 0.6840 - accuracy: 0.8687\n",
            "Epoch 19/40\n",
            "93/93 [==============================] - 8s 90ms/step - loss: 0.6569 - accuracy: 0.8724\n",
            "Epoch 20/40\n",
            "93/93 [==============================] - 8s 91ms/step - loss: 0.6311 - accuracy: 0.8766\n",
            "Epoch 21/40\n",
            "93/93 [==============================] - 8s 91ms/step - loss: 0.6055 - accuracy: 0.8806\n",
            "Epoch 22/40\n",
            "93/93 [==============================] - 9s 91ms/step - loss: 0.5779 - accuracy: 0.8856\n",
            "Epoch 23/40\n",
            "93/93 [==============================] - 8s 91ms/step - loss: 0.5521 - accuracy: 0.8910\n",
            "Epoch 24/40\n",
            "93/93 [==============================] - 8s 91ms/step - loss: 0.5320 - accuracy: 0.8934\n",
            "Epoch 25/40\n",
            "93/93 [==============================] - 8s 91ms/step - loss: 0.5104 - accuracy: 0.8975\n",
            "Epoch 26/40\n",
            "93/93 [==============================] - 8s 91ms/step - loss: 0.4876 - accuracy: 0.9012\n",
            "Epoch 27/40\n",
            "93/93 [==============================] - 8s 91ms/step - loss: 0.4725 - accuracy: 0.9034\n",
            "Epoch 28/40\n",
            "93/93 [==============================] - 8s 91ms/step - loss: 0.4493 - accuracy: 0.9078\n",
            "Epoch 29/40\n",
            "93/93 [==============================] - 8s 91ms/step - loss: 0.4274 - accuracy: 0.9123\n",
            "Epoch 30/40\n",
            "93/93 [==============================] - 8s 91ms/step - loss: 0.4116 - accuracy: 0.9160\n",
            "Epoch 31/40\n",
            "93/93 [==============================] - 8s 91ms/step - loss: 0.4010 - accuracy: 0.9185\n",
            "Epoch 32/40\n",
            "93/93 [==============================] - 8s 91ms/step - loss: 0.3758 - accuracy: 0.9233\n",
            "Epoch 33/40\n",
            "93/93 [==============================] - 8s 91ms/step - loss: 0.3654 - accuracy: 0.9254\n",
            "Epoch 34/40\n",
            "93/93 [==============================] - 8s 91ms/step - loss: 0.3486 - accuracy: 0.9305\n",
            "Epoch 35/40\n",
            "93/93 [==============================] - 8s 91ms/step - loss: 0.3322 - accuracy: 0.9329\n",
            "Epoch 36/40\n",
            "93/93 [==============================] - 8s 91ms/step - loss: 0.3187 - accuracy: 0.9359\n",
            "Epoch 37/40\n",
            "93/93 [==============================] - 8s 91ms/step - loss: 0.3145 - accuracy: 0.9362\n",
            "Epoch 38/40\n",
            "93/93 [==============================] - 8s 91ms/step - loss: 0.2943 - accuracy: 0.9412\n",
            "Epoch 39/40\n",
            "93/93 [==============================] - 8s 91ms/step - loss: 0.2825 - accuracy: 0.9438\n",
            "Epoch 40/40\n",
            "93/93 [==============================] - 8s 91ms/step - loss: 0.2738 - accuracy: 0.9452\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7bd0218748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cHRRLWbOO8Z"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# 질문 단어 집합의 크기 : 13418, (11823, 16)\n",
        "# 답변 단어 집합의 크기 : 9855, (11823, 26)\n",
        "\n",
        "def translate(Q):\n",
        "    # A => index => pad\n",
        "    Q_seq = tokenizer_Q.texts_to_sequences([Q])\n",
        "    Q_pad = tf.keras.preprocessing.sequence.pad_sequences(Q_seq, maxlen=16)\n",
        "\n",
        "    A = []\n",
        "    for n in range(26-1):\n",
        "        # Q => index => pad\n",
        "        A_seq = tokenizer_A.texts_to_sequences([['<sos>'] + A])\n",
        "        A_pad = tf.keras.preprocessing.sequence.pad_sequences(A_seq, maxlen=26-1)\n",
        "        A_next = model.predict([Q_pad, A_pad])\n",
        "\n",
        "        # onehot -> index -> word\n",
        "        A = [tokenizer_A.index_word[i] for i in np.argmax(A_next[0], axis=1) if i != 0]\n",
        "        # 번역된 word 선택\n",
        "        A = A[:n+1]\n",
        "        \n",
        "        if A[-1] == '<eos>':\n",
        "            break\n",
        "\n",
        "    return A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUglKyFVQW4y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c97dd7b5-9093-4253-d066-755ce077c1a2"
      },
      "source": [
        "import random\n",
        "\n",
        "# 랜덤 10개\n",
        "indices = list(range(3648))\n",
        "random.shuffle(indices)\n",
        "\n",
        "for n in indices[:10]:\n",
        "    print(f\"한국어: {Q_sent[n]}\\n영어: {A_sent[n]}\")\n",
        "    print(f\"번역: {' '.join(translate(Q_sent[n])[:-1])}\")\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "한국어: 사업 구상하고 있어\n",
            "영어: <sos> 성공하길 바랍니다 .  <eos>\n",
            "번역: 지금은 괜찮길 사람이에요 . <eos>\n",
            "\n",
            "한국어: 결혼준비하는데 돈 얼마나 드나\n",
            "영어: <sos> 욕심에 따라 천지 차이일 거예요 .  <eos>\n",
            "번역: 일이 수도 할 . <eos> <eos>\n",
            "\n",
            "한국어: 엿같다 . \n",
            "영어: <sos> 벗어나는 게 좋겠네요 .  <eos>\n",
            "번역: 벗어나는 좋은 것 거예요 .\n",
            "\n",
            "한국어: 엄마한테 막말했어\n",
            "영어: <sos> 더 후회하기 전에 사과하세요 .  <eos>\n",
            "번역: 좋은 곳으로 갈 바뀔 것도 수도 <eos> 생각해요\n",
            "\n",
            "한국어: 다음에 봐\n",
            "영어: <sos> 잘가요 .  <eos>\n",
            "번역: 안녕히 . ! <eos>\n",
            "\n",
            "한국어: 목욕탕 가야지\n",
            "영어: <sos> 시원하게 씻고 오세요 .  <eos>\n",
            "번역: 시원하게 좋은 . 것 .\n",
            "\n",
            "한국어: 반 배정 좀 잘 됐으면 좋겠다\n",
            "영어: <sos> 잘 되길 바랍니다 .  <eos>\n",
            "번역: 많이 잘 해놨나봐요 살 .\n",
            "\n",
            "한국어: 오늘 보름달이다 . \n",
            "영어: <sos> 소원을 비세요 .  <eos>\n",
            "번역: 소원을 필요해요 <eos> .\n",
            "\n",
            "한국어: 연금 믿어도 될까\n",
            "영어: <sos> 없는 것보다 나을 거예요 .  <eos>\n",
            "번역: 원하는 게 만큼 중요한 좋아요 . <eos>\n",
            "\n",
            "한국어: 내가 제정신이 아니다\n",
            "영어: <sos> 그럴 때가 있죠 .  <eos>\n",
            "번역: 아직 잘 수 거예요 .\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mZSvqaFUdwV"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}