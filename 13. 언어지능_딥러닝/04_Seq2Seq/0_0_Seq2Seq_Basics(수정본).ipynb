{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGlWW9jN5e9a"
      },
      "source": [
        "# Sequence to Sequence (a.k.a. seq2seq)\n",
        "\n",
        "**학습목표**\n",
        "* Encoder Decoder 구조를 이해하고 구현할 줄 안다.\n",
        "* Seq2Seq에 필요한 전처리를 이해한다.\n",
        "\n",
        "![이런거](https://raw.githubusercontent.com/KerasKorea/KEKOxTutorial/master/media/28_1.png)\n",
        "---------------------------------\n",
        "edu.rayleigh@gmail.com\n",
        "Special Thanks to : 숙번님 ( [봉수골 개발자 이선비](https://www.youtube.com/channel/UCOAyyrvi7tnCAz7RhH98QCQ) )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObiFUtaC8pHk"
      },
      "source": [
        "# !wget http://www.manythings.org/anki/fra-eng.zip"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeblRhOP9CxX"
      },
      "source": [
        "# import zipfile\n",
        "# fra_eng = zipfile.ZipFile('fra-eng.zip')\n",
        "# fra_eng.extractall()\n",
        "# fra_eng.close()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VTApAubX8bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b646467-5d6b-4c09-b496-bc3e6995570a"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/L1aoXingyu/seq2seq-translation/master/data/eng-fra.txt"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-31 06:41:49--  https://raw.githubusercontent.com/L1aoXingyu/seq2seq-translation/master/data/eng-fra.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9541158 (9.1M) [text/plain]\n",
            "Saving to: ‘eng-fra.txt.1’\n",
            "\n",
            "\reng-fra.txt.1         0%[                    ]       0  --.-KB/s               \reng-fra.txt.1       100%[===================>]   9.10M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-03-31 06:41:50 (91.8 MB/s) - ‘eng-fra.txt.1’ saved [9541158/9541158]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-A2Uf0V-y-W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "847fdac0-8587-42db-f370-49aaa5a7fbb7"
      },
      "source": [
        "import pandas as pd\n",
        "# temp = pd.read_table('fra.txt', names=['Eng', 'Fra', 'License'])\n",
        "temp = pd.read_table('eng-fra.txt', names=['Eng', 'Fra'])\n",
        "temp.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(135842, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0n8j-x_j8rTj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "30854fde-146a-4321-9353-5aa5e9857442"
      },
      "source": [
        "temp.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Eng         Fra\n",
              "0    Go.        Va !\n",
              "1   Run!     Cours !\n",
              "2   Run!    Courez !\n",
              "3   Wow!  Ça alors !\n",
              "4  Fire!    Au feu !"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0264c6f-0175-4980-9097-53625915c96e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Eng</th>\n",
              "      <th>Fra</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Va !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Cours !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Courez !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wow!</td>\n",
              "      <td>Ça alors !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Fire!</td>\n",
              "      <td>Au feu !</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0264c6f-0175-4980-9097-53625915c96e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a0264c6f-0175-4980-9097-53625915c96e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a0264c6f-0175-4980-9097-53625915c96e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI1y7O_OSAVY"
      },
      "source": [
        "# 너무 많으므로 50000개 문장만 진행하자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pm522fcSSDdH"
      },
      "source": [
        "# ## 끔찍한 결과를 볼 수 있다.\n",
        "# temp = temp.sample(n=50000, replace=False, random_state=2021)\n",
        "\n",
        "temp = temp.iloc[:50000]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHEF-9_1AHF2"
      },
      "source": [
        "eng_sent = temp['Eng'].tolist()\n",
        "fra_sent = temp['Fra'].tolist()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qntWaQtjSo0U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a27d7007-bf22-4e00-fb7c-0ee3f85238f2"
      },
      "source": [
        "print(eng_sent[100])\n",
        "print(fra_sent[100])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go away!\n",
            "Pars !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPU1CYykAdXU"
      },
      "source": [
        "# 데이터 준비\n",
        "0. 단어와 구두점 사이 공백 만들기\n",
        "1. sos 와 eos\n",
        "1. tokenizing, idx_seq, padding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fj9FhCC9IgaO"
      },
      "source": [
        "## 0. 단어와 구두점 사이 공백 만들기\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex1 = 'Abandonne\\u202f!'\n",
        "ex2 = 'Allez vous échauffer !'"
      ],
      "metadata": {
        "id": "jqlLtq9KTktp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wi0kBaQRIjwB"
      },
      "source": [
        "# 정규식 공부\n",
        "# 문장을 하나 딱 짚어서\n",
        "# 실제 어떻게 동작하는지를 뜯어서 확인\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def preprocess_sentence(sent):\n",
        "    # 위에서 구현한 함수를 내부적으로 호출\n",
        "    sent = unicode_to_ascii(sent.lower())\n",
        "\n",
        "    # 단어와 구두점 사이에 공백을 만듭니다.\n",
        "    # Ex) \"he is a boy.\" => \"he is a boy .\"\n",
        "    sent = re.sub(r\"([?.!,'¿])\", r\" \\1 \", sent)\n",
        "\n",
        "    # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 이들을 제외하고는 전부 공백으로 변환합니다.\n",
        "    sent = re.sub(r\"[^a-zA-Z!.?']+\", r\" \", sent)\n",
        "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
        "    return sent"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjAoavx2IsTj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "5735fec4-d132-4853-c85b-535157f077a5"
      },
      "source": [
        "preprocess_sentence(\"I'm just a poor boy.\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"i ' m just a poor boy . \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjr_CjB6JFlj"
      },
      "source": [
        "eng_sent = [ preprocess_sentence(sent) for sent in eng_sent ]\n",
        "fra_sent = [ preprocess_sentence(sent) for sent in fra_sent ]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MIrvRfKJOB3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6d4c241-b4ec-43b8-f65d-9dbc606fdaaa"
      },
      "source": [
        "print(eng_sent[100])\n",
        "print(fra_sent[100])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "go away ! \n",
            "pars ! \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LR2w3i3EJ6c"
      },
      "source": [
        "## 1. sos 와 eos\n",
        "1. sos : start of speech\n",
        "2. eos : end of speech"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFkzszhyDq6E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "8a482e48-44af-4cfd-d8b6-0e09f29c84ec"
      },
      "source": [
        "fra_sent = [f\"<sos> {fra} <eos>\" for fra in fra_sent]\n",
        "fra_sent[100]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<sos> pars !  <eos>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrEhHIQlEU8F"
      },
      "source": [
        "## 2. Tokenizing, idx_seq, padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-C-zqpSEewe"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbf-Y--TEj7Y"
      },
      "source": [
        "# Tokenizing\n",
        "tokenizer_en = Tokenizer(filters=\"\", lower=True)\n",
        "tokenizer_en.fit_on_texts(eng_sent)\n",
        "tokenizer_fr = Tokenizer(filters=\"\", lower=True)\n",
        "tokenizer_fr.fit_on_texts(fra_sent)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvDe7BY-F3jB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5132119a-088a-486e-96cb-00a584899dd9"
      },
      "source": [
        "# Index Sequence\n",
        "eng_seq = tokenizer_en.texts_to_sequences(eng_sent)\n",
        "fra_seq = tokenizer_fr.texts_to_sequences(fra_sent)\n",
        "\n",
        "print(eng_seq[100])\n",
        "print(fra_seq[100])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[38, 194, 47]\n",
            "[1, 683, 18, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sadRsDiaJ7p5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24545387-6b80-4b2e-ffab-4ae323a0abc0"
      },
      "source": [
        "# padding   프랑스어 패딩 위치를 '뒤'로 바꿨음.\n",
        "eng_pad = pad_sequences(eng_seq, padding='pre') # 최대 문장 길이에 패딩에 맞춰지게 됨.\n",
        "fra_pad = pad_sequences(fra_seq, padding='post')\n",
        "\n",
        "print(eng_pad[100])\n",
        "print(fra_pad[100])\n",
        "print(eng_pad.shape)\n",
        "print(fra_pad.shape)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  0   0   0   0   0   0   0   0  38 194  47]\n",
            "[  1 683  18   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0]\n",
            "(50000, 11)\n",
            "(50000, 19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW-52MAiKjLW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9080fb3-1d0d-4894-dd5c-41dc22ff8f88"
      },
      "source": [
        "# tokenizer에서 0 index가 구성되어있지 않지만, \n",
        "# pad_sequence에서 pad의 의미로 0을 사용하고 있어서, 전체 사이즈를 구할 때, +1을 해준다.\n",
        "\n",
        "eng_vocab_size = len(tokenizer_en.word_index) + 1\n",
        "fra_vocab_size = len(tokenizer_fr.word_index) + 1\n",
        "print(\"영어 단어 집합의 크기: {:d}\\n프랑스어 단어 집합의 크기: {:d}\".format(eng_vocab_size, fra_vocab_size))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영어 단어 집합의 크기: 5965\n",
            "프랑스어 단어 집합의 크기: 10406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faI0SNWRKr7O"
      },
      "source": [
        "# 모델링!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daSlqB5TK-ua"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, GRU"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHPZhTlXK8Gy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8003a535-b9bf-493a-f5e7-e4dc3cf47db6"
      },
      "source": [
        "# 혹시 이미 그려둔 그래프가 있다면 날려줘!\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# 영어 단어 집합의 크기 : 5965, (50000, 11)\n",
        "# 프랑스어 단어 집합의 크기 : 10406, (50000, 19)\n",
        "# 프랑스어 문장은 길이가 19이지만,\n",
        "# 디코더의 인풋으로 넣을때는 맨 뒤의 <eos>를 떼고 길이 18의 문장을\n",
        "# 디코더의 아웃풋은 맨 앞의 <eos>를 떼고 길이 18의 문장으로 준비해야 함.\n",
        "\n",
        "# Encoder\n",
        "enc_X = tf.keras.layers.Input(shape=[eng_pad.shape[1]])\n",
        "enc_E = tf.keras.layers.Embedding(eng_vocab_size, 64)(enc_X) # 토큰수, 차원수\n",
        "enc_S_full, enc_S = tf.keras.layers.GRU(256, return_sequences=True, return_state=True)(enc_E)\n",
        "## 물론 지금은 enc_S_full은 사용하지 않는다.\n",
        "# S : (Hidden) State\n",
        "\n",
        "# Decoder\n",
        "dec_X = tf.keras.layers.Input(shape=[fra_pad.shape[1]-1])\n",
        "dec_E = tf.keras.layers.Embedding(fra_vocab_size, 64)(dec_X) # 토큰수, 차원수\n",
        "dec_H = tf.keras.layers.GRU(256, return_sequences=True)(dec_E, initial_state=enc_S)\n",
        "# dec_H = tf.keras.layers.Dense(256, activation=\"swish\")(dec_H) # 없어도 상관은 없는 부분.\n",
        "dec_Y = tf.keras.layers.Dense(fra_vocab_size, activation=\"softmax\")(dec_H) # 매시점에서, 어떤 단어가 타당할지 분류 문제로 푸는 것\n",
        "\n",
        "model = tf.keras.models.Model([enc_X, dec_X], dec_Y)\n",
        "# 텍스트는 index이고(원핫인코딩을 안했고)\n",
        "# 아웃풋레이어는 분류문제 처럼 노드가 준비되어 있다면\n",
        "# sparse categorical crossentropy\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer = 'rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 11)]         0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 18)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 11, 64)       381760      ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 18, 64)       665984      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " gru (GRU)                      [(None, 11, 256),    247296      ['embedding[0][0]']              \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " gru_1 (GRU)                    (None, 18, 256)      247296      ['embedding_1[0][0]',            \n",
            "                                                                  'gru[0][1]']                    \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 18, 10406)    2674342     ['gru_1[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,216,678\n",
            "Trainable params: 4,216,678\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceSiL3RxNuQE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35e161b8-335c-48d8-cc79-ae8e3a89aea2"
      },
      "source": [
        "# decoder의 인풋은 마지막 <eos>를 뗀다.\n",
        "# decoder의 아웃풋 학습시엔 처음의 <sos>를 뗀다.\n",
        "model.fit([eng_pad, fra_pad[:, :-1]], fra_pad[:, 1:], shuffle=True, \n",
        "          batch_size=128, epochs=10)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 1.1938 - accuracy: 0.7906\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 1.0997 - accuracy: 0.8055\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 1.0576 - accuracy: 0.8108\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 1.0238 - accuracy: 0.8150\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.9939 - accuracy: 0.8187\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.9667 - accuracy: 0.8224\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.9411 - accuracy: 0.8252\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.9167 - accuracy: 0.8285\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.8933 - accuracy: 0.8315\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.8707 - accuracy: 0.8345\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6e79bf1a00>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cHRRLWbOO8Z"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# 영어 단어 집합의 크기 : 5965, (50000, 11)\n",
        "# 프랑스어 단어 집합의 크기 : 10406, (50000, 19)\n",
        "\n",
        "def translate(eng):  # 영어 문장을 인풋으로 받아서\n",
        "    # eng => index => pad\n",
        "    eng_seq = tokenizer_en.texts_to_sequences([eng]) # 인덱스의 시퀀스로 바꾸고\n",
        "    eng_pad = tf.keras.preprocessing.sequence.pad_sequences(eng_seq, maxlen=11) # 문장길이 통일해줍니다.\n",
        "\n",
        "    fra = []  # 번역: 시점순서에 맞추어 차근차근 단어를 선택하여 담을 공간\n",
        "    for n in range(19-1):\n",
        "        # fra => index => pad\n",
        "        # 첫 루프에는 <sos>만 담겨있습니다.\n",
        "        fra_seq = tokenizer_fr.texts_to_sequences([['<sos>'] + fra]) # 인덱스의 시퀀스로 바꿉니다.\n",
        "        # 문장길이 통일합니다. 문장 앞부분에 0으로 가득차게 됩니다. \n",
        "        # 공부한 전략과 다르지요? 원래는 LSTM 시점 하나하나 조절해야 하는데\n",
        "        # 코드 난이도를 낮추기 위해 변형을 가했습니다.\n",
        "        fra_pad = tf.keras.preprocessing.sequence.pad_sequences(fra_seq, maxlen=19-1) \n",
        "        # 영어문장과, 현재까지 번역한 프랑스어를 input(번역한게 없으면 <sos>만)으로 사용합니다.\n",
        "        # eng_pad는 인코더 인풋으로,  fra_pad는 디코더 인풋으로 갑니다.\n",
        "        fra_next = model.predict([eng_pad, fra_pad]) \n",
        "\n",
        "        # onehot -> index -> word\n",
        "        fra = [tokenizer_fr.index_word[i] for i in np.argmax(fra_next[0], axis=1) if i != 0]\n",
        "        # fra_next는 모든 단어 클래스 별 확률값이 담겨 있고\n",
        "        # 그 중 가장 확률이 높은 단어의 인덱스를 선택하여\n",
        "        # 토큰을 복원하는 과정입니다.\n",
        "        # 그래서 fra 리스트에 선택된 token을 하나하나 담습니다.\n",
        "        # 0번째를 무시하는 이유는 <sos>가 필요없어서!\n",
        "\n",
        "        # 번역된 word 선택\n",
        "        fra = fra[:n+1]\n",
        "        print(fra)  # 무슨 과정이 일어나는지 눈으로 추적 가능\n",
        "        \n",
        "        if fra[-1] == '<eos>':  # 마지막이 eos면 본 과정을 마무리 합니다.\n",
        "            break\n",
        "\n",
        "    return fra\n",
        "\n",
        "# 위 함수를 우리가 배운 전략 그대로 사용하려면\n",
        "# https://tykimos.github.io/2018/09/14/ten-minute_introduction_to_sequence-to-sequence_learning_in_Keras/\n",
        "# 위 링크를 참고하면 좋습니다.\n",
        "# 단... 코드 난이도가 좀 올라갑니다."
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translate(\"I am a boy.\")  # 무슨일이 일어나는지 추적 용도"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykZUSmBrZdPT",
        "outputId": "5194bdce-6116-487c-b2df-b0bf76942172"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 27ms/step\n",
            "['je']\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "['je', 'suis']\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "['je', 'suis', '!']\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "['je', 'suis', '!', '<eos>']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['je', 'suis', '!', '<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUglKyFVQW4y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ca51079-5e56-4f7a-c6cb-0d382375ecf9"
      },
      "source": [
        "import random\n",
        "\n",
        "# 랜덤 10개\n",
        "indices = list(range(50000))\n",
        "random.shuffle(indices)\n",
        "\n",
        "for n in indices[:10]:\n",
        "    print(f\"영어: {eng_sent[n]}\\n불어: {fra_sent[n]}\")\n",
        "    print(f\"번역: {' '.join(translate(eng_sent[n])[:-1])}\")\n",
        "    print()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영어: i nearly starved . \n",
            "불어: <sos> je mourus presque de faim .  <eos>\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "['je']\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "['je', 'suis']\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "['je', 'suis', '!']\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "['je', 'suis', '!', '<eos>']\n",
            "번역: je suis !\n",
            "\n",
            "영어: i was too small . \n",
            "불어: <sos> j ' etais trop petit .  <eos>\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "['j']\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "['j', 'de']\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "['j', 'de', \"'\"]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "['j', 'de', \"'\", 'ete']\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "['j', 'de', \"'\", 'ete', \"'\"]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "['j', 'de', \"'\", 'ete', \"'\", '!']\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "['j', 'de', \"'\", 'ete', \"'\", '!', \"'\"]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "['j', 'de', \"'\", 'ete', \"'\", '!', \"'\", '<eos>']\n",
            "번역: j de ' ete ' ! '\n",
            "\n",
            "영어: have you tried it before ? \n",
            "불어: <sos> l ' as tu essaye auparavant ?  <eos>\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "['tu']\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "['tu', 'tu']\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "['tu', 'tu', '<eos>']\n",
            "번역: tu tu\n",
            "\n",
            "영어: i have to exercise . \n",
            "불어: <sos> j ' ai besoin de m ' exercer .  <eos>\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "['je']\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "['je', 'je']\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "['je', 'je', 'suis']\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "['je', 'je', 'suis', 'suis']\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "['je', 'je', 'suis', 'suis', 'ici']\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "['je', 'je', 'suis', 'suis', 'ici', '!']\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "['je', 'je', 'suis', 'suis', 'ici', '!', '.']\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "['je', 'je', 'suis', 'suis', 'ici', '!', '.', '<eos>']\n",
            "번역: je je suis suis ici ! .\n",
            "\n",
            "영어: dinner is almost ready . \n",
            "불어: <sos> le souper est presque pret .  <eos>\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "['les']\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "['les', '<eos>']\n",
            "번역: les\n",
            "\n",
            "영어: did you get the check ? \n",
            "불어: <sos> avez vous recu la note ?  <eos>\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "['tu']\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "['tu', 'tu']\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "['tu', 'tu', '<eos>']\n",
            "번역: tu tu\n",
            "\n",
            "영어: we kissed each other . \n",
            "불어: <sos> nous nous embrassames .  <eos>\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "['nous']\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "['nous', 'nous']\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "['nous', 'nous', '!']\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "['nous', 'nous', '!', 'en']\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "['nous', 'nous', '!', 'en', '<eos>']\n",
            "번역: nous nous ! en\n",
            "\n",
            "영어: i am from brazil . \n",
            "불어: <sos> je viens du bresil .  <eos>\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "['je']\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "['je', 'suis']\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "['je', 'suis', '!']\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "['je', 'suis', '!', '<eos>']\n",
            "번역: je suis !\n",
            "\n",
            "영어: it was all there . \n",
            "불어: <sos> tout s ' est passe la .  <eos>\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "['c']\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "['c', 'ce']\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "['c', 'ce', \"'\"]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "['c', 'ce', \"'\", 'a']\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "['c', 'ce', \"'\", 'a', \"'\"]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "['c', 'ce', \"'\", 'a', \"'\", 'pas']\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "['c', 'ce', \"'\", 'a', \"'\", 'pas', \"'\"]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "['c', 'ce', \"'\", 'est', \"'\", 'pas', \"'\", '.']\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "['c', 'ce', \"'\", 'est', \"'\", 'pas', \"'\", '!', \"'\"]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "['c', 'ce', \"'\", 'est', \"'\", 'pas', \"'\", '!', \"'\", '<eos>']\n",
            "번역: c ce ' est ' pas ' ! '\n",
            "\n",
            "영어: he is not married . \n",
            "불어: <sos> il n ' est pas marie .  <eos>\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "['il']\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "['il', 'ca']\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "['il', 'ca', 'ne']\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "['il', 'ca', 'ne', '.']\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "['il', 'ca', 'ne', '.', 'l']\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "['il', 'ca', 'ne', '.', 'l', '<eos>']\n",
            "번역: il ca ne . l\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mZSvqaFUdwV"
      },
      "source": [],
      "execution_count": 35,
      "outputs": []
    }
  ]
}