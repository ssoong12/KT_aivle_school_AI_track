{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"0_4_exercise_QA.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMwi64JdjYzjyxT0yd5/J+k"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"IGlWW9jN5e9a"},"source":["# Sequence to Sequence (a.k.a. seq2seq)\r\n","\r\n","**학습목표**\r\n","* Encoder Decoder 구조를 이해하고 구현할 줄 안다.\r\n","* Seq2Seq에 필요한 전처리를 이해한다.\r\n","* **데이터 부족**과, **긴 문장**을 겪어본다.\r\n","\r\n","![이런거](https://raw.githubusercontent.com/KerasKorea/KEKOxTutorial/master/media/28_1.png)\r\n","---------------------------------\r\n","edu.rayleigh@gmail.com\r\n","Special Thanks to : 숙번님 ( [봉수골 개발자 이선비](https://www.youtube.com/channel/UCOAyyrvi7tnCAz7RhH98QCQ) )"]},{"cell_type":"code","metadata":{"id":"Vpud2H-Js6fN"},"source":["url = 'https://raw.githubusercontent.com/kitae104/New_Python/master/Chatbot/data/ChatbotData%20.csv'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z-A2Uf0V-y-W"},"source":["####################\r\n","## Your Code Here ##\r\n","####################\r\n","\r\n","import pandas as pd\r\n","temp = ## 데이터를 불러오시오.\r\n","temp.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0n8j-x_j8rTj"},"source":["temp.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gTTke03auDnt"},"source":["####################\r\n","## Your Code Here ##\r\n","####################\r\n","\r\n","Q_sent =  # 질문 부분을 리스트로 선언\r\n","A_sent =  # 답변 부분을 리스트로 선언"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qntWaQtjSo0U"},"source":["print(Q_sent[1000])\r\n","print(A_sent[1000])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aPU1CYykAdXU"},"source":["# 데이터 준비\r\n","0. 단어와 구두점 사이 공백 만들기\r\n","1. sos 와 eos\r\n","1. tokenizing, idx_seq, padding"]},{"cell_type":"markdown","metadata":{"id":"Fj9FhCC9IgaO"},"source":["## 0. 단어와 구두점 사이 공백 만들기\r\n"]},{"cell_type":"code","metadata":{"id":"Wi0kBaQRIjwB"},"source":["import unicodedata\r\n","import re\r\n","def unicode_to_ascii(s):\r\n","  return ''.join(c for c in unicodedata.normalize('NFD', s)\r\n","      if unicodedata.category(c) != 'Mn')\r\n","\r\n","def preprocessor(sent):\r\n","    # 위에서 구현한 함수를 내부적으로 호출\r\n","    sent = unicode_to_ascii(sent.lower())\r\n","\r\n","    # 단어와 구두점 사이에 공백을 만듭니다.\r\n","    # Ex) \"he is a boy.\" => \"he is a boy .\"\r\n","    sent = re.sub(r\"([?.!,'¿])\", r\" \\1 \", sent)\r\n","\r\n","    sent = re.sub(r\"\\s+\", \" \", sent)\r\n","    return sent"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PjAoavx2IsTj"},"source":["preprocessor(\"나는 멋있어.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yjr_CjB6JFlj"},"source":["####################\r\n","## Your Code Here ##\r\n","####################\r\n","\r\n","A_sent = ## 모든 문장 전처리\r\n","Q_sent = ## 모든 문장 전처리"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2MIrvRfKJOB3"},"source":["print(A_sent[1000])\r\n","print(Q_sent[1000])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3LR2w3i3EJ6c"},"source":["## 1. sos 와 eos\r\n","1. sos : start of speech\r\n","2. eos : end of speech"]},{"cell_type":"code","metadata":{"id":"RFkzszhyDq6E"},"source":["######################\r\n","### Your Code here ###\r\n","######################\r\n","\r\n","## 답변 문장 전 후에 <sos>와 <eos>를 추가할 것\r\n","## 띄어쓰기 주의!\r\n","\r\n","A_sent =  ## 여기에 추가하여 재선언\r\n","A_sent[1000]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zrEhHIQlEU8F"},"source":["## 2. Tokenizing, idx_seq, padding"]},{"cell_type":"code","metadata":{"id":"4-C-zqpSEewe"},"source":["####################\r\n","## Your Code Here ##\r\n","####################\r\n","\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bbf-Y--TEj7Y"},"source":["######################\r\n","### Your Code here ###\r\n","######################\r\n","\r\n","# Tokenizing    # 한국어는 lower = False\r\n","tokenizer_A = \r\n","\r\n","tokenizer_Q = \r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OvDe7BY-F3jB"},"source":["######################\r\n","### Your Code here ###\r\n","######################\r\n","\r\n","# Index Sequence\r\n","A_seq = \r\n","Q_seq = \r\n","\r\n","print(A_seq[1000])\r\n","print(Q_seq[1000])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sadRsDiaJ7p5"},"source":["######################\r\n","### Your Code here ###\r\n","######################\r\n","## 최대 문장 길이에 맞춰지도록 할 것.\r\n","# padding\r\n","A_pad = \r\n","Q_pad = \r\n","\r\n","print(Q_pad.shape)\r\n","print(A_pad.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kW-52MAiKjLW"},"source":["# tokenizer에서 0 index가 구성되어있지 않지만, \r\n","# pad_sequence에서 pad의 의미로 0을 사용하고 있어서, 전체 사이즈를 구할 때, +1을 해준다.\r\n","\r\n","A_vocab_size = len(tokenizer_A.word_index) + 1\r\n","Q_vocab_size = len(tokenizer_Q.word_index) + 1\r\n","print(\"질문 단어 집합의 크기: {:d}\\n답변 단어 집합의 크기: {:d}\".format(Q_vocab_size, A_vocab_size))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"faI0SNWRKr7O"},"source":["# 모델링!\r\n","\r\n","1. 모든 임베딩 레이어는 128개 차원으로 구성.\r\n","2. 인코더도 디코더도 GRU, 히든스테이트 512로 구성.\r\n","3. attention layer 구성\r\n","3. 디코더의 뒤에는 Fully Conneceted layer 사용. 노드 512개, tanh\r\n","4. 적절한 아웃풋레이어\r\n","    * 매 시점, 가장 적절한 단어가 무엇일지 분류 한다고 생각하면 됨!"]},{"cell_type":"code","metadata":{"id":"daSlqB5TK-ua"},"source":["import tensorflow as tf\r\n","from tensorflow.keras.layers import Input, Embedding, GRU"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qHPZhTlXK8Gy"},"source":["######################\r\n","### Your Code here ###\r\n","######################\r\n","\r\n","# 혹시 이미 그려둔 그래프가 있다면 날려줘!\r\n","tf.keras.backend.clear_session()\r\n","\r\n","# 질문 단어 집합의 크기 : 13418, (11823, 16)\r\n","# 답변 단어 집합의 크기 : 9855, (11823, 26)\r\n","# 디코더의 인풋으로 넣을때는 맨 뒤의 <eos>를 떼고 길이 103의 문장을\r\n","# 디코더의 아웃풋은 맨 앞의 <eos>를 떼고 길이 103의 문장으로 준비해야 함.\r\n","\r\n","# Encoder\r\n","\r\n","\r\n","\r\n","\r\n","# Decoder\r\n","\r\n","\r\n","\r\n","\r\n","#####################\r\n","## Attention layer ##\r\n","#####################\r\n","key =         # 인코더의 히든스테이트를 key로 활용한다.\r\n","value =        # 인코더의 히든스테이트를 value로 활용한다.\r\n","query =          # 디코더의 히든스테이트를 query로 활용한다.\r\n","\r\n","# 1. 어텐션 스코어(Attention Score)를 구한다.\r\n","score = \r\n","\r\n","# 2. 소프트맥스(softmax) 함수를 통해 어텐션 분포(Attention Distribution)를 구한다.\r\n","att_dist = \r\n","\r\n","# 3. 각 인코더의 어텐션 가중치와 은닉 상태를 가중합하여 어텐션 값(Attention Value)을 구한다.\r\n","att_value = \r\n","\r\n","# 한줄로 짠다면?\r\n","att_value = \r\n","\r\n","\r\n","# 4. 어텐션 값과 디코더의 t 시점의 은닉 상태를 연결한다.(Concatenate)\r\n","\r\n","\r\n","# 5. 출력층 연산의 입력이 되는 dec_H를 계산.\r\n","\r\n","# 아웃풋 레이어\r\n","\r\n","model = \r\n","\r\n","# 컴파일"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ceSiL3RxNuQE"},"source":["######################\r\n","### Your Code here ###\r\n","######################\r\n","## 학습 시킬 것!\r\n","\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2cHRRLWbOO8Z"},"source":["import numpy as np\r\n","\r\n","# 질문 단어 집합의 크기 : 13418, (11823, 16)\r\n","# 답변 단어 집합의 크기 : 9855, (11823, 26)\r\n","\r\n","def translate(Q):\r\n","    # A => index => pad\r\n","    Q_seq = tokenizer_Q.texts_to_sequences([Q])\r\n","    Q_pad = tf.keras.preprocessing.sequence.pad_sequences(Q_seq, maxlen=16)\r\n","\r\n","    A = []\r\n","    for n in range(26-1):\r\n","        # Q => index => pad\r\n","        A_seq = tokenizer_A.texts_to_sequences([['<sos>'] + A])\r\n","        A_pad = tf.keras.preprocessing.sequence.pad_sequences(A_seq, maxlen=26-1)\r\n","        A_next = model.predict([Q_pad, A_pad])\r\n","\r\n","        # onehot -> index -> word\r\n","        A = [tokenizer_A.index_word[i] for i in np.argmax(A_next[0], axis=1) if i != 0]\r\n","        # 번역된 word 선택\r\n","        A = A[:n+1]\r\n","        \r\n","        if A[-1] == '<eos>':\r\n","            break\r\n","\r\n","    return A"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GUglKyFVQW4y"},"source":["import random\r\n","\r\n","# 랜덤 10개\r\n","indices = list(range(3648))\r\n","random.shuffle(indices)\r\n","\r\n","for n in indices[:10]:\r\n","    print(f\"한국어: {Q_sent[n]}\\n영어: {A_sent[n]}\")\r\n","    print(f\"번역: {' '.join(translate(Q_sent[n])[:-1])}\")\r\n","    print()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3mZSvqaFUdwV"},"source":[""],"execution_count":null,"outputs":[]}]}