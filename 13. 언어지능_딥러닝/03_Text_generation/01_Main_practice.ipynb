{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Main_practice_II.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMiKVvTFzN2x21gvFhreVUh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"auy0rKAs6sBO"},"source":["# Text Generation\n","\n","* 시점별로, 준비된 단어들 중 어떤 단어를 가져와야 적절할지 '선택'하는 문제이다.\n","* 선택이란 곧, 분류이다.( 적절한 선택 or 그렇지 않은 선택들 )\n","* 당연히, 데이터가 엄청 많아야 '작사'다울 수 있다.\n","* 데이터가 부족한 지금은, 모델은 고장난 앵무새일 수 밖에 없다."]},{"cell_type":"markdown","metadata":{"id":"oG-S5Vg78k4b"},"source":["# Data : 야생화, 바람기억, 숨\n","\n","**조건**\n","1. 원하는 노래가사로 변경해도 좋다. 하지만 아래의 포맷을 맞추어 내야 코드를 재사용할 수 있다.\n"]},{"cell_type":"code","metadata":{"id":"VSHqFyu0Bcxa"},"source":["# 처음 설치할때만 실행하고, 그 후에는 주석처리 하세요.\n","!pip install konlpy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4NXFe1T_BdrC"},"source":["import numpy as np\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4PfAFwAl9CCE"},"source":["gasa1 = \"하얗게 피어난 얼음 꽃 하나가\\n달가운 바람에 얼굴을 내밀어\\n아무 말 못했던 이름도 몰랐던\\n지나간 날들에 눈물이 흘러\\n차가운 바람에 숨어 있다\\n한줄기 햇살에 몸 녹이다\\n그렇게 너는 또 한번 내게 온다\\n좋았던 기억만\\n그리운 마음만\\n니가 떠나간 그 길 위에\\n이렇게 남아 서 있다\\n잊혀질 만큼만\\n괜찮을 만큼만\\n눈물 머금고 기다린 떨림 끝에\\n다시 나를 피우리라\\n사랑은 피고 또 지는 타버리는 불꽃\\n빗물에 젖을까 두 눈을 감는다\\n어리고 작았던 나의 맘에\\n눈부시게 빛나던 추억 속에\\n그렇게 너를 또 한번 불러본다\\n좋았던 기억만\\n그리운 마음만\\n니가 떠나간 그 길 위에\\n이렇게 남아 서 있다\\n잊혀질 만큼만\\n괜찮을 만큼만\\n눈물 머금고 기다린 떨림\\n끝에 다시 나는\\n메말라가는 땅 위에\\n온몸이 타 들어가고\\n내 손끝에 남은\\n너의 향기 흩어져 날아가\\n멀어져 가는 너의 손을\\n붙잡지 못해 아프다\\n살아갈 만큼만\\n미워했던 만큼만\\n먼 훗날 너를 데려다 줄\\n그 봄이 오면\\n그날에 나 피우리라\"\n","gasa2 = \"\"\"바람 불어와 내 맘 흔들면\n","지나간 세월에\n","두 눈을 감아본다\n","나를 스치는 고요한 떨림\n","그 작은 소리에\n","난 귀를 기울여 본다\n","내 안에 숨쉬는\n","커버린 삶의 조각들이\n","날 부딪혀 지날 때\n","그 곳을 바라보리라\n","우리의 믿음 우리의 사랑\n","그 영원한 약속들을\n","나 추억한다면 힘차게 걸으리라\n","우리의 만남 우리의 이별\n","그 바래진 기억에\n","나 사랑했다면 미소를 띄우리라\n","내 안에 있는\n","모자란 삶의 기억들이\n","날 부딪혀 지날 때\n","그 곳을 바라보리라\n","우리의 믿음 우리의 사랑\n","그 영원한 약속들을\n","나 추억한다면 힘차게 걸으리라\n","우리의 만남 우리의 이별\n","그 바래진 기억에\n","나 사랑했다면 미소를 띄우리라\"\"\"\n","gasa3 = \"오늘 하루 쉴 숨이\\n오늘 하루 쉴 곳이\\n오늘만큼 이렇게 또 한번 살아가\\n침대 밑에 놓아둔\\n지난 밤에 꾼 꿈이\\n지친 맘을 덮으며\\n눈을 감는다 괜찮아\\n남들과는 조금은 다른 모양 속에\\n나 홀로 잠들어\\n다시 오는 아침에\\n눈을 뜨면 웃고프다\\n오늘 같은 밤\\n이대로 머물러도 될 꿈이라면\\n바랄 수 없는걸 바라도 된다면\\n두렵지 않다면 너처럼\\n오늘 같은 날\\n마른 줄 알았던\\n오래된 눈물이 흐르면\\n잠들지 않는 내 작은 가슴이\\n숨을 쉰다\\n끝도 없이 먼 하늘\\n날아가는 새처럼\\n뒤돌아 보지 않을래\\n이 길 너머 어딘가 봄이\\n힘없이 멈춰있던\\n세상에 비가 내리고\\n다시 자라난 오늘\\n그 하루를 살아\\n오늘 같은 밤\\n이대로 머물러도 될 꿈이라면\\n바랄 수 없는걸 바라도 된다면\\n두렵지 않다면 너처럼\\n오늘 같은 날\\n마른 줄 알았던\\n오래된 눈물이 흐르면\\n잠들지 않는\\n이 어린 가슴이 숨을 쉰다\\n고단했던 내 하루가\\n숨을 쉰다\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9_z9AGKe9Ha5"},"source":["gasa1_ = gasa1.split(\"\\n\")\n","gasa2_ = gasa2.split(\"\\n\")\n","gasa3_ = gasa3.split(\"\\n\")\n","\n","gasa = gasa1_ + gasa2_ + gasa3_"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MzpfezPaBRNB"},"source":["from konlpy.tag import Okt\n","okt = Okt()\n","\n","# 이랬던 문장이.\n","print(\"원본 문장 : \", gasa[1]) \n","\n","# 이렇게 바뀝니다. okt.morphs가 형태소 분석기에요.\n","형태소토큰 = okt.morphs(gasa[1])\n","print(\"형태소 기준으로 tokenize : \", 형태소토큰) \n","\n","# 이러면 배운 대로, 띄어쓰기 기준 token을 사용할 수 있겠죠?\n","다시문장으로 = \" \".join(형태소토큰)\n","print(\"다시 문장으로 : \", 다시문장으로)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-nJaR4u7C-N4"},"source":["# Q1. gasa안의 모든 문장에, 형태소 사이 사이에 띄어쓰기를 추가하라.\n","\n","**힌트**\n","1. 위의 코드를 적극 참고할 것.\n","2. 루프"]},{"cell_type":"code","metadata":{"id":"gPIEw3-RD8cA"},"source":["####################\n","## Your Code here ##\n","####################\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M4AXvSHIEvLz"},"source":["# Q2. gasa를 띄어쓰기 기준으로 tokenize하고, index의 sequence로 바꾸어 내시오.\n","\n","**조건**\n","0. gasa_seq에, index의 seq로 바뀐 가사를 선언해둔다.\n","1. 데이터가 부족하다, 모든 단어 다 사용할 것.\n","2. vocab_size라는 변수에 사용하게 될 token의 수를 선언해두자.\n","    * 힌트1 : 토크나이저.index_word , 인덱스가 몇부터 시작하는가?\n","    * 힌트2 : 패딩, 0을 덧댈것이다. (0이 인덱스이자 덧댐을 의미하는 token이 될 것이다.)\n","    * 힌트3 : embedding 때도, index:0이 필요하다.\n","    * 힌트4 : 원핫인코딩도, 0부터 시작하기 때문에, 0이 필요하다.\n","    * 힌트5 : 심지어, Tokenizer도, num_words = 1000을 둔다면, 상위 999개 token만 사용한다. (우리가 0을 추가로 사용할 것을 가정함. 결국 1000개가 됨.)"]},{"cell_type":"code","metadata":{"id":"bIBL0VxXFknI"},"source":["####################\n","## Your Code here ##\n","####################\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N7pjc7lkN7zp"},"source":["# Q3. gasa_seq안의 모든 문장을 다음과 같이 재구성하시오.\n","\n","**예시**\n","* gasa_seq가 [ [1,2,3], [7,2,9,10] ] 라면\n","* 결과 : gasa_seq = [ [1, 2], [1,2,3], [7,2], [7,2,9], [7,2,9,10] ]\n","* 중간에 다른 변수를 임시로 사용해도 좋다."]},{"cell_type":"code","metadata":{"id":"nQp5KuETN7tp"},"source":["####################\n","## Your Code here ##\n","####################\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y7ygk0ZRKYKz"},"source":["# Q4. gasa_seq안의 가장 긴 문장을 찾고, 그 길이에 맞추어 문장 길이를 통일하시오.\n","\n","**Questions**\n","1. 0을 앞에 덧대야 할까, 뒤에 덧대야 할까?\n","2. 문장의 길이가 매우 길다면, 가장 긴 문장에 맞추어 길이를 통일하는 것이 좋은 방법일까?\n","3. gasa_seq의 shape를 확인하라."]},{"cell_type":"code","metadata":{"id":"hs95h9vnKoR5"},"source":["####################\n","## Your Code here ##\n","####################\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"70Uyq9BXLSQP"},"source":["# Q5. gasa_seq의 마지막 컬럼은 y로, 나머지 컬럼은 x로 분할하라."]},{"cell_type":"code","metadata":{"id":"EfgBcyQ6LiwJ"},"source":["####################\n","## Your Code here ##\n","####################\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"33Q3yVPYNBbT"},"source":["# Q6. y를, vocab_size에 맞추어 원핫 인코딩 하시오.\n","\n","1. num_classes 를 반드시 vocab_size에 맞출 것.\n","2. 사용하지 않을 컬럼이 존재할 수 있다.\n","    * 예시) y에는 4가 없는데, 0으로만 가득찬 4번 컬럼이 만들어질 수도 있다.\n","\n","**추가설명**\n","* 효율을 위해, 이 모든걸 엄격히 보정하여 사용할 수도 있다.\n","* 그러나, 코드가 매우 길어진다.\n","* 데이터가 많아지면, 별차이도 없어진다."]},{"cell_type":"code","metadata":{"id":"CB-od6kqNIfK"},"source":["####################\n","## Your Code here ##\n","####################\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JsdLQENlPMw6"},"source":["# Q7. 문장을 받아, 다음 단어를 선택하는 모델을 만드시오.\n","\n","* 컴파일까지 마치시오.\n","    * 모니터링 지표로 accuracy 사용0\n","* 모델 구조는 아래와 같다.\n","    1. 임베딩 레이어 : 임베딩 차원 32, input_length 주의. gasa_seq를 x와 y로 분할했기 때문에, 문장길이가 달라졌다.\n","    2. GRU, 32, 모든 출력을 다음 layer로\n","    3. GRU, 48, 모든 출력을 다음 layer로\n","    4. GRU, 64, 마지막 출력만 다음 레이어로.\n","    5. 멀티클래스 분류 아웃풋레이어\n"]},{"cell_type":"code","metadata":{"id":"OgoF1sOYRRLP"},"source":["####################\n","## Your Code here ##\n","####################\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PUTNpBU3RcYZ"},"source":["####################\n","## Your Code here ##\n","####################\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P6t4h6owSV_i"},"source":["# Q8. 모델을 학습시킬 것.\n","\n","* batch_size = 64\n","* epochs = 1000\n"]},{"cell_type":"code","metadata":{"id":"A7PfTWSTSckw"},"source":["####################\n","## Your Code here ##\n","####################\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VS6exGm2SjQy"},"source":["# Q9. 학습된 모델을 이용하여, '나'뒤에 생성될 확률이 가장 높은 3개 단어를 출력하시오.\n","\n","1. first_word = ['나'] 을 활용한다.\n","1. 인풋은 똑같은 전처리 과정을 겪어야 한다. (단, 문장 길이는 max_len -1 일것이다. )\n","2. 아웃풋은, 가장 출력값이 큰 3개의 index를 찾아낼 수 있어야 한다.\n","    * np.argsort를 활용해볼 것\n","3. 아웃풋의 index가 정확히 어떤 단어를 가리키는지, 토크나이저의 index_word를 활용하여 복원한다.\n","4. 이후에 나올 단어 3개와, 확률을 print를 이용하여 같이 출력한다."]},{"cell_type":"code","metadata":{"id":"iYLohp-QT4p-"},"source":["####################\n","## Your Code here ##\n","####################\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wg8pRNlbYTxR"},"source":["# Q10. 위의 Q9에서 두번째로 확률이 높은 단어를 골라 문장을 구성한 뒤, 다음에 올 단어로 가장 확률이 높은 3 단어를 출력하시오.\n","\n","1. 만일, 가장 확률 높은 단어가 '추억'이었다면, words = '나 추억' 을 활용한다.\n","1. 확률과 단어를 같이 출력한다.\n","2. 기본적으로는 위 Q9번과 동일하게 푼다."]},{"cell_type":"code","metadata":{"id":"CgN3VEJdaIwG"},"source":["####################\n","## Your Code here ##\n","####################\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G2bX0Y2rakmm"},"source":["# Q11. 9번,10번 문항을 참고하여, 다음의 기능을 하는 함수를 제작한다.\n","\n","* 편의를 위해, 외부에 선언된 변수를 활용해도 좋다.\n","* 인풋 : 사용할 첫 단어, 반복 예측 수\n","* 내부 : 매번 가장 확률 높은 단어만 선택한다.\n","* 아웃풋 : 완성된 문장.\n","* 예시 :\n","```\n","jaksa(\"나\", 4 )\n",">> \"나 추억 한다면 힘차게 걸으리라\"\n","```\n","* 실제로 노래 가사에 사용된 여러 단어를 넣어 테스트해보자."]},{"cell_type":"code","metadata":{"id":"31oEHOLdcK6f"},"source":["####################\n","## Your Code here ##\n","####################\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZvCcvnmfdR_v"},"source":["#######################\n","## Your testing here ##\n","#######################\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KXJqN747cLzh"},"source":["# (+Optional)Q12. Q11번 함수를 개량하여 다듬는다.\n","\n","* 인풋 : 사용할 첫 단어, 반복 예측 수, 사용할 모델, 사용할 tokenizer\n","* 내부 : 모든 예측 중 하나를 확률에 맞추어 sampling 한다.\n","    * np.random.choice 이용. 만일 '바람'일 확률이 80%라면, 100번에 80번 정도는 바람이, 20번 정도는 다른 단어가 선택될 것이다.\n","* 아웃풋 : 완성된 문장.\n","* 반복 예측 수 : 7이상이면 다음의 문구를 출력하고 함수 동작을 종료한다.\n","    * \"6이하의 반복예측만 가능합니다.\"\n","* 예시 :\n","```\n","jaksa(\"나\", 4, tk, model )\n",">> \"나 추억 한다면 힘차게 걸으리라\"\n","jaksa(\"나\", 4, tk, model )\n",">> \"나 사랑 했다면 미소 를\"\n","```"]},{"cell_type":"code","metadata":{"id":"MucjnWmFeuKp"},"source":["####################\n","## Your Code here ##\n","####################\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"97Jg0snLffn-"},"source":["#######################\n","## Your testing here ##\n","#######################\n","\n","\n"],"execution_count":null,"outputs":[]}]}