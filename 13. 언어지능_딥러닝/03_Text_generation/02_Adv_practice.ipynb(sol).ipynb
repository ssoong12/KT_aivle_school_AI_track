{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Adv_practice_II(sol).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPZ6mcQoIkmUZMoWb/2TYA2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"auy0rKAs6sBO"},"source":["# Text Generation\n","\n","* 게임플랫폼 '스팀'의 리뷰 생성기를 제작해보자."]},{"cell_type":"markdown","metadata":{"id":"oG-S5Vg78k4b"},"source":["# Data : Steam reviews\n"]},{"cell_type":"code","metadata":{"id":"VSHqFyu0Bcxa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628059052122,"user_tz":-540,"elapsed":2961,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}},"outputId":"8bf2ed28-3a68-41aa-8e9c-b76592f38037"},"source":["# 처음 설치할때만 실행하고, 그 후에는 주석처리 하세요.\n","!pip install konlpy"],"execution_count":120,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.5.2)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from konlpy) (0.4.4)\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n","Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.6.0)\n","Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n","Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.3.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n","Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4NXFe1T_BdrC","executionInfo":{"status":"ok","timestamp":1628059052123,"user_tz":-540,"elapsed":3,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}}},"source":["import numpy as np\n","import pandas as pd"],"execution_count":121,"outputs":[]},{"cell_type":"code","metadata":{"id":"SDHckWpxlzCH","executionInfo":{"status":"ok","timestamp":1628059052523,"user_tz":-540,"elapsed":402,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}}},"source":["url = 'https://raw.githubusercontent.com/bab2min/corpus/master/sentiment/steam.txt'\n","data= pd.read_table(url, names=['label', 'reviews'])"],"execution_count":122,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j173CbPcl5kX"},"source":["# Q1. data안의 'reviews'만 가져와 전처리 하시오.\n","\n","1. 'reviews'컬럼만 사용한다.\n","2. 'reviews'의 문장들을 하나의 list로 담는다.\n","3. reviews에 선언한다.\n","4. 처음 10000개 문장만 사용하기로 한다.(그렇지 않으면 매우 느려진다.)"]},{"cell_type":"code","metadata":{"id":"NCR-SxrNl5cf","executionInfo":{"status":"ok","timestamp":1628059052524,"user_tz":-540,"elapsed":2,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}}},"source":["####################\n","## Your Code here ##\n","####################\n","\n","reviews = data['reviews'].tolist()[:10000]"],"execution_count":123,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-nJaR4u7C-N4"},"source":["# (+optional)Q2. reviews안의 모든 문장에, 형태소 사이 사이에 띄어쓰기를 추가하라.\n","\n","* 없이 진행해보고, 나중에 추가하여 비교해보자.\n","* konlpy의 Okt를 사용한다.\n","* 시간이 꽤 걸릴 수 있으니, 처음에는 정상적으로 루프가 동작하는지 처음 10개 리뷰만 가지고 테스팅해가며 진행한다.\n","* 전체 문장을 전부 진행할경우, 약 1~2분 정도 걸린다."]},{"cell_type":"code","metadata":{"id":"gPIEw3-RD8cA","executionInfo":{"status":"ok","timestamp":1628059052524,"user_tz":-540,"elapsed":2,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}}},"source":["# %%time\n","\n","# ####################\n","# ## Your Code here ##\n","# ####################\n","# from konlpy.tag import Okt\n","# okt = Okt()\n","\n","\n","# print(\"변경 전 :\", reviews[5])\n","\n","# for idx, sentence in enumerate(reviews) :\n","#     reviews[idx] = \" \".join( okt.morphs(sentence)  )\n","\n","# print(\"변경 후 :\", reviews[5])\n"],"execution_count":124,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M4AXvSHIEvLz"},"source":["# Q3. reviews를 띄어쓰기 기준으로 tokenize하고, index의 sequence로 바꾸어 내시오.\n","\n","**조건**\n","* revews_seq 에 선언해둔다.\n","* 패딩에 사용할 0을 포함하여, 상위 20000개 단어를 사용하자.\n","    * tokenizer는 num_words에 20000을 주면, 사용자가 0을 사용할 것을 감안하여 상위 1999개만 추려준다.  패딩 포함하면 자동으로 20000개가 된다.\n","    * max_words = 20000 을 활용한다."]},{"cell_type":"code","metadata":{"id":"bIBL0VxXFknI","executionInfo":{"status":"ok","timestamp":1628059052881,"user_tz":-540,"elapsed":359,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}}},"source":["####################\n","## Your Code here ##\n","####################\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","max_words = 20000\n","\n","tk = Tokenizer(num_words=max_words)\n","tk.fit_on_texts(reviews)\n","reviews_seq = tk.texts_to_sequences(reviews)"],"execution_count":125,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rVXk8HqXpZVP"},"source":["# Q4.reviews_seq 에서 길이가 2이하인 seq를 제거하시오.\n","\n","* 그대로 다시 reviews_seq에 선언한다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Pb9VBD_pUzA","executionInfo":{"status":"ok","timestamp":1628059052881,"user_tz":-540,"elapsed":4,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}},"outputId":"2b99382c-0886-44c8-821d-a09985c435a3"},"source":["reviews_seq = [ seq for seq in reviews_seq if len(seq)>=3 ]\n","\n","reviews_seq[:6]"],"execution_count":126,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[1229, 2, 1762],\n"," [10391, 13, 10392, 2472, 5838, 1763, 10393, 1764],\n"," [5839, 5840, 5839, 10394, 3075, 21, 10395, 766],\n"," [4007, 4007, 4007, 11, 4008, 5841, 10396, 7, 5842],\n"," [133, 10397, 139, 1116, 10398, 10, 1765, 7, 344],\n"," [95, 826, 2473, 498, 2474, 3076, 5843, 10399, 452]]"]},"metadata":{"tags":[]},"execution_count":126}]},{"cell_type":"markdown","metadata":{"id":"N7pjc7lkN7zp"},"source":["# Q5. reviews_seq안의 모든 문장을 다음과 같이 재구성하시오.\n","\n","**예시**\n","* reviews_seq가 [ [1,2,3], [7,2,9,10] ] 라면\n","* 결과 : reviews_seq = [ [1, 2], [1,2,3], [7,2], [7,2,9], [7,2,9,10] ]\n","* 중간에 다른 변수를 임시로 사용해도 좋다."]},{"cell_type":"code","metadata":{"id":"nQp5KuETN7tp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628059053218,"user_tz":-540,"elapsed":339,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}},"outputId":"c8490881-095d-4b83-d4f4-277962caf191"},"source":["####################\n","## Your Code here ##\n","####################\n","\n","temp_ = []\n","\n","for seq in reviews_seq :\n","    for i in range(1, len(seq)):\n","        temp_.append( seq[:i+1]    )\n","\n","reviews_seq = temp_\n","reviews_seq[:10]\n"],"execution_count":127,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[1229, 2],\n"," [1229, 2, 1762],\n"," [10391, 13],\n"," [10391, 13, 10392],\n"," [10391, 13, 10392, 2472],\n"," [10391, 13, 10392, 2472, 5838],\n"," [10391, 13, 10392, 2472, 5838, 1763],\n"," [10391, 13, 10392, 2472, 5838, 1763, 10393],\n"," [10391, 13, 10392, 2472, 5838, 1763, 10393, 1764],\n"," [5839, 5840]]"]},"metadata":{"tags":[]},"execution_count":127}]},{"cell_type":"markdown","metadata":{"id":"y7ygk0ZRKYKz"},"source":["# Q6. reviews_seq안의 seq의 길이를 통일하시오.\n","\n","**Questions**\n","1. 0을 앞에 덧대야 할까, 뒤에 덧대야 할까?\n","2. max_len = 11 ( x로 활용할 10, y로 활용할 1 )\n","3. reviews_seq의 shape를 확인하라."]},{"cell_type":"code","metadata":{"id":"hs95h9vnKoR5","executionInfo":{"status":"ok","timestamp":1628059053484,"user_tz":-540,"elapsed":267,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}}},"source":["####################\n","## Your Code here ##\n","####################\n","\n","\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","max_len = 10 + 1\n","\n","reviews_seq = pad_sequences(reviews_seq, maxlen=max_len, padding='pre')"],"execution_count":128,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3tJvDxo3qqR9","executionInfo":{"status":"ok","timestamp":1628059053485,"user_tz":-540,"elapsed":5,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}},"outputId":"e8604e55-5f19-4cca-978a-4b46ba47d52c"},"source":["reviews_seq.shape"],"execution_count":129,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(73484, 11)"]},"metadata":{"tags":[]},"execution_count":129}]},{"cell_type":"markdown","metadata":{"id":"70Uyq9BXLSQP"},"source":["# Q7. reviews_seq의 마지막 컬럼은 y로, 나머지 컬럼은 x로 분할하라."]},{"cell_type":"code","metadata":{"id":"EfgBcyQ6LiwJ","executionInfo":{"status":"ok","timestamp":1628059053485,"user_tz":-540,"elapsed":2,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}}},"source":["####################\n","## Your Code here ##\n","####################\n","\n","x = reviews_seq[:, :-1]\n","y = reviews_seq[:, -1]\n"],"execution_count":130,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"33Q3yVPYNBbT"},"source":["# 주의. y를 원핫 인코딩 하지 않을 예정. 메모리가 버티지 못할 수 있다."]},{"cell_type":"markdown","metadata":{"id":"JsdLQENlPMw6"},"source":["# Q8. 문장을 받아, 다음 단어를 선택하는 모델을 만드시오.\n","\n","* 컴파일까지 마치시오.\n","    * 모니터링 지표로 accuracy 사용\n","    * loss 를 sparse_categorical_crossentropy를 사용해야만, y를 원핫인코딩 하지 않고도 학습시킬 수 있다.\n","* 모델 구조는 아래와 같다.\n","    1. 임베딩 레이어 : 임베딩 차원 256, 문장길이 10\n","    2. GRU, 128, 모든 출력을 다음 layer로\n","    3. GRU, 128, 모든 출력을 다음 layer로\n","    4. MaxPool1D, 필터사이즈 2\n","    4. GRU, 256, 모든 출력만 다음 레이어로.\n","    4. GRU, 256, 모든 출력만 다음 레이어로.\n","    4. MaxPool1D, 필터사이즈 2\n","    4. GRU, 512, 마지막 출력만 다음 레이어로.\n","    5. 멀티클래스(max_words만큼)분류하는 아웃풋레이어\n"]},{"cell_type":"code","metadata":{"id":"OgoF1sOYRRLP","executionInfo":{"status":"ok","timestamp":1628059053485,"user_tz":-540,"elapsed":2,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}}},"source":["####################\n","## Your Code here ##\n","####################\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import GRU, Embedding, Dense, MaxPool1D"],"execution_count":131,"outputs":[]},{"cell_type":"code","metadata":{"id":"PUTNpBU3RcYZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628059055208,"user_tz":-540,"elapsed":1725,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}},"outputId":"a9044e86-e474-4b55-8613-329108463338"},"source":["####################\n","## Your Code here ##\n","####################\n","\n","keras.backend.clear_session()\n","\n","model = keras.models.Sequential()\n","\n","model.add( keras.layers.Embedding(input_dim = max_words,\n","                                  output_dim = 256,\n","                                  input_length = 10 ))\n","model.add( GRU(128, return_sequences=True) )\n","model.add( GRU(128, return_sequences=True) )\n","model.add( MaxPool1D( 2 ) )\n","model.add( GRU(256, return_sequences=True) )\n","model.add( GRU(256, return_sequences=True) )\n","model.add( MaxPool1D( 2 ) )\n","model.add( GRU(512, return_sequences=False) )\n","model.add( Dense( max_words, activation='softmax' ))\n","\n","model.compile( loss = 'sparse_categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])\n","\n","model.summary()"],"execution_count":132,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, 10, 256)           5120000   \n","_________________________________________________________________\n","gru (GRU)                    (None, 10, 128)           148224    \n","_________________________________________________________________\n","gru_1 (GRU)                  (None, 10, 128)           99072     \n","_________________________________________________________________\n","max_pooling1d (MaxPooling1D) (None, 5, 128)            0         \n","_________________________________________________________________\n","gru_2 (GRU)                  (None, 5, 256)            296448    \n","_________________________________________________________________\n","gru_3 (GRU)                  (None, 5, 256)            394752    \n","_________________________________________________________________\n","max_pooling1d_1 (MaxPooling1 (None, 2, 256)            0         \n","_________________________________________________________________\n","gru_4 (GRU)                  (None, 512)               1182720   \n","_________________________________________________________________\n","dense (Dense)                (None, 20000)             10260000  \n","=================================================================\n","Total params: 17,501,216\n","Trainable params: 17,501,216\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"P6t4h6owSV_i"},"source":["# Q8. 모델을 학습시킬 것.\n","\n","* batch_size = 1024\n","* epochs = 60\n"]},{"cell_type":"code","metadata":{"id":"A7PfTWSTSckw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628059569980,"user_tz":-540,"elapsed":514773,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}},"outputId":"172540f7-e476-41a7-9592-7a6a7592ba8e"},"source":["####################\n","## Your Code here ##\n","####################\n","\n","model.fit(x, y, epochs=60, batch_size=1024, verbose=1)"],"execution_count":133,"outputs":[{"output_type":"stream","text":["Epoch 1/60\n","72/72 [==============================] - 21s 114ms/step - loss: 9.2779 - accuracy: 0.0173\n","Epoch 2/60\n","72/72 [==============================] - 8s 112ms/step - loss: 8.7870 - accuracy: 0.0178\n","Epoch 3/60\n","72/72 [==============================] - 8s 112ms/step - loss: 8.7210 - accuracy: 0.0178\n","Epoch 4/60\n","72/72 [==============================] - 8s 112ms/step - loss: 8.6777 - accuracy: 0.0178\n","Epoch 5/60\n","72/72 [==============================] - 8s 113ms/step - loss: 8.6114 - accuracy: 0.0177\n","Epoch 6/60\n","72/72 [==============================] - 8s 114ms/step - loss: 8.5335 - accuracy: 0.0178\n","Epoch 7/60\n","72/72 [==============================] - 8s 114ms/step - loss: 8.4659 - accuracy: 0.0179\n","Epoch 8/60\n","72/72 [==============================] - 8s 113ms/step - loss: 8.3928 - accuracy: 0.0180\n","Epoch 9/60\n","72/72 [==============================] - 8s 113ms/step - loss: 8.3020 - accuracy: 0.0182\n","Epoch 10/60\n","72/72 [==============================] - 8s 113ms/step - loss: 8.1960 - accuracy: 0.0185\n","Epoch 11/60\n","72/72 [==============================] - 8s 114ms/step - loss: 8.0670 - accuracy: 0.0192\n","Epoch 12/60\n","72/72 [==============================] - 8s 114ms/step - loss: 7.9191 - accuracy: 0.0196\n","Epoch 13/60\n","72/72 [==============================] - 8s 113ms/step - loss: 7.7489 - accuracy: 0.0204\n","Epoch 14/60\n","72/72 [==============================] - 8s 111ms/step - loss: 7.5629 - accuracy: 0.0228\n","Epoch 15/60\n","72/72 [==============================] - 8s 111ms/step - loss: 7.3717 - accuracy: 0.0247\n","Epoch 16/60\n","72/72 [==============================] - 8s 112ms/step - loss: 7.1658 - accuracy: 0.0286\n","Epoch 17/60\n","72/72 [==============================] - 8s 113ms/step - loss: 6.9649 - accuracy: 0.0345\n","Epoch 18/60\n","72/72 [==============================] - 8s 112ms/step - loss: 6.7522 - accuracy: 0.0438\n","Epoch 19/60\n","72/72 [==============================] - 8s 114ms/step - loss: 6.5408 - accuracy: 0.0570\n","Epoch 20/60\n","72/72 [==============================] - 8s 114ms/step - loss: 6.3291 - accuracy: 0.0741\n","Epoch 21/60\n","72/72 [==============================] - 8s 113ms/step - loss: 6.1098 - accuracy: 0.0991\n","Epoch 22/60\n","72/72 [==============================] - 8s 112ms/step - loss: 5.9005 - accuracy: 0.1260\n","Epoch 23/60\n","72/72 [==============================] - 8s 111ms/step - loss: 5.7006 - accuracy: 0.1528\n","Epoch 24/60\n","72/72 [==============================] - 8s 111ms/step - loss: 5.5113 - accuracy: 0.1798\n","Epoch 25/60\n","72/72 [==============================] - 8s 112ms/step - loss: 5.3307 - accuracy: 0.2075\n","Epoch 26/60\n","72/72 [==============================] - 8s 112ms/step - loss: 5.1594 - accuracy: 0.2346\n","Epoch 27/60\n","72/72 [==============================] - 8s 114ms/step - loss: 4.9986 - accuracy: 0.2572\n","Epoch 28/60\n","72/72 [==============================] - 8s 114ms/step - loss: 4.8582 - accuracy: 0.2787\n","Epoch 29/60\n","72/72 [==============================] - 8s 113ms/step - loss: 4.7126 - accuracy: 0.2995\n","Epoch 30/60\n","72/72 [==============================] - 8s 112ms/step - loss: 4.5832 - accuracy: 0.3199\n","Epoch 31/60\n","72/72 [==============================] - 8s 113ms/step - loss: 4.4650 - accuracy: 0.3390\n","Epoch 32/60\n","72/72 [==============================] - 8s 112ms/step - loss: 4.3518 - accuracy: 0.3544\n","Epoch 33/60\n","72/72 [==============================] - 8s 112ms/step - loss: 4.2481 - accuracy: 0.3697\n","Epoch 34/60\n","72/72 [==============================] - 8s 112ms/step - loss: 4.1457 - accuracy: 0.3860\n","Epoch 35/60\n","72/72 [==============================] - 8s 115ms/step - loss: 4.0600 - accuracy: 0.3988\n","Epoch 36/60\n","72/72 [==============================] - 8s 114ms/step - loss: 3.9601 - accuracy: 0.4153\n","Epoch 37/60\n","72/72 [==============================] - 8s 113ms/step - loss: 3.8713 - accuracy: 0.4307\n","Epoch 38/60\n","72/72 [==============================] - 8s 111ms/step - loss: 3.7914 - accuracy: 0.4418\n","Epoch 39/60\n","72/72 [==============================] - 8s 112ms/step - loss: 3.7089 - accuracy: 0.4558\n","Epoch 40/60\n","72/72 [==============================] - 8s 112ms/step - loss: 3.6380 - accuracy: 0.4671\n","Epoch 41/60\n","72/72 [==============================] - 8s 112ms/step - loss: 3.5733 - accuracy: 0.4782\n","Epoch 42/60\n","72/72 [==============================] - 8s 111ms/step - loss: 3.5004 - accuracy: 0.4899\n","Epoch 43/60\n","72/72 [==============================] - 8s 112ms/step - loss: 3.4395 - accuracy: 0.5013\n","Epoch 44/60\n","72/72 [==============================] - 8s 114ms/step - loss: 3.3803 - accuracy: 0.5101\n","Epoch 45/60\n","72/72 [==============================] - 8s 114ms/step - loss: 3.3216 - accuracy: 0.5205\n","Epoch 46/60\n","72/72 [==============================] - 8s 112ms/step - loss: 3.2667 - accuracy: 0.5304\n","Epoch 47/60\n","72/72 [==============================] - 8s 112ms/step - loss: 3.2137 - accuracy: 0.5399\n","Epoch 48/60\n","72/72 [==============================] - 8s 111ms/step - loss: 3.1684 - accuracy: 0.5486\n","Epoch 49/60\n","72/72 [==============================] - 8s 112ms/step - loss: 3.1179 - accuracy: 0.5550\n","Epoch 50/60\n","72/72 [==============================] - 8s 111ms/step - loss: 3.0738 - accuracy: 0.5631\n","Epoch 51/60\n","72/72 [==============================] - 8s 114ms/step - loss: 3.0357 - accuracy: 0.5685\n","Epoch 52/60\n","72/72 [==============================] - 8s 114ms/step - loss: 2.9903 - accuracy: 0.5773\n","Epoch 53/60\n","72/72 [==============================] - 8s 114ms/step - loss: 2.9443 - accuracy: 0.5855\n","Epoch 54/60\n","72/72 [==============================] - 8s 112ms/step - loss: 2.9054 - accuracy: 0.5934\n","Epoch 55/60\n","72/72 [==============================] - 8s 114ms/step - loss: 2.8727 - accuracy: 0.5985\n","Epoch 56/60\n","72/72 [==============================] - 8s 114ms/step - loss: 2.8412 - accuracy: 0.6039\n","Epoch 57/60\n","72/72 [==============================] - 8s 114ms/step - loss: 2.8045 - accuracy: 0.6092\n","Epoch 58/60\n","72/72 [==============================] - 8s 112ms/step - loss: 2.7732 - accuracy: 0.6161\n","Epoch 59/60\n","72/72 [==============================] - 8s 112ms/step - loss: 2.7457 - accuracy: 0.6200\n","Epoch 60/60\n","72/72 [==============================] - 8s 111ms/step - loss: 2.7099 - accuracy: 0.6271\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fc5769b9510>"]},"metadata":{"tags":[]},"execution_count":133}]},{"cell_type":"markdown","metadata":{"id":"KXJqN747cLzh"},"source":["# (+권장)Q9. 다음의 함수를 제작한다.\n","\n","* 인풋 : 사용할 첫 단어, 반복 예측 수, 사용할 모델, 사용할 tokenizer\n","* 내부 : 모든 예측 중 하나를 확률에 맞추어 sampling 한다.\n","    * np.random.choice 이용. 만일 '바람'일 확률이 80%라면, 100번에 80번 정도는 바람이, 20번 정도는 다른 단어가 선택될 것이다.\n","* 아웃풋 : 완성된 문장.\n","* 반복 예측 수 : 9이상이면 다음의 문구를 출력하고 함수 동작을 종료한다.\n","    * \"8이하의 반복예측만 가능합니다.\"\n","* 예시 :\n","```\n","reviewer(\"나\", 4, tk, model )\n",">> \"나 추억 한다면 힘차게 걸으리라\"\n","reviewer(\"나\", 4, tk, model )\n",">> \"나 사랑 했다면 미소 를\"\n","```"]},{"cell_type":"code","metadata":{"id":"MucjnWmFeuKp","executionInfo":{"status":"ok","timestamp":1628059569980,"user_tz":-540,"elapsed":9,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}}},"source":["####################\n","## Your Code here ##\n","####################\n","\n","def reviewer( word, n_iter, tk, model):\n","    if n_iter >= 9 :\n","        print(\"6이하의 반복 예측만 가능합니다.\")\n","    else : \n","        for i in range( n_iter ) :\n","            words = [word]\n","            seq_ = tk.texts_to_sequences(words)\n","            seq_ = pad_sequences(seq_, maxlen=max_len-1, padding='pre')\n","            pred_ = model.predict(seq_, )\n","            selected_idx = np.random.choice(max_words, p = pred_.reshape(-1))\n","            next_word = tk.index_word[ selected_idx ]\n","\n","            word = word + \" \" + next_word\n","        return word"],"execution_count":134,"outputs":[]},{"cell_type":"code","metadata":{"id":"97Jg0snLffn-","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1628059713432,"user_tz":-540,"elapsed":671,"user":{"displayName":"Rayleigh Kim","photoUrl":"","userId":"07970978477328976416"}},"outputId":"4e8c72b0-509b-4f48-bfa8-1cef6691b0e2"},"source":["#######################\n","## Your testing here ##\n","#######################\n","reviewer(\"나\", 7, tk, model)"],"execution_count":138,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'나 1 포기 게임 2판 사셈 시뮬레이팅 그만큼'"]},"metadata":{"tags":[]},"execution_count":138}]}]}