{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **저시력자를 위한 원화 화폐 분류**\n","---\n","- 본 과제는 UltraLytics YOLO v5 모델 사용을 권장합니다.\n","    - 본 파일의 목차는 UltraLytics YOLO v5에 맞게 작성되어 있습니다.\n","    - 다른 모델을 찾아서 사용하셔도 좋습니다.\n","    - 산출물이 잘 나오면 됩니다 : )\n","---"],"metadata":{"id":"XT7PRhnMf-kI"}},{"cell_type":"markdown","source":["## 0.미션\n","---\n","- **과제 수행 목표**\n","    - 본 과제는 Object Detection 문제입니다.\n","    - Object Detection 문제로 접근하기 위해 **데이터셋 전처리**를 하셔야 합니다.\n","    - 데이터셋 : money_dataset.zip\n","        1. 데이터셋은 압축 파일로 제공됩니다.\n","        2. 압축 파일 안에는 화폐마다 폴더가 개별적으로 존재합니다.\n","        3. 폴더 안에는 화폐 이미지와 화폐 정보가 담긴 json 파일이 있습니다.\n","    - 여러분이 직접 촬영한 화폐 사진들을 탐지 과정에서 이용 해보세요.\n","    - 이미지에 화폐 하나만 나오게 촬영하는 것은 지양해주세요.\n","    - 다양한 방법으로 화폐를 촬영하고 결과를 확인해보세요.\n","        - ex 1) 화폐의 모든 종류를 한 이미지에 나오게 촬영\n","        - ex 2) 여러 화폐를 겹치게 하여 촬영\n","---\n","- **Key Point**\n","    1. 모델에 맞는 폴더 구조 확인\n","    2. 이미지 축소 비율에 맞춰 좌표값 변경\n","        - 좌표를 이미지 리사이즈한 비율로 변경\n","    3. 모델에 맞는 정보 추출/형식 변경\n","        - json 파일에서 정보 추출 및 모델 형식에 맞게 변경\n","    4. 화폐당 하나의 클래스로 변경\n","        - 총 8개 클래스\n","    5. 모델 선택 필요\n","---"],"metadata":{"id":"47D2vGDYdCOz"}},{"cell_type":"markdown","source":["## 1.환경설정"],"metadata":{"id":"aZon1K-Ag9be"}},{"cell_type":"markdown","source":["### (1) 구글 드라이브 연동\n","---\n","- 아래의 코드 셀을 반드시 실행시켜야 합니다.\n","---"],"metadata":{"id":"CMgnHN9ZBF05"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"id":"xCplyiojBFwh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679641696555,"user_tz":-540,"elapsed":24810,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}},"outputId":"692254c3-211d-484d-d3f9-ca2982967341"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"markdown","source":["### (2) 데이터셋 불러오기\n","---\n","- **세부요구사항**\n","    - 데이터셋 파일의 압축을 해제하세요.\n","---\n","- 예제 코드에서는 zipfile 모듈을 이용하였습니다.\n","    - [zipfile document](https://docs.python.org/3/library/zipfile.html#zipfile-objects)\n","    - 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n","---"],"metadata":{"id":"J8vjv0acBAV4"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"bkSa5ejf8LMe","executionInfo":{"status":"ok","timestamp":1679641696556,"user_tz":-540,"elapsed":5,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"outputs":[],"source":["import zipfile\n","import os"]},{"cell_type":"code","source":["path = '/content/drive/MyDrive/Datasets/'"],"metadata":{"id":"IDEKV5NoxPiJ","executionInfo":{"status":"ok","timestamp":1679641696557,"user_tz":-540,"elapsed":5,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# 데이터셋 압축 파일 경로 : 유저별로 상이할 수 있음\n","money_data = zipfile.ZipFile(path + 'money_dataset.zip')"],"metadata":{"id":"N4cdpkRv86QQ","executionInfo":{"status":"ok","timestamp":1679641698557,"user_tz":-540,"elapsed":2005,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["!mkdir /content/Dataset/"],"metadata":{"id":"csXuHldPyqqY","executionInfo":{"status":"ok","timestamp":1679641698558,"user_tz":-540,"elapsed":10,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# 데이터셋 압축 해제\n","money_data.extractall('/content/Dataset/money_data/')"],"metadata":{"id":"TDAyDRLT9hZS","executionInfo":{"status":"ok","timestamp":1679641713950,"user_tz":-540,"elapsed":15399,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# 전체 이미지 갯수를 확인합니다.\n","print(len(os.listdir('/content/Dataset/money_data/10')))\n","print(len(os.listdir('/content/Dataset/money_data/100')))\n","print(len(os.listdir('/content/Dataset/money_data/1000')))\n","print(len(os.listdir('/content/Dataset/money_data/10000')))\n","print(len(os.listdir('/content/Dataset/money_data/50')))\n","print(len(os.listdir('/content/Dataset/money_data/500')))\n","print(len(os.listdir('/content/Dataset/money_data/5000')))\n","print(len(os.listdir('/content/Dataset/money_data/50000')))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3iSY-teEEIyU","executionInfo":{"status":"ok","timestamp":1679641713951,"user_tz":-540,"elapsed":9,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}},"outputId":"2ab081c2-a07f-4413-a7d8-affea34bfa2b"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["872\n","880\n","1716\n","1734\n","880\n","880\n","1734\n","1740\n"]}]},{"cell_type":"markdown","source":["## 2.데이터 전처리"],"metadata":{"id":"QyEd-WNIhoSc"}},{"cell_type":"markdown","source":["### (1) 폴더 구조 생성 및 파일 이동\n","---\n","- **세부요구사항**\n","    -  모델에서 요구하는 폴더 구조를 만들어야 합니다.\n","        - Hint : Image와 Label을 구분하는 폴더를 만들어 주세요\n","---\n","- 예제 코드에서는 glob, shutil 모듈을 이용하였습니다.\n","    - [glob document](https://docs.python.org/3/library/glob.html) | [shutil document](https://docs.python.org/3/library/shutil.html)\n","    - 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n","---"],"metadata":{"id":"P81d6utx-3LY"}},{"cell_type":"code","source":["# 1.폴더 구조 만들기\n","!mkdir /content/Dataset;\n","!mkdir /content/Dataset/images;\n","!mkdir /content/Dataset/images/train; mkdir /content/Dataset/images/val\n","\n","!mkdir /content/Dataset/labels;\n","!mkdir /content/Dataset/labels/train_raw; mkdir /content/Dataset/labels/val_raw"],"metadata":{"id":"YBqCJU5z_UI8","executionInfo":{"status":"ok","timestamp":1679641714971,"user_tz":-540,"elapsed":1025,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"cef97c06-439e-4647-c113-d78666f08801"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["mkdir: cannot create directory ‘/content/Dataset’: File exists\n"]}]},{"cell_type":"code","source":["import glob, shutil"],"metadata":{"id":"UuchlNA_DftJ","executionInfo":{"status":"ok","timestamp":1679641714972,"user_tz":-540,"elapsed":7,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# 2. Dataset metadata 입력\n","won_list = ['10', '50', '100', '500', '1000', '5000', '10000', '50000']\n","data_path = '/content/Dataset/'"],"metadata":{"id":"Q3lnYcLS_UOy","executionInfo":{"status":"ok","timestamp":1679641714972,"user_tz":-540,"elapsed":7,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["---\n","- 데이터를 Training set | Validation set으로 분할하세요.\n","    - 예시 : Training과 Validation은 8:2로 분리\n","- Hint : 이미지 데이터는 /images에, JSON 데이터는 /labels에 넣어주세요\n","    - 예시 : /dataset/images/train, /dataset/labels/train\n","    - 예제 코드에서는 glob, shutil 모듈을 이용하였습니다.\n","    - [glob document](https://docs.python.org/3/library/glob.html) | [shutil document](https://docs.python.org/3/library/shutil.html)\n","\n","    ※ 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n","    \n","---"],"metadata":{"id":"ihJgeqXJG1Ml"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from PIL import  Image\n","import json\n","import os"],"metadata":{"id":"maK5sYxx1HEA","executionInfo":{"status":"ok","timestamp":1679641715475,"user_tz":-540,"elapsed":508,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# for won in won_list:\n","#  print(won)"],"metadata":{"id":"V_odcYVx3lD3","executionInfo":{"status":"ok","timestamp":1679641715475,"user_tz":-540,"elapsed":6,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["print(len(os.listdir('/content/Dataset/images/train')))\n","print(len(os.listdir('/content/Dataset/labels/train_raw')))\n","print(len(os.listdir('/content/Dataset/images/val')))\n","print(len(os.listdir('/content/Dataset/labels/val_raw')))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jlw_1pAfTd89","executionInfo":{"status":"ok","timestamp":1679641715476,"user_tz":-540,"elapsed":6,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}},"outputId":"f8467891-beb0-4120-b246-426a05092a83"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","0\n","0\n","0\n"]}]},{"cell_type":"code","source":["data_1 = os.listdir('/content/Dataset/images/train')\n","data_2 = os.listdir('/content/Dataset/labels/train_raw')\n","count=0\n","for list1 in data_1:\n","    for list2 in data_2:\n","    # 데이터1이랑 데이터2랑 같으면 count + 1\n","        if os.path.splitext(list1)[0] == os.path.splitext(list2)[0]:\n","            count+=1     \n","            "],"metadata":{"id":"yROLcbqqZkGa","executionInfo":{"status":"ok","timestamp":1679641715476,"user_tz":-540,"elapsed":4,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["count"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A9MzlmL-bF-x","executionInfo":{"status":"ok","timestamp":1679641716346,"user_tz":-540,"elapsed":874,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}},"outputId":"990e58fa-8d01-4011-fe16-235f70ecd42d"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["# 3. 데이터를 Training set | Validation set으로 분할하세요.\n","data_path = '/content/Dataset/money_data/'\n","for won in won_list :\n","    data = os.listdir(data_path+ won)\n","    \n","    # train_test_split 방식 대신 이 방식으로 나누어 갯수는 맞지만 내용물이 랜덤하게 나뉘어짐. >> 가상환경으로 이동하면서..\n","    split_tr_data = data[:round(len(data)*0.8)]\n","    split_val_data = data[round(len(data)*0.8):]\n","\n","    for filename in split_tr_data:\n","        name=os.path.splitext(filename)[0]\n","        ext = os.path.splitext(filename)[1]\n","        if ext == \".jpg\": # shutil.copy(복사할 파일 경로, 저장할 경로) \n","            shutil.copy(os.path.join(data_path+won, name+'.jpg'), '/content/Dataset/images/train')\n","            shutil.copy(os.path.join(data_path+won, name+'.json'), '/content/Dataset/labels/train_raw')\n","\n","    for filename in split_val_data:\n","        name=os.path.splitext(filename)[0]\n","        ext = os.path.splitext(filename)[1]\n","        \n","        if ext == \".jpg\":\n","            shutil.copy(os.path.join(data_path+won, name+'.jpg'), '/content/Dataset/images/val')\n","            shutil.copy(os.path.join(data_path+won, name+'.json'), '/content/Dataset/labels/val_raw')\n"],"metadata":{"id":"1qfGCSqy_kL0","executionInfo":{"status":"ok","timestamp":1679641719818,"user_tz":-540,"elapsed":3475,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["print(len(os.listdir('/content/Dataset/images/train')))\n","print(len(os.listdir('/content/Dataset/images/val'))) \n","print(len(os.listdir('/content/Dataset/labels/train_raw'))) \n","print(len(os.listdir('/content/Dataset/labels/val_raw')))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lg5JbnISFfsH","executionInfo":{"status":"ok","timestamp":1679641719818,"user_tz":-540,"elapsed":9,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}},"outputId":"4a24cd8f-35e0-43d8-e1ee-1f180e68138d"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["4161\n","1057\n","4161\n","1057\n"]}]},{"cell_type":"markdown","source":["### (2) json에서 정보 추출\n","---\n","- **세부요구사항**\n","    - json 파일에서 필요한 정보를 추출하세요:\n","        - 위치 정보 : x1, x2, y1, y2\n","        - 박스 정보 : shape_type\n","        - 클래스 정보 : labels\n","    - 화폐당 하나의 클래스로 변경하세요.\n","        - json 파일에는 화폐 클래스가 앞뒷면으로 구분되어 있습니다.\n","        - 화폐의 앞뒷면 구분을 없애주세요.\n","            - 예시 : 'ten_front', 'ten_back' -> 'ten'\n","    - 화폐의 위치 정보를 YOLO 모델 형식에 맞게 변경 해주세요.\n","        - 사용되는 이미지는 원본에서 1/4로 축소되어 있습니다.\n","        - json 파일의 정보는 원본 기준 데이터이므로 위치 정보 추출을 할 때 x값과 y값을 1/4로 줄여주세요.\n","    - 이렇게 변경된 정보를 YOLO label 형식에 맞게 txt파일로 저장 해 주세요.\n","        - Hint : YOLO Labeling Format [label, x-center, y-center, width-norm, height-norm]\n","---"],"metadata":{"id":"II_hsJ6bKYGn"}},{"cell_type":"code","source":["import os, json"],"metadata":{"id":"MgUoCewjM-Jf","executionInfo":{"status":"ok","timestamp":1679641720202,"user_tz":-540,"elapsed":388,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["json_path = '/content/Dataset/labels/'\n","temp_list = ['train_raw', 'val_raw']"],"metadata":{"id":"gBD1Zv9BKaxi","executionInfo":{"status":"ok","timestamp":1679641720203,"user_tz":-540,"elapsed":7,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["!mkdir /content/Dataset/labels/train/\n","!mkdir /content/Dataset/labels/val/"],"metadata":{"id":"YQgxvkEZObYd","executionInfo":{"status":"ok","timestamp":1679641720203,"user_tz":-540,"elapsed":6,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["for i in temp_list :\n","    files = os.listdir(json_path+ i)\n","    for name in files :\n","        # json 파일 불러오기\n","        with open(json_path + i + '/' + name, 'r') as file:\n","            a = json.load(file)\n","            # 위치 정보 추출\n","            x_1 = a['shapes'][0]['points'][0][0]\n","            y_1 = a['shapes'][0]['points'][0][1]\n","            x_2 = a['shapes'][0]['points'][1][0]\n","            y_2 = a['shapes'][0]['points'][1][1]\n","            \n","            # bounding box center 좌표 계산 \n","            center_x = ((x_1 + x_2 )/2)/4\n","            center_y = ((y_1 + y_2)/2)/4\n","\n","            # bounding box 가로 세로 길이 계산 후 사이즈 1/4로 줄이기\n","            width_1 = (x_2 - x_1)/4\n","            height_1 = (y_2 - y_1) /4\n","            \n","            # 원본 이미지 크기 추출\n","            width_image = a['imageWidth']/4\n","            height_image = a['imageHeight']/4\n","\n","            x = center_x/width_image\n","            y = center_y/height_image\n","            \n","            # width, height 크기 줄이기\n","            width = width_1/width_image\n","            height = height_1/height_image\n","            \n","            # 화폐의 클래스 정보를 변환하는 함수\n","            file_name = a['shapes'][0]['label']\n","\n","            if (file_name  == 'Ten_back') or (file_name == 'Ten_front'):\n","                c = 0\n","            elif (file_name  == 'Fifty_front') or (file_name == 'Fifty_back'):\n","                c = 1\n","            elif (file_name  == 'Hundred_front') or (file_name == 'Hundred_back'):\n","                c = 2\n","            elif (file_name  == 'Five_Hundred_front') or (file_name == 'Five_Hundred_back'):\n","                c = 3\n","            elif (file_name  == 'Thousand_front') or (file_name == 'Thousand_back'):\n","                c = 4\n","            elif (file_name  == 'Five_Thousand_front') or (file_name == 'Five_Thousand_back'):\n","                c = 5\n","            elif (file_name  == 'Ten_Thousand_front') or (file_name == 'Ten_Thousand_back'):\n","                c = 6\n","            elif (file_name  == 'Fifty_Thousand_front') or (file_name == 'Fifty_Thousand_back'):\n","                c = 7\n","\n","            # YOLO label 형식으로 변환하여 파일에 저장\n","            txt_name = name.split('.')[0]\n","            folder_name = i.split('_')[0]\n","            f = open(json_path + folder_name +'/'+ txt_name +'.txt', 'w')\n","            # YOLO label 형식으로 변환하여 파일에 저장\n","            result = f'{c} {x} {y} {width} {height}'\n","            f.write(result)\n","            f.close()"],"metadata":{"id":"DdYPyQ8REiD4","executionInfo":{"status":"ok","timestamp":1679641721810,"user_tz":-540,"elapsed":1611,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tOQeEhApesWR"},"source":["### (3) 데이터셋 정보가 담긴 파일 생성\n","---\n","- **세부요구사항**\n","    - 파일 안에 있어야 할 정보는 아래와 같습니다.\n","        - 학습할 클래스 이름 정보\n","        - 학습할 클래스 수 정보\n","        - Training, Validation 데이터셋 위치 정보\n","---\n","- 가장 대중적으로 이용하는 라이브러리는 yaml 입니다.\n","    - [yaml document](https://pyyaml.org/wiki/PyYAMLDocumentation)\n","    - 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n","---"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"pu1iQfQolBhJ","executionInfo":{"status":"ok","timestamp":1679641721810,"user_tz":-540,"elapsed":7,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"outputs":[],"source":["import yaml"]},{"cell_type":"code","source":["# y 클래스 정보\n","won_dict = {0:'10', 1:'50', 2:'100', 3:'500', 4:'1000', 5:'5000', 6:'10000', 7:'50000'}"],"metadata":{"id":"t1_uOeXcSvv3","executionInfo":{"status":"ok","timestamp":1679641721811,"user_tz":-540,"elapsed":8,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","execution_count":24,"metadata":{"id":"qvMQcHirmSnD","executionInfo":{"status":"ok","timestamp":1679641721811,"user_tz":-540,"elapsed":7,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"outputs":[],"source":["# 수정 전\n","# data = {\n","#     'names': [won_dict[i] for i in range(len(won_dict))],\n","#     'nc': len(won_dict),\n","#     'datasets': {\n","#         'train': [\n","#             '/content/Dataset/images/train',\n","#             '/content/Dataset/labels/train_txt'\n","#         ],\n","#         'val': [\n","#             '/content/Dataset/images/val',     \n","#             '/content/Dataset/labels/val_txt'     \n","#         ]\n","#     }\n","# }\n","\n","# with open('/content/Dataset/money_data.yaml', 'w') as f:\n","#     yaml.dump(data, f)\n","    "]},{"cell_type":"code","source":["# yaml 파일 작성\n","data = dict(path = '/content/Dataset/',\n","            train = 'images/train',\n","            val = 'images/val',\n","            nc = 8,\n","            names = won_dict)\n","\n","with open('/content/Dataset/money_dataset.yaml', 'w') as f :\n","    yaml.dump(data, f, default_flow_style = False)"],"metadata":{"id":"-dvgrbA8G7Il","executionInfo":{"status":"ok","timestamp":1679641721812,"user_tz":-540,"elapsed":8,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["## 3.모델링"],"metadata":{"id":"3btFvySXi2dt"}},{"cell_type":"markdown","metadata":{"id":"0pQ2gRbTYgLL"},"source":["### (1) 모델 라이브러리 설치\n","---"]},{"cell_type":"code","source":["!pip install jedi"],"metadata":{"id":"73a1l-ZQuHyF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679641728598,"user_tz":-540,"elapsed":6794,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}},"outputId":"f5edc1a9-7d06-427d-e67e-4465e0792e0f"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting jedi\n","  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi) (0.8.3)\n","Installing collected packages: jedi\n","Successfully installed jedi-0.18.2\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/ultralytics/yolov5"],"metadata":{"id":"Biyr9AHkMyNf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679641731048,"user_tz":-540,"elapsed":2463,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}},"outputId":"36ced3e4-419f-44de-beb7-16f0e4c8169b"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 15338, done.\u001b[K\n","remote: Counting objects: 100% (3/3), done.\u001b[K\n","remote: Compressing objects: 100% (3/3), done.\u001b[K\n","remote: Total 15338 (delta 0), reused 2 (delta 0), pack-reused 15335\u001b[K\n","Receiving objects: 100% (15338/15338), 14.15 MiB | 17.27 MiB/s, done.\n","Resolving deltas: 100% (10524/10524), done.\n"]}]},{"cell_type":"code","source":["## yolov5 폴더 requirements.txt 수정 필요\n","## setuptools<=64.0.2\n","\n","temp_str = 'setuptools<=64.0.2\\n'\n","\n","f = open('/content/yolov5/requirements.txt', 'r')\n","f_str = f.readlines()\n","f.close()\n","\n","f2 = open('/content/yolov5/requirements.txt', 'w')\n","\n","for idx, val in enumerate(f_str) :\n","    if 'setuptools' in val :\n","        idx_v = idx\n","        f_str.remove(val)\n","        f_str.insert(idx_v, temp_str)\n","\n","for val in f_str :\n","    f2.write(val)\n","\n","f2.close() "],"metadata":{"id":"W3JjyVOpg26s","executionInfo":{"status":"ok","timestamp":1679641731049,"user_tz":-540,"elapsed":8,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","execution_count":29,"metadata":{"id":"6xD6tBTdMyNg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679641742382,"user_tz":-540,"elapsed":11339,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}},"outputId":"ae8ed8ec-3214-4f97-c18f-f5d52b4e9e18"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting gitpython>=3.1.30\n","  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 7)) (1.22.4)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 8)) (4.7.0.72)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 9)) (8.4.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 10)) (5.9.4)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 11)) (6.0)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 12)) (2.27.1)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 13)) (1.10.1)\n","Collecting thop>=0.1.1\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 15)) (1.13.1+cu116)\n","Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 16)) (0.14.1+cu116)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 17)) (4.65.0)\n","Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 21)) (2.11.2)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 26)) (1.4.4)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 27)) (0.12.2)\n","Collecting setuptools<=64.0.2\n","  Downloading setuptools-64.0.2-py3-none-any.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (5.12.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (23.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (1.0.7)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (2.8.2)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (4.39.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (1.4.4)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (0.11.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2022.12.7)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (4.5.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.40.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (2.16.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (3.4.1)\n","Requirement already satisfied: protobuf<4,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (3.19.6)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.51.3)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (2.2.3)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.4.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.6.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.4.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 26)) (2022.7.1)\n","Collecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.2.8)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (5.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (4.9)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.16.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.3.1)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=3.2.2->-r requirements.txt (line 6)) (3.15.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 21)) (6.1.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r requirements.txt (line 21)) (2.1.2)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 21)) (3.2.2)\n","Installing collected packages: smmap, setuptools, thop, gitdb, gitpython\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 67.6.0\n","    Uninstalling setuptools-67.6.0:\n","      Successfully uninstalled setuptools-67.6.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cvxpy 1.3.1 requires setuptools>65.5.1, but you have setuptools 64.0.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed gitdb-4.0.10 gitpython-3.1.31 setuptools-64.0.2 smmap-5.0.0 thop-0.1.1.post2209072238\n"]}],"source":["# yolo5 폴더 이동 및 requirements.txt 내부 패키지 설치\n","!cd yolov5; pip install -r requirements.txt"]},{"cell_type":"markdown","source":["### (2) 가중치 파일 다운로드\n","---\n","- **세부요구사항**\n","    - 모델 개발자가 제공하는 사전 학습 가중치 파일을 다운로드 하세요.\n","        - 해당 과정이 불필요하다면 넘어가셔도 됩니다!\n","---"],"metadata":{"id":"_mHMAspjR6Xp"}},{"cell_type":"code","source":["# pretrained weights 저장 폴더 생성\n","!mkdir /content/yolov5/pretrained"],"metadata":{"id":"sSVIqkMLDIOd","executionInfo":{"status":"ok","timestamp":1679641742383,"user_tz":-540,"elapsed":21,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["# pretrained weights 다운로드\n","!wget -O /content/yolov5/pretrained/yolov5l.pt https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5l.pt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lwNNemVGemzW","executionInfo":{"status":"ok","timestamp":1679641745273,"user_tz":-540,"elapsed":2909,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}},"outputId":"f46d922c-0a8f-43fc-d567-29820e57d157"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-03-24 07:09:00--  https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5l.pt\n","Resolving github.com (github.com)... 140.82.121.3\n","Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/638b4816-c501-4617-9384-54fd42a62e3a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230324%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230324T070900Z&X-Amz-Expires=300&X-Amz-Signature=c53ed30308c88b269c9c1643a23caafadf803dd8383143abfba126c8f1344f79&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5l.pt&response-content-type=application%2Foctet-stream [following]\n","--2023-03-24 07:09:01--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/638b4816-c501-4617-9384-54fd42a62e3a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230324%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230324T070900Z&X-Amz-Expires=300&X-Amz-Signature=c53ed30308c88b269c9c1643a23caafadf803dd8383143abfba126c8f1344f79&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5l.pt&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 93622629 (89M) [application/octet-stream]\n","Saving to: ‘/content/yolov5/pretrained/yolov5l.pt’\n","\n","/content/yolov5/pre 100%[===================>]  89.29M  50.3MB/s    in 1.8s    \n","\n","2023-03-24 07:09:03 (50.3 MB/s) - ‘/content/yolov5/pretrained/yolov5l.pt’ saved [93622629/93622629]\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"W8-5lC4mfbwT"},"source":["### (3) 학습 : train.py\n","---\n","- **세부요구사항**\n","    - UltraLytics YOLO v5에는 아래의 데이터가 필요합니다.\n","        - 데이터셋 정보가 담긴 yaml 파일\n","        - 사용하려는 모델 구조에 대한 yaml 파일\n","        - 사용하려는 모델의 가중치 파일\n","---"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"4AYFDMaVfmTK","executionInfo":{"status":"ok","timestamp":1679641745273,"user_tz":-540,"elapsed":5,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"outputs":[],"source":["# !cd yolov5; python train.py -h\n"]},{"cell_type":"code","source":["!cd yolov5; python train.py \\\n","    --data '/content/Dataset/money_dataset.yaml' \\\n","    --cfg '/content/yolov5/models/yolov5l.yaml' \\\n","    --weights '/content/yolov5/pretrained/yolov5l.pt' \\\n","    --epochs 1000 \\\n","    --patience 3 \\\n","    --img 640 \\\n","    --project '/content/yolov5/trained' \\\n","    --name 'train_money_data' \\\n","    --exist-ok"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RcSMyEAqfjCe","executionInfo":{"status":"ok","timestamp":1679645198202,"user_tz":-540,"elapsed":3132307,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}},"outputId":"ff125703-aef2-4674-d97e-5cf4a085640d"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mweights=/content/yolov5/pretrained/yolov5l.pt, cfg=/content/yolov5/models/yolov5l.yaml, data=/content/Dataset/money_dataset.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=1000, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=/content/yolov5/trained, name=train_money_data, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=3, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n","YOLOv5 🚀 v7.0-128-gb96f35c Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/yolov5/trained', view at http://localhost:6006/\n","2023-03-24 07:14:27.682193: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-03-24 07:14:28.789829: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n","2023-03-24 07:14:28.789978: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n","2023-03-24 07:14:28.790000: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","Overriding model.yaml nc=80 with nc=8\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n","  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n","  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n","  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n","  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n","  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n","  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n"," 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n"," 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n"," 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n"," 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n"," 24      [17, 20, 23]  1     70005  models.yolo.Detect                      [8, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n","YOLOv5l summary: 368 layers, 46175989 parameters, 46175989 gradients, 108.3 GFLOPs\n","\n","Transferred 606/613 items from /content/yolov5/pretrained/yolov5l.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0005), 104 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Dataset/labels/train.cache... 4161 images, 0 backgrounds, 0 corrupt: 100% 4161/4161 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Dataset/labels/val.cache... 1057 images, 0 backgrounds, 0 corrupt: 100% 1057/1057 [00:00<?, ?it/s]\n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.00 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n","Plotting labels to /content/yolov5/trained/train_money_data/labels.jpg... \n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/content/yolov5/trained/train_money_data\u001b[0m\n","Starting training for 1000 epochs...\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      0/999      10.2G    0.05061    0.02115    0.05046          2        640: 100% 261/261 [03:41<00:00,  1.18it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:22<00:00,  1.52it/s]\n","                   all       1057       1057      0.249      0.845      0.509      0.322\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      1/999      12.8G    0.03754    0.01046    0.03085          1        640: 100% 261/261 [03:32<00:00,  1.23it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:23<00:00,  1.44it/s]\n","                   all       1057       1057      0.527      0.937      0.725      0.487\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      2/999      12.8G    0.03472    0.00797    0.01985          1        640: 100% 261/261 [03:31<00:00,  1.24it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:21<00:00,  1.60it/s]\n","                   all       1057       1057      0.885       0.93      0.956      0.677\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      3/999      12.8G    0.02926   0.006944    0.01574          2        640: 100% 261/261 [03:29<00:00,  1.25it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:22<00:00,  1.48it/s]\n","                   all       1057       1057      0.809      0.858      0.896      0.787\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      4/999      12.8G    0.02416   0.006685    0.01516          2        640: 100% 261/261 [03:28<00:00,  1.25it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:21<00:00,  1.62it/s]\n","                   all       1057       1057      0.905      0.878      0.953      0.831\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      5/999      12.8G    0.02244   0.006229      0.014          1        640: 100% 261/261 [03:30<00:00,  1.24it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:22<00:00,  1.48it/s]\n","                   all       1057       1057       0.92      0.959      0.978      0.874\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      6/999      12.8G    0.02087   0.006044    0.01281          4        640: 100% 261/261 [03:30<00:00,  1.24it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:21<00:00,  1.58it/s]\n","                   all       1057       1057      0.869      0.823      0.883       0.75\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      7/999      12.8G    0.02011   0.005732    0.01251          2        640: 100% 261/261 [03:29<00:00,  1.24it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:21<00:00,  1.62it/s]\n","                   all       1057       1057       0.94      0.919      0.974      0.888\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      8/999      12.8G    0.01931   0.005666    0.01119          2        640: 100% 261/261 [03:28<00:00,  1.25it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:22<00:00,  1.49it/s]\n","                   all       1057       1057      0.963      0.962      0.985      0.869\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      9/999      12.8G    0.01883     0.0055    0.01106          4        640: 100% 261/261 [03:29<00:00,  1.25it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:22<00:00,  1.52it/s]\n","                   all       1057       1057      0.985      0.961      0.991      0.924\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     10/999      12.8G    0.01823   0.005433   0.009968          1        640: 100% 261/261 [03:33<00:00,  1.22it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:22<00:00,  1.54it/s]\n","                   all       1057       1057      0.976      0.979      0.988      0.906\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     11/999      12.8G     0.0171   0.005272   0.009561          1        640: 100% 261/261 [03:32<00:00,  1.23it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:21<00:00,  1.57it/s]\n","                   all       1057       1057      0.975      0.966      0.985       0.91\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     12/999      12.8G    0.01632   0.005118   0.009366          1        640: 100% 261/261 [03:30<00:00,  1.24it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:22<00:00,  1.53it/s]\n","                   all       1057       1057      0.959      0.964      0.985      0.921\n","Stopping training early as no improvement observed in last 3 epochs. Best results observed at epoch 9, best model saved as best.pt.\n","To update EarlyStopping(patience=3) pass a new patience value, i.e. `python train.py --patience 300` or use `--patience 0` to disable EarlyStopping.\n","\n","13 epochs completed in 0.854 hours.\n","Optimizer stripped from /content/yolov5/trained/train_money_data/weights/last.pt, 92.8MB\n","Optimizer stripped from /content/yolov5/trained/train_money_data/weights/best.pt, 92.8MB\n","\n","Validating /content/yolov5/trained/train_money_data/weights/best.pt...\n","Fusing layers... \n","YOLOv5l summary: 267 layers, 46145973 parameters, 0 gradients, 107.8 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:23<00:00,  1.48it/s]\n","                   all       1057       1057      0.985      0.961      0.991      0.923\n","                    10       1057         84      0.984      0.988      0.988      0.911\n","                    50       1057         98      0.974      0.929      0.991      0.908\n","                   100       1057         91      0.988      0.881      0.979      0.883\n","                   500       1057         96      0.994      0.948      0.992      0.928\n","                  1000       1057        170          1          1      0.995      0.949\n","                  5000       1057        174      0.999      0.983      0.995      0.931\n","                 10000       1057        168       0.94          1      0.991      0.934\n","                 50000       1057        176          1      0.962      0.993      0.942\n","Results saved to \u001b[1m/content/yolov5/trained/train_money_data\u001b[0m\n"]}]},{"cell_type":"markdown","metadata":{"id":"u2YESAa5fc4M"},"source":["## 4.탐지 : detect.py\n","---\n","- **세부요구사항**\n","    - 학습 과정에서 생성된 가중치 파일을 이용하세요.\n","    - IoU threshold를 0.25 이하로 설정하세요.\n","    - confidence threshold를 0.75 이상으로 설정하세요.\n","---\n","- 여러분이 **직접 촬영한 화폐 사진과 동영상**을 탐지 과정에 이용하여 결과를 확인하세요.\n","    - 조건\n","        1. 화폐의 수를 늘려가며 촬영 해보세요.\n","            - ex) 50원 하나, 50원 둘, 50원 셋, ...\n","        2. 화폐의 종류를 늘려가며 촬영 해보세요.\n","            - ex) 50원 하나와 100원 하나, 50원 하나와 100원 하나와 1000원 하나, ...\n","        3. 사진은 최소 30장 이상, 동영상은 최소 하나 이상 촬영하여 사용 해보세요.\n","---"]},{"cell_type":"code","source":["test_data = zipfile.ZipFile( '/content/drive/MyDrive/Datasets/test.zip' )"],"metadata":{"id":"_Pfi_0l0cqEx","executionInfo":{"status":"ok","timestamp":1679645853507,"user_tz":-540,"elapsed":3,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["test_data.extractall('/content/drive/MyDrive/Datasets/')"],"metadata":{"id":"rk2blPIZcqzy","executionInfo":{"status":"ok","timestamp":1679645861507,"user_tz":-540,"elapsed":1304,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["!cd yolov5; python detect.py \\\n","    --weights '/content/yolov5/trained/money/weights/best.pt' \\\n","    --source '/content/drive/MyDrive/Datasets/test/00e9142def4da14905847fbc307d6bfa.jpg' \\\n","    --project '/content/yolov5/detected/' \\\n","    --name 'images' \\\n","    --img 640 \\\n","    --conf-thres 0.5 \\\n","    --iou-thres 0.4 \\\n","    --line-thickness 2 \\\n","    --exist-ok"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A13gGvNNcqwK","executionInfo":{"status":"ok","timestamp":1679645881703,"user_tz":-540,"elapsed":4675,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}},"outputId":"f4d3435f-ef91-4c18-96c8-ac50499601a9"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov5/trained/money/weights/best.pt'], source=/content/drive/MyDrive/Datasets/test/00e9142def4da14905847fbc307d6bfa.jpg, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.5, iou_thres=0.4, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=/content/yolov5/detected/, name=images, exist_ok=True, line_thickness=2, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n","YOLOv5 🚀 v7.0-128-gb96f35c Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n","\n","Traceback (most recent call last):\n","  File \"/content/yolov5/detect.py\", line 261, in <module>\n","    main(opt)\n","  File \"/content/yolov5/detect.py\", line 256, in main\n","    run(**vars(opt))\n","  File \"/usr/local/lib/python3.9/dist-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n","    return func(*args, **kwargs)\n","  File \"/content/yolov5/detect.py\", line 98, in run\n","    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)\n","  File \"/content/yolov5/models/common.py\", line 344, in __init__\n","    model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)\n","  File \"/content/yolov5/models/experimental.py\", line 79, in attempt_load\n","    ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n","  File \"/usr/local/lib/python3.9/dist-packages/torch/serialization.py\", line 771, in load\n","    with _open_file_like(f, 'rb') as opened_file:\n","  File \"/usr/local/lib/python3.9/dist-packages/torch/serialization.py\", line 270, in _open_file_like\n","    return _open_file(name_or_buffer, mode)\n","  File \"/usr/local/lib/python3.9/dist-packages/torch/serialization.py\", line 251, in __init__\n","    super(_open_file, self).__init__(open(name, mode))\n","FileNotFoundError: [Errno 2] No such file or directory: '/content/yolov5/trained/money/weights/best.pt'\n"]}]},{"cell_type":"code","source":["from IPython.display import Image\n","from google.colab import files"],"metadata":{"id":"fEAW28pmcqrb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Image(filename='/content/yolov3/detected/images/00e9142def4da14905847fbc307d6bfa.jpg', width=640)"],"metadata":{"id":"yzgQ2Qkhc3Cl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cd yolov5; python detect.py \\\n","    --weights '/content/yolov5/trained/train_money_data/weights/best.pt' \\\n","    --source '/content/drive/MyDrive/Datasets/test/' \\\n","    --project '/content/yolov5/detected/' \\\n","    --name 'images' \\\n","    --img 640 \\\n","    --conf-thres 0.5 \\\n","    --iou-thres 0.4 \\\n","    --line-thickness 2 \\\n","    --exist-ok"],"metadata":{"id":"9rK0ClfTcjEZ","executionInfo":{"status":"ok","timestamp":1679646093512,"user_tz":-540,"elapsed":11767,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"51fa3c83-557d-469d-8085-f4a7920cee7c"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov5/trained/train_money_data/weights/best.pt'], source=/content/drive/MyDrive/Datasets/test/, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.5, iou_thres=0.4, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=/content/yolov5/detected/, name=images, exist_ok=True, line_thickness=2, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n","YOLOv5 🚀 v7.0-128-gb96f35c Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n","\n","Fusing layers... \n","YOLOv5l summary: 267 layers, 46145973 parameters, 0 gradients, 107.8 GFLOPs\n","image 1/61 /content/drive/MyDrive/Datasets/test/00e9142def4da14905847fbc307d6bfa.jpg: 416x640 1 5000, 45.3ms\n","image 2/61 /content/drive/MyDrive/Datasets/test/0341036562022051075637400-f7e4-4b38-a0d4-68b543d311e7.jpeg: 640x448 1 1000, 2 10000s, 29.5ms\n","image 3/61 /content/drive/MyDrive/Datasets/test/14b1d6f7baaae8e7f490c4d5b042aa1b.jpg: 448x640 1 10, 2 50s, 1 100, 35.2ms\n","image 4/61 /content/drive/MyDrive/Datasets/test/1531488668629.jpg: 640x640 1 100, 39.5ms\n","image 5/61 /content/drive/MyDrive/Datasets/test/15_shop1_225726.jpg: 480x640 1 10000, 27.3ms\n","image 6/61 /content/drive/MyDrive/Datasets/test/165433777_{cnt}_1667222355_w{res}.jpg: 480x640 2 100s, 27.0ms\n","image 7/61 /content/drive/MyDrive/Datasets/test/170917797_1_1642652996_w180.jpg: 640x640 (no detections), 32.7ms\n","image 8/61 /content/drive/MyDrive/Datasets/test/185164424_1_1650147332_w180.jpg: 640x640 1 50, 32.5ms\n","image 9/61 /content/drive/MyDrive/Datasets/test/188033147_1_1652698349_w180.jpg: 640x640 (no detections), 26.2ms\n","image 10/61 /content/drive/MyDrive/Datasets/test/188971735_1_1653571632_w180.jpg: 640x640 1 50000, 27.2ms\n","image 11/61 /content/drive/MyDrive/Datasets/test/188974870_1_1653573627_w180.jpg: 640x640 (no detections), 27.5ms\n","image 12/61 /content/drive/MyDrive/Datasets/test/189138630_1_1675961028_w180 (1).jpg: 640x640 4 50s, 27.3ms\n","image 13/61 /content/drive/MyDrive/Datasets/test/189138630_1_1675961028_w180.jpg: 640x640 4 50s, 28.6ms\n","image 14/61 /content/drive/MyDrive/Datasets/test/189264534_1_1653881147_w180.jpg: 640x640 (no detections), 28.1ms\n","image 15/61 /content/drive/MyDrive/Datasets/test/195265771_1_1659445820_w180 (1).jpg: 640x640 1 50, 27.0ms\n","image 16/61 /content/drive/MyDrive/Datasets/test/195265771_1_1659445820_w180.jpg: 640x640 1 50, 28.0ms\n","image 17/61 /content/drive/MyDrive/Datasets/test/195879506_1_1660021672_w180 (1).jpg: 640x640 (no detections), 28.4ms\n","image 18/61 /content/drive/MyDrive/Datasets/test/195879506_1_1660021672_w180.jpg: 640x640 (no detections), 27.1ms\n","image 19/61 /content/drive/MyDrive/Datasets/test/195880160_1_1660022089_w180.jpg: 640x640 1 10, 27.8ms\n","image 20/61 /content/drive/MyDrive/Datasets/test/196283601_1_1660373488_w180 (1).jpg: 640x640 1 10, 2 50s, 28.8ms\n","image 21/61 /content/drive/MyDrive/Datasets/test/196283601_1_1660373488_w180 (2).jpg: 640x640 1 10, 2 50s, 27.4ms\n","image 22/61 /content/drive/MyDrive/Datasets/test/196283601_1_1660373488_w180.jpg: 640x640 1 10, 2 50s, 26.9ms\n","image 23/61 /content/drive/MyDrive/Datasets/test/197892866_1_1665574269_w180.jpg: 640x640 (no detections), 28.2ms\n","image 24/61 /content/drive/MyDrive/Datasets/test/1┐°.jpg: 384x640 1 50, 18.7ms\n","image 25/61 /content/drive/MyDrive/Datasets/test/20140125.88001191535i3 (1).jpg: 480x640 1 10000, 20.6ms\n","image 26/61 /content/drive/MyDrive/Datasets/test/20150714153105308125.jpg: 416x640 2 10s, 21.1ms\n","image 27/61 /content/drive/MyDrive/Datasets/test/20171024_181216.jpg: 640x416 1 1000, 1 5000, 1 10000, 1 50000, 19.0ms\n","image 28/61 /content/drive/MyDrive/Datasets/test/20171024_181309.jpg: 480x640 1 50000, 19.7ms\n","image 29/61 /content/drive/MyDrive/Datasets/test/20171024_181323 (1).jpg: 480x640 1 5000, 19.9ms\n","image 30/61 /content/drive/MyDrive/Datasets/test/20171024_181336.jpg: 480x640 1 10000, 19.9ms\n","image 31/61 /content/drive/MyDrive/Datasets/test/2018021301018679.jpg: 640x640 (no detections), 25.2ms\n","image 32/61 /content/drive/MyDrive/Datasets/test/20190209013654_1299253_1123_503.jpg: 288x640 2 100s, 1 500, 18.5ms\n","image 33/61 /content/drive/MyDrive/Datasets/test/20191028503286.jpg: 384x640 1 10, 15.9ms\n","image 34/61 /content/drive/MyDrive/Datasets/test/202006031821_500.jpg: 448x640 (no detections), 19.2ms\n","image 35/61 /content/drive/MyDrive/Datasets/test/202312792_1_1673422992_w180.jpg: 640x640 5 50s, 3 100s, 26.7ms\n","image 36/61 /content/drive/MyDrive/Datasets/test/212311341_1_1674439238_w180.jpg: 640x640 (no detections), 26.2ms\n","image 37/61 /content/drive/MyDrive/Datasets/test/214433963_1_1676042486_w180.jpg: 640x640 (no detections), 28.1ms\n","image 38/61 /content/drive/MyDrive/Datasets/test/214523896_1_1676119580_w180.jpg: 640x640 3 100s, 28.2ms\n","image 39/61 /content/drive/MyDrive/Datasets/test/214631590_1_1676204298_w180 (1).jpg: 640x640 (no detections), 28.0ms\n","image 40/61 /content/drive/MyDrive/Datasets/test/214631590_1_1676204298_w180.jpg: 640x640 (no detections), 28.7ms\n","image 41/61 /content/drive/MyDrive/Datasets/test/215509944_1_1676864155_w180.jpg: 640x640 1 10, 1 50, 27.7ms\n","image 42/61 /content/drive/MyDrive/Datasets/test/216980125_1_1679142500_w180.jpg: 640x640 (no detections), 27.9ms\n","image 43/61 /content/drive/MyDrive/Datasets/test/217083873_1_1678087124_w180.jpg: 640x640 3 50s, 1 100, 3 500s, 28.3ms\n","image 44/61 /content/drive/MyDrive/Datasets/test/217085657_1_1678088101_w180.jpg: 640x640 3 50s, 27.1ms\n","image 45/61 /content/drive/MyDrive/Datasets/test/217733906_1_1678617136_w180 (1).jpg: 640x640 (no detections), 28.2ms\n","image 46/61 /content/drive/MyDrive/Datasets/test/217733906_1_1678617136_w180.jpg: 640x640 (no detections), 28.7ms\n","image 47/61 /content/drive/MyDrive/Datasets/test/2cbfa6838c773.jpg: 640x640 (no detections), 24.6ms\n","image 48/61 /content/drive/MyDrive/Datasets/test/304.jpg: 384x640 1 50000, 15.8ms\n","image 49/61 /content/drive/MyDrive/Datasets/test/306.jpg: 384x640 (no detections), 15.7ms\n","image 50/61 /content/drive/MyDrive/Datasets/test/771_1092_577.jpg: 320x640 1 10, 2 50s, 3 100s, 2 500s, 18.7ms\n","image 51/61 /content/drive/MyDrive/Datasets/test/9778503ac16142409ce1ba64b44c86dd.jpg: 448x640 1 10000, 19.3ms\n","image 52/61 /content/drive/MyDrive/Datasets/test/AKR20210225147900062_01_i.webp: 448x640 1 10, 1 1000, 1 10000, 19.3ms\n","image 53/61 /content/drive/MyDrive/Datasets/test/SE-0c358fe0-ed65-4bbb-bd1b-d48eaad2a289.jpg: 384x640 (no detections), 15.7ms\n","image 54/61 /content/drive/MyDrive/Datasets/test/ae_1436146981_111918581_0.jpg: 640x608 (no detections), 23.9ms\n","image 55/61 /content/drive/MyDrive/Datasets/test/img (1).png: 640x576 (no detections), 24.6ms\n","image 56/61 /content/drive/MyDrive/Datasets/test/img.jpg: 640x640 (no detections), 24.7ms\n","image 57/61 /content/drive/MyDrive/Datasets/test/img.png: 640x576 (no detections), 23.8ms\n","image 58/61 /content/drive/MyDrive/Datasets/test/istockphoto-1048867506-612x612.jpg: 448x640 1 10000, 19.3ms\n","image 59/61 /content/drive/MyDrive/Datasets/test/korea-money-693949_1280.jpg: 640x480 (no detections), 18.8ms\n","image 60/61 /content/drive/MyDrive/Datasets/test/vm3eJPKbcRlI5xb9i23A3.png: 288x640 2 50s, 15.9ms\n","image 61/61 /content/drive/MyDrive/Datasets/test/┤┘┐ε╖╬╡σ.png: 640x480 (no detections), 18.2ms\n","Speed: 0.5ms pre-process, 25.1ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1m/content/yolov5/detected/images\u001b[0m\n"]}]},{"cell_type":"code","source":["import urllib.request\n","import os\n","\n","def download_session_folder():\n","    # Replace the URL with your own Cloud Storage URL\n","    url = \"/content/yolov5/detected/images\"\n","\n","    # Replace the folder name with your own folder name\n","    folder_name = \"week5_session\"\n","\n","    # Download the zip file from the Cloud Storage URL\n","    urllib.request.urlretrieve(url, f\"{folder_name}.zip\")\n","\n","    # Unzip the downloaded file\n","    os.system(f\"unzip {folder_name}.zip\")\n","\n","    # Remove the zip file\n","    os.system(f\"rm {folder_name}.zip\")\n","\n","    print(\"Session folder download complete.\")\n","\n","download_session_folder()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":360},"id":"lUs9y1vTcllL","executionInfo":{"status":"error","timestamp":1679646364557,"user_tz":-540,"elapsed":449,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}},"outputId":"b80f8762-a773-4e7a-b921-060631816925"},"execution_count":42,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-732a32765a11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Session folder download complete.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mdownload_session_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-42-732a32765a11>\u001b[0m in \u001b[0;36mdownload_session_folder\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Download the zip file from the Cloud Storage URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{folder_name}.zip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Unzip the downloaded file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0murl_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_splittype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;31m# accept a URL or a Request object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullurl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullurl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfullurl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, url, data, headers, origin_req_host, unverifiable, method)\u001b[0m\n\u001b[1;32m    318\u001b[0m                  \u001b[0morigin_req_host\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munverifiable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                  method=None):\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munredirected_hdrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36mfull_url\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfragment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_splittag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeleter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_splittype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unknown url type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_splithost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: unknown url type: '/content/yolov5/detected/images'"]}]}]}