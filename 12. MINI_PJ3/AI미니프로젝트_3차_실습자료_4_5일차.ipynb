{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **저시력자를 위한 원화 화폐 분류**\n","---\n","- 본 과제는 UltraLytics YOLO v5 모델 사용을 권장합니다.\n","    - 본 파일의 목차는 UltraLytics YOLO v5에 맞게 작성되어 있습니다.\n","    - 다른 모델을 찾아서 사용하셔도 좋습니다.\n","    - 산출물이 잘 나오면 됩니다 : )\n","---"],"metadata":{"id":"XT7PRhnMf-kI"}},{"cell_type":"markdown","source":["## 0.미션\n","---\n","- **과제 수행 목표**\n","    - 본 과제는 Object Detection 문제입니다.\n","    - Object Detection 문제로 접근하기 위해 **데이터셋 전처리**를 하셔야 합니다.\n","    - 데이터셋 : money_dataset.zip\n","        1. 데이터셋은 압축 파일로 제공됩니다.\n","        2. 압축 파일 안에는 화폐마다 폴더가 개별적으로 존재합니다.\n","        3. 폴더 안에는 화폐 이미지와 화폐 정보가 담긴 json 파일이 있습니다.\n","    - 여러분이 직접 촬영한 화폐 사진들을 탐지 과정에서 이용 해보세요.\n","    - 이미지에 화폐 하나만 나오게 촬영하는 것은 지양해주세요.\n","    - 다양한 방법으로 화폐를 촬영하고 결과를 확인해보세요.\n","        - ex 1) 화폐의 모든 종류를 한 이미지에 나오게 촬영\n","        - ex 2) 여러 화폐를 겹치게 하여 촬영\n","---\n","- **Key Point**\n","    1. 모델에 맞는 폴더 구조 확인\n","    2. 이미지 축소 비율에 맞춰 좌표값 변경\n","        - 좌표를 이미지 리사이즈한 비율로 변경\n","    3. 모델에 맞는 정보 추출/형식 변경\n","        - json 파일에서 정보 추출 및 모델 형식에 맞게 변경\n","    4. 화폐당 하나의 클래스로 변경\n","        - 총 8개 클래스\n","    5. 모델 선택 필요\n","---"],"metadata":{"id":"47D2vGDYdCOz"}},{"cell_type":"markdown","source":["## 1.환경설정"],"metadata":{"id":"aZon1K-Ag9be"}},{"cell_type":"markdown","source":["### (1) 구글 드라이브 연동\n","---\n","- 아래의 코드 셀을 반드시 실행시켜야 합니다.\n","---"],"metadata":{"id":"CMgnHN9ZBF05"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"id":"xCplyiojBFwh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679914860879,"user_tz":-540,"elapsed":20757,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}},"outputId":"d02a43ba-91c7-44ae-a4ac-a55369dcde20"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"markdown","source":["### (2) 데이터셋 불러오기\n","---\n","- **세부요구사항**\n","    - 데이터셋 파일의 압축을 해제하세요.\n","---\n","- 예제 코드에서는 zipfile 모듈을 이용하였습니다.\n","    - [zipfile document](https://docs.python.org/3/library/zipfile.html#zipfile-objects)\n","    - 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n","---"],"metadata":{"id":"J8vjv0acBAV4"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"bkSa5ejf8LMe","executionInfo":{"status":"ok","timestamp":1679914860880,"user_tz":-540,"elapsed":14,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"outputs":[],"source":["import zipfile\n","import os"]},{"cell_type":"code","source":["path = '/content/drive/MyDrive/Datasets/'"],"metadata":{"id":"IDEKV5NoxPiJ","executionInfo":{"status":"ok","timestamp":1679914860881,"user_tz":-540,"elapsed":12,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# 데이터셋 압축 파일 경로 : 유저별로 상이할 수 있음\n","money_data = zipfile.ZipFile(path + 'money_dataset.zip')"],"metadata":{"id":"N4cdpkRv86QQ","executionInfo":{"status":"ok","timestamp":1679914862169,"user_tz":-540,"elapsed":1297,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["!mkdir /content/Dataset/"],"metadata":{"id":"csXuHldPyqqY","executionInfo":{"status":"ok","timestamp":1679914862171,"user_tz":-540,"elapsed":8,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# 데이터셋 압축 해제\n","money_data.extractall('/content/Dataset/money_data/')"],"metadata":{"id":"TDAyDRLT9hZS","executionInfo":{"status":"ok","timestamp":1679914872534,"user_tz":-540,"elapsed":10368,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# 전체 이미지 갯수를 확인합니다.\n","print(len(os.listdir('/content/Dataset/money_data/10')))\n","print(len(os.listdir('/content/Dataset/money_data/100')))\n","print(len(os.listdir('/content/Dataset/money_data/1000')))\n","print(len(os.listdir('/content/Dataset/money_data/10000')))\n","print(len(os.listdir('/content/Dataset/money_data/50')))\n","print(len(os.listdir('/content/Dataset/money_data/500')))\n","print(len(os.listdir('/content/Dataset/money_data/5000')))\n","print(len(os.listdir('/content/Dataset/money_data/50000')))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3iSY-teEEIyU","executionInfo":{"status":"ok","timestamp":1679914872535,"user_tz":-540,"elapsed":13,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}},"outputId":"d483cd50-96c1-4fcd-ac40-0bb60e2d5a85"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["872\n","880\n","1716\n","1734\n","880\n","880\n","1734\n","1740\n"]}]},{"cell_type":"markdown","source":["## 2.데이터 전처리"],"metadata":{"id":"QyEd-WNIhoSc"}},{"cell_type":"markdown","source":["### (1) 폴더 구조 생성 및 파일 이동\n","---\n","- **세부요구사항**\n","    -  모델에서 요구하는 폴더 구조를 만들어야 합니다.\n","        - Hint : Image와 Label을 구분하는 폴더를 만들어 주세요\n","---\n","- 예제 코드에서는 glob, shutil 모듈을 이용하였습니다.\n","    - [glob document](https://docs.python.org/3/library/glob.html) | [shutil document](https://docs.python.org/3/library/shutil.html)\n","    - 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n","---"],"metadata":{"id":"P81d6utx-3LY"}},{"cell_type":"code","source":["# 1.폴더 구조 만들기\n","!mkdir /content/Dataset;\n","!mkdir /content/Dataset/images;\n","!mkdir /content/Dataset/images/train; mkdir /content/Dataset/images/val\n","\n","!mkdir /content/Dataset/labels;\n","!mkdir /content/Dataset/labels/train_raw; mkdir /content/Dataset/labels/val_raw"],"metadata":{"id":"YBqCJU5z_UI8","executionInfo":{"status":"ok","timestamp":1679914873187,"user_tz":-540,"elapsed":661,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e5da84d3-94c8-4e55-ba18-e9d8f6efc75d"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["mkdir: cannot create directory ‘/content/Dataset’: File exists\n"]}]},{"cell_type":"code","source":["import glob, shutil"],"metadata":{"id":"UuchlNA_DftJ","executionInfo":{"status":"ok","timestamp":1679914873188,"user_tz":-540,"elapsed":6,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# 2. Dataset metadata 입력\n","won_list = ['10', '50', '100', '500', '1000', '5000', '10000', '50000']\n","data_path = '/content/Dataset/'"],"metadata":{"id":"Q3lnYcLS_UOy","executionInfo":{"status":"ok","timestamp":1679914873189,"user_tz":-540,"elapsed":6,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["---\n","- 데이터를 Training set | Validation set으로 분할하세요.\n","    - 예시 : Training과 Validation은 8:2로 분리\n","- Hint : 이미지 데이터는 /images에, JSON 데이터는 /labels에 넣어주세요\n","    - 예시 : /dataset/images/train, /dataset/labels/train\n","    - 예제 코드에서는 glob, shutil 모듈을 이용하였습니다.\n","    - [glob document](https://docs.python.org/3/library/glob.html) | [shutil document](https://docs.python.org/3/library/shutil.html)\n","\n","    ※ 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n","    \n","---"],"metadata":{"id":"ihJgeqXJG1Ml"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from PIL import  Image\n","import json\n","import os"],"metadata":{"id":"maK5sYxx1HEA","executionInfo":{"status":"ok","timestamp":1679914873911,"user_tz":-540,"elapsed":728,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# for won in won_list:\n","#  print(won)"],"metadata":{"id":"V_odcYVx3lD3","executionInfo":{"status":"ok","timestamp":1679914874287,"user_tz":-540,"elapsed":379,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["print(len(os.listdir('/content/Dataset/images/train')))\n","print(len(os.listdir('/content/Dataset/labels/train_raw')))\n","print(len(os.listdir('/content/Dataset/images/val')))\n","print(len(os.listdir('/content/Dataset/labels/val_raw')))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jlw_1pAfTd89","executionInfo":{"status":"ok","timestamp":1679914874287,"user_tz":-540,"elapsed":9,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}},"outputId":"b930abbf-80e9-41c2-928d-dec9c51ef8ad"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","0\n","0\n","0\n"]}]},{"cell_type":"code","source":["data_1 = os.listdir('/content/Dataset/images/train')\n","data_2 = os.listdir('/content/Dataset/labels/train_raw')\n","count=0\n","for list1 in data_1:\n","    for list2 in data_2:\n","    # 데이터1이랑 데이터2랑 같으면 count + 1\n","        if os.path.splitext(list1)[0] == os.path.splitext(list2)[0]:\n","            count+=1     \n","            "],"metadata":{"id":"yROLcbqqZkGa","executionInfo":{"status":"ok","timestamp":1679914874288,"user_tz":-540,"elapsed":7,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["count"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A9MzlmL-bF-x","executionInfo":{"status":"ok","timestamp":1679914874289,"user_tz":-540,"elapsed":8,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}},"outputId":"28c89540-0680-4ffe-b798-f32d84d79072"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["# 3. 데이터를 Training set | Validation set으로 분할하세요.\n","data_path = '/content/Dataset/money_data/'\n","for won in won_list :\n","    data = os.listdir(data_path+ won)\n","    \n","    # train_test_split 방식 대신 이 방식으로 나누어 갯수는 맞지만 내용물이 랜덤하게 나뉘어짐. >> 가상환경으로 이동하면서..\n","    split_tr_data = data[:round(len(data)*0.8)]\n","    split_val_data = data[round(len(data)*0.8):]\n","\n","    for filename in split_tr_data:\n","        name=os.path.splitext(filename)[0]\n","        ext = os.path.splitext(filename)[1]\n","        if ext == \".jpg\": # shutil.copy(복사할 파일 경로, 저장할 경로) \n","            shutil.copy(os.path.join(data_path+won, name+'.jpg'), '/content/Dataset/images/train')\n","            shutil.copy(os.path.join(data_path+won, name+'.json'), '/content/Dataset/labels/train_raw')\n","\n","    for filename in split_val_data:\n","        name=os.path.splitext(filename)[0]\n","        ext = os.path.splitext(filename)[1]\n","        \n","        if ext == \".jpg\":\n","            shutil.copy(os.path.join(data_path+won, name+'.jpg'), '/content/Dataset/images/val')\n","            shutil.copy(os.path.join(data_path+won, name+'.json'), '/content/Dataset/labels/val_raw')\n"],"metadata":{"id":"1qfGCSqy_kL0","executionInfo":{"status":"ok","timestamp":1679914877265,"user_tz":-540,"elapsed":2982,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["print(len(os.listdir('/content/Dataset/images/train')))\n","print(len(os.listdir('/content/Dataset/images/val'))) \n","print(len(os.listdir('/content/Dataset/labels/train_raw'))) \n","print(len(os.listdir('/content/Dataset/labels/val_raw')))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lg5JbnISFfsH","executionInfo":{"status":"ok","timestamp":1679914877889,"user_tz":-540,"elapsed":10,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}},"outputId":"14599fb2-7216-4574-ff9e-759c1124a339"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["4183\n","1035\n","4183\n","1035\n"]}]},{"cell_type":"markdown","source":["### (2) json에서 정보 추출\n","---\n","- **세부요구사항**\n","    - json 파일에서 필요한 정보를 추출하세요:\n","        - 위치 정보 : x1, x2, y1, y2\n","        - 박스 정보 : shape_type\n","        - 클래스 정보 : labels\n","    - 화폐당 하나의 클래스로 변경하세요.\n","        - json 파일에는 화폐 클래스가 앞뒷면으로 구분되어 있습니다.\n","        - 화폐의 앞뒷면 구분을 없애주세요.\n","            - 예시 : 'ten_front', 'ten_back' -> 'ten'\n","    - 화폐의 위치 정보를 YOLO 모델 형식에 맞게 변경 해주세요.\n","        - 사용되는 이미지는 원본에서 1/4로 축소되어 있습니다.\n","        - json 파일의 정보는 원본 기준 데이터이므로 위치 정보 추출을 할 때 x값과 y값을 1/4로 줄여주세요.\n","    - 이렇게 변경된 정보를 YOLO label 형식에 맞게 txt파일로 저장 해 주세요.\n","        - Hint : YOLO Labeling Format [label, x-center, y-center, width-norm, height-norm]\n","---"],"metadata":{"id":"II_hsJ6bKYGn"}},{"cell_type":"code","source":["import os, json"],"metadata":{"id":"MgUoCewjM-Jf","executionInfo":{"status":"ok","timestamp":1679914877889,"user_tz":-540,"elapsed":8,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["json_path = '/content/Dataset/labels/'\n","temp_list = ['train_raw', 'val_raw']"],"metadata":{"id":"gBD1Zv9BKaxi","executionInfo":{"status":"ok","timestamp":1679914877890,"user_tz":-540,"elapsed":8,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["!mkdir /content/Dataset/labels/train/\n","!mkdir /content/Dataset/labels/val/"],"metadata":{"id":"YQgxvkEZObYd","executionInfo":{"status":"ok","timestamp":1679914877890,"user_tz":-540,"elapsed":8,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["for i in temp_list :\n","    files = os.listdir(json_path+ i)\n","    for name in files :\n","        # json 파일 불러오기\n","        with open(json_path + i + '/' + name, 'r') as file:\n","            a = json.load(file)\n","            # 위치 정보 추출\n","            x_1 = a['shapes'][0]['points'][0][0]\n","            y_1 = a['shapes'][0]['points'][0][1]\n","            x_2 = a['shapes'][0]['points'][1][0]\n","            y_2 = a['shapes'][0]['points'][1][1]\n","            \n","            # bounding box center 좌표 계산 \n","            center_x = ((x_1 + x_2 )/2)/4\n","            center_y = ((y_1 + y_2)/2)/4\n","\n","            # bounding box 가로 세로 길이 계산 후 사이즈 1/4로 줄이기\n","            width_1 = (x_2 - x_1)/4\n","            height_1 = (y_2 - y_1) /4\n","            \n","            # 원본 이미지 크기 추출\n","            width_image = a['imageWidth']/4\n","            height_image = a['imageHeight']/4\n","\n","            x = center_x/width_image\n","            y = center_y/height_image\n","            \n","            # width, height 크기 줄이기\n","            width = width_1/width_image\n","            height = height_1/height_image\n","            \n","            # 화폐의 클래스 정보를 변환하는 함수\n","            file_name = a['shapes'][0]['label']\n","\n","            if (file_name  == 'Ten_back') or (file_name == 'Ten_front'):\n","                c = 0\n","            elif (file_name  == 'Fifty_front') or (file_name == 'Fifty_back'):\n","                c = 1\n","            elif (file_name  == 'Hundred_front') or (file_name == 'Hundred_back'):\n","                c = 2\n","            elif (file_name  == 'Five_Hundred_front') or (file_name == 'Five_Hundred_back'):\n","                c = 3\n","            elif (file_name  == 'Thousand_front') or (file_name == 'Thousand_back'):\n","                c = 4\n","            elif (file_name  == 'Five_Thousand_front') or (file_name == 'Five_Thousand_back'):\n","                c = 5\n","            elif (file_name  == 'Ten_Thousand_front') or (file_name == 'Ten_Thousand_back'):\n","                c = 6\n","            elif (file_name  == 'Fifty_Thousand_front') or (file_name == 'Fifty_Thousand_back'):\n","                c = 7\n","\n","            # YOLO label 형식으로 변환하여 파일에 저장\n","            txt_name = name.split('.')[0]\n","            folder_name = i.split('_')[0]\n","            f = open(json_path + folder_name +'/'+ txt_name +'.txt', 'w')\n","            # YOLO label 형식으로 변환하여 파일에 저장\n","            result = f'{c} {x} {y} {width} {height}'\n","            f.write(result)\n","            f.close()"],"metadata":{"id":"DdYPyQ8REiD4","executionInfo":{"status":"ok","timestamp":1679914878476,"user_tz":-540,"elapsed":592,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tOQeEhApesWR"},"source":["### (3) 데이터셋 정보가 담긴 파일 생성\n","---\n","- **세부요구사항**\n","    - 파일 안에 있어야 할 정보는 아래와 같습니다.\n","        - 학습할 클래스 이름 정보\n","        - 학습할 클래스 수 정보\n","        - Training, Validation 데이터셋 위치 정보\n","---\n","- 가장 대중적으로 이용하는 라이브러리는 yaml 입니다.\n","    - [yaml document](https://pyyaml.org/wiki/PyYAMLDocumentation)\n","    - 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n","---"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"pu1iQfQolBhJ","executionInfo":{"status":"ok","timestamp":1679914878476,"user_tz":-540,"elapsed":6,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"outputs":[],"source":["import yaml"]},{"cell_type":"code","source":["# y 클래스 정보\n","won_dict = {0:'10', 1:'50', 2:'100', 3:'500', 4:'1000', 5:'5000', 6:'10000', 7:'50000'}"],"metadata":{"id":"t1_uOeXcSvv3","executionInfo":{"status":"ok","timestamp":1679914878477,"user_tz":-540,"elapsed":6,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","execution_count":24,"metadata":{"id":"qvMQcHirmSnD","executionInfo":{"status":"ok","timestamp":1679914878477,"user_tz":-540,"elapsed":6,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"outputs":[],"source":["# 수정 전\n","# data = {\n","#     'names': [won_dict[i] for i in range(len(won_dict))],\n","#     'nc': len(won_dict),\n","#     'datasets': {\n","#         'train': [\n","#             '/content/Dataset/images/train',\n","#             '/content/Dataset/labels/train_txt'\n","#         ],\n","#         'val': [\n","#             '/content/Dataset/images/val',     \n","#             '/content/Dataset/labels/val_txt'     \n","#         ]\n","#     }\n","# }\n","\n","# with open('/content/Dataset/money_data.yaml', 'w') as f:\n","#     yaml.dump(data, f)\n","    "]},{"cell_type":"code","source":["# yaml 파일 작성\n","data = dict(path = '/content/Dataset/',\n","            train = 'images/train',\n","            val = 'images/val',\n","            nc = 8,\n","            names = won_dict)\n","\n","with open('/content/Dataset/money_dataset.yaml', 'w') as f :\n","    yaml.dump(data, f, default_flow_style = False)"],"metadata":{"id":"-dvgrbA8G7Il","executionInfo":{"status":"ok","timestamp":1679914878478,"user_tz":-540,"elapsed":6,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["## 3.모델링"],"metadata":{"id":"3btFvySXi2dt"}},{"cell_type":"markdown","metadata":{"id":"0pQ2gRbTYgLL"},"source":["### (1) 모델 라이브러리 설치\n","---"]},{"cell_type":"code","source":["!pip install jedi"],"metadata":{"id":"73a1l-ZQuHyF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679914883478,"user_tz":-540,"elapsed":5007,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}},"outputId":"279ed8b9-fad5-49d3-e1a3-2d51a59ac22a"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting jedi\n","  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi) (0.8.3)\n","Installing collected packages: jedi\n","Successfully installed jedi-0.18.2\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/ultralytics/yolov5"],"metadata":{"id":"Biyr9AHkMyNf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679914885815,"user_tz":-540,"elapsed":2381,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}},"outputId":"725f521a-d3ed-48b3-a712-5d526afeec49"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 15348, done.\u001b[K\n","remote: Counting objects: 100% (13/13), done.\u001b[K\n","remote: Compressing objects: 100% (13/13), done.\u001b[K\n","remote: Total 15348 (delta 2), reused 6 (delta 0), pack-reused 15335\u001b[K\n","Receiving objects: 100% (15348/15348), 14.16 MiB | 27.71 MiB/s, done.\n","Resolving deltas: 100% (10526/10526), done.\n"]}]},{"cell_type":"code","source":["## yolov5 폴더 requirements.txt 수정 필요\n","## setuptools<=64.0.2\n","\n","temp_str = 'setuptools<=64.0.2\\n'\n","\n","f = open('/content/yolov5/requirements.txt', 'r')\n","f_str = f.readlines()\n","f.close()\n","\n","f2 = open('/content/yolov5/requirements.txt', 'w')\n","\n","for idx, val in enumerate(f_str) :\n","    if 'setuptools' in val :\n","        idx_v = idx\n","        f_str.remove(val)\n","        f_str.insert(idx_v, temp_str)\n","\n","for val in f_str :\n","    f2.write(val)\n","\n","f2.close() "],"metadata":{"id":"W3JjyVOpg26s","executionInfo":{"status":"ok","timestamp":1679914885816,"user_tz":-540,"elapsed":56,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","execution_count":29,"metadata":{"id":"6xD6tBTdMyNg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679914897407,"user_tz":-540,"elapsed":11645,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}},"outputId":"58e0aa54-917c-43c5-8aed-413e3daa8719"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting gitpython>=3.1.30\n","  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 7)) (1.22.4)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 8)) (4.7.0.72)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 9)) (8.4.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 10)) (5.9.4)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 11)) (6.0)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 12)) (2.27.1)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 13)) (1.10.1)\n","Collecting thop>=0.1.1\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 15)) (1.13.1+cu116)\n","Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 16)) (0.14.1+cu116)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 17)) (4.65.0)\n","Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 21)) (2.11.2)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 26)) (1.4.4)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 27)) (0.12.2)\n","Collecting setuptools<=64.0.2\n","  Downloading setuptools-64.0.2-py3-none-any.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (1.4.4)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (3.0.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (23.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (1.0.7)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (4.39.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (0.11.0)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (5.12.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (2.8.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (4.5.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (2.16.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.8.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.4.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.40.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.51.3)\n","Requirement already satisfied: protobuf<4,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (3.19.6)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.4.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.6.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (3.4.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (2.2.3)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 26)) (2022.7.1)\n","Collecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.16.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (4.9)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.2.8)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (5.3.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.3.1)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=3.2.2->-r requirements.txt (line 6)) (3.15.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 21)) (6.1.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r requirements.txt (line 21)) (2.1.2)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 21)) (3.2.2)\n","Installing collected packages: smmap, setuptools, thop, gitdb, gitpython\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 67.6.0\n","    Uninstalling setuptools-67.6.0:\n","      Successfully uninstalled setuptools-67.6.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cvxpy 1.3.1 requires setuptools>65.5.1, but you have setuptools 64.0.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed gitdb-4.0.10 gitpython-3.1.31 setuptools-64.0.2 smmap-5.0.0 thop-0.1.1.post2209072238\n"]}],"source":["# yolo5 폴더 이동 및 requirements.txt 내부 패키지 설치\n","!cd yolov5; pip install -r requirements.txt"]},{"cell_type":"markdown","source":["### (2) 가중치 파일 다운로드\n","---\n","- **세부요구사항**\n","    - 모델 개발자가 제공하는 사전 학습 가중치 파일을 다운로드 하세요.\n","        - 해당 과정이 불필요하다면 넘어가셔도 됩니다!\n","---"],"metadata":{"id":"_mHMAspjR6Xp"}},{"cell_type":"code","source":["# pretrained weights 저장 폴더 생성\n","!mkdir /content/yolov5/pretrained"],"metadata":{"id":"sSVIqkMLDIOd","executionInfo":{"status":"ok","timestamp":1679914897408,"user_tz":-540,"elapsed":8,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["# pretrained weights 다운로드\n","!wget -O /content/yolov5/pretrained/yolov5l.pt https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5l.pt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lwNNemVGemzW","executionInfo":{"status":"ok","timestamp":1679914899204,"user_tz":-540,"elapsed":1802,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}},"outputId":"a390c07d-d457-4b28-d853-6325d8890f7a"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-03-27 11:01:37--  https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5l.pt\n","Resolving github.com (github.com)... 140.82.112.3\n","Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/638b4816-c501-4617-9384-54fd42a62e3a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230327%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230327T110137Z&X-Amz-Expires=300&X-Amz-Signature=73dfc969c06fe80ac8cf39a7ad9dda6be06ace2193898a7cc11206f3b58279bc&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5l.pt&response-content-type=application%2Foctet-stream [following]\n","--2023-03-27 11:01:37--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/638b4816-c501-4617-9384-54fd42a62e3a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230327%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230327T110137Z&X-Amz-Expires=300&X-Amz-Signature=73dfc969c06fe80ac8cf39a7ad9dda6be06ace2193898a7cc11206f3b58279bc&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5l.pt&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 93622629 (89M) [application/octet-stream]\n","Saving to: ‘/content/yolov5/pretrained/yolov5l.pt’\n","\n","/content/yolov5/pre 100%[===================>]  89.29M   188MB/s    in 0.5s    \n","\n","2023-03-27 11:01:37 (188 MB/s) - ‘/content/yolov5/pretrained/yolov5l.pt’ saved [93622629/93622629]\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"W8-5lC4mfbwT"},"source":["### (3) 학습 : train.py\n","---\n","- **세부요구사항**\n","    - UltraLytics YOLO v5에는 아래의 데이터가 필요합니다.\n","        - 데이터셋 정보가 담긴 yaml 파일\n","        - 사용하려는 모델 구조에 대한 yaml 파일\n","        - 사용하려는 모델의 가중치 파일\n","---"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"4AYFDMaVfmTK","executionInfo":{"status":"ok","timestamp":1679914899207,"user_tz":-540,"elapsed":24,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"outputs":[],"source":["# !cd yolov5; python train.py -h\n"]},{"cell_type":"code","source":["!cd yolov5; python train.py \\\n","    --data '/content/Dataset/money_dataset.yaml' \\\n","    --cfg '/content/yolov5/models/yolov5l.yaml' \\\n","    --weights '/content/yolov5/pretrained/yolov5l.pt' \\\n","    --epochs 1000 \\\n","    --patience 7 \\\n","    --img 640 \\\n","    --project '/content/yolov5/trained' \\\n","    --name 'train_money_data' \\\n","    --exist-ok"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RcSMyEAqfjCe","executionInfo":{"status":"ok","timestamp":1679931607627,"user_tz":-540,"elapsed":16708442,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}},"outputId":"afe6ca99-6173-46d8-939d-5d49e3c086e8"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mweights=/content/yolov5/pretrained/yolov5l.pt, cfg=/content/yolov5/models/yolov5l.yaml, data=/content/Dataset/money_dataset.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=1000, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=/content/yolov5/trained, name=train_money_data, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=7, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n","YOLOv5 🚀 v7.0-129-gb54fd0a Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/yolov5/trained', view at http://localhost:6006/\n","2023-03-27 11:01:46.195433: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-03-27 11:01:47.818447: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n","2023-03-27 11:01:47.825633: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n","2023-03-27 11:01:47.825666: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","100% 755k/755k [00:00<00:00, 17.4MB/s]\n","Overriding model.yaml nc=80 with nc=8\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n","  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n","  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n","  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n","  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n","  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n","  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n"," 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n"," 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n"," 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n"," 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n"," 24      [17, 20, 23]  1     70005  models.yolo.Detect                      [8, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n","YOLOv5l summary: 368 layers, 46175989 parameters, 46175989 gradients, 108.3 GFLOPs\n","\n","Transferred 606/613 items from /content/yolov5/pretrained/yolov5l.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0005), 104 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Dataset/labels/train... 4183 images, 0 backgrounds, 0 corrupt: 100% 4183/4183 [00:02<00:00, 1952.26it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Dataset/labels/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Dataset/labels/val... 1035 images, 0 backgrounds, 0 corrupt: 100% 1035/1035 [00:02<00:00, 486.52it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Dataset/labels/val.cache\n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.01 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n","Plotting labels to /content/yolov5/trained/train_money_data/labels.jpg... \n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/content/yolov5/trained/train_money_data\u001b[0m\n","Starting training for 1000 epochs...\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      0/999      10.1G    0.05012    0.02113    0.05068         17        640: 100% 262/262 [03:43<00:00,  1.17it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:22<00:00,  1.49it/s]\n","                   all       1035       1035      0.291       0.66      0.486       0.32\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      1/999      12.7G    0.03715     0.0104    0.03142         13        640: 100% 262/262 [03:38<00:00,  1.20it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:21<00:00,  1.51it/s]\n","                   all       1035       1035      0.495      0.898      0.739      0.513\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      2/999      12.7G    0.03498   0.007949    0.02041         15        640: 100% 262/262 [03:36<00:00,  1.21it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:21<00:00,  1.55it/s]\n","                   all       1035       1035      0.695      0.846      0.859      0.601\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      3/999      12.7G    0.02872   0.007101    0.01734         13        640: 100% 262/262 [03:35<00:00,  1.22it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:22<00:00,  1.46it/s]\n","                   all       1035       1035      0.925      0.842      0.948      0.717\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      4/999      12.7G     0.0248   0.006522    0.01489         17        640: 100% 262/262 [03:34<00:00,  1.22it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:22<00:00,  1.46it/s]\n","                   all       1035       1035      0.812      0.775      0.876      0.734\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      5/999      12.7G    0.02251   0.006305    0.01375         17        640: 100% 262/262 [03:35<00:00,  1.21it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:22<00:00,  1.47it/s]\n","                   all       1035       1035       0.92      0.915      0.939       0.83\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      6/999      12.7G    0.02098   0.005912    0.01274         18        640: 100% 262/262 [03:32<00:00,  1.23it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:20<00:00,  1.63it/s]\n","                   all       1035       1035      0.911      0.894      0.958       0.84\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      7/999      12.7G    0.02002   0.005896    0.01221         19        640: 100% 262/262 [03:31<00:00,  1.24it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:21<00:00,  1.55it/s]\n","                   all       1035       1035      0.957      0.964      0.984      0.876\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      8/999      12.7G    0.01874   0.005638    0.01164         10        640: 100% 262/262 [03:31<00:00,  1.24it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:21<00:00,  1.50it/s]\n","                   all       1035       1035      0.955      0.915      0.967      0.878\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      9/999      12.7G    0.01867   0.005463    0.01176         14        640: 100% 262/262 [03:31<00:00,  1.24it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:20<00:00,  1.61it/s]\n","                   all       1035       1035      0.957       0.96      0.979      0.867\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     10/999      12.7G    0.01804   0.005432    0.01014         17        640: 100% 262/262 [03:31<00:00,  1.24it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:21<00:00,  1.51it/s]\n","                   all       1035       1035      0.988      0.973      0.992      0.914\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     11/999      12.7G    0.01755   0.005329   0.009486         13        640: 100% 262/262 [03:31<00:00,  1.24it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:20<00:00,  1.60it/s]\n","                   all       1035       1035      0.986      0.977      0.993      0.925\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     12/999      12.7G    0.01692   0.005066   0.009078         20        640: 100% 262/262 [03:30<00:00,  1.24it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:22<00:00,  1.48it/s]\n","                   all       1035       1035       0.99      0.986      0.993      0.945\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     13/999      12.7G    0.01623   0.005192   0.009247         13        640: 100% 262/262 [03:31<00:00,  1.24it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:20<00:00,  1.58it/s]\n","                   all       1035       1035      0.985      0.979      0.991       0.93\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     14/999      12.7G     0.0153   0.004937   0.008582         17        640: 100% 262/262 [03:33<00:00,  1.23it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:20<00:00,  1.60it/s]\n","                   all       1035       1035      0.968      0.954      0.986      0.923\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     15/999      12.7G    0.01559   0.004924   0.009443         11        640: 100% 262/262 [03:31<00:00,  1.24it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:21<00:00,  1.56it/s]\n","                   all       1035       1035       0.98       0.98      0.991      0.929\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     16/999      12.7G    0.01518   0.004875   0.008271         16        640: 100% 262/262 [03:30<00:00,  1.24it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:21<00:00,  1.56it/s]\n","                   all       1035       1035      0.984      0.984      0.994      0.936\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     17/999      12.7G    0.01487   0.004873   0.008005         15        640: 100% 262/262 [03:31<00:00,  1.24it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:21<00:00,  1.55it/s]\n","                   all       1035       1035      0.993      0.986      0.994      0.948\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     18/999      12.7G    0.01482   0.004616   0.007769         15        640: 100% 262/262 [03:32<00:00,  1.24it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:20<00:00,  1.59it/s]\n","                   all       1035       1035      0.984      0.991      0.993      0.939\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     19/999      12.7G    0.01431   0.004743   0.008157         17        640: 100% 262/262 [03:31<00:00,  1.24it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:22<00:00,  1.47it/s]\n","                   all       1035       1035      0.984       0.98       0.99      0.937\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     20/999      12.7G    0.01388   0.004639   0.007994         14        640: 100% 262/262 [03:33<00:00,  1.23it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:20<00:00,  1.61it/s]\n","                   all       1035       1035      0.992      0.987      0.992      0.963\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     21/999      12.7G    0.01409   0.004598   0.007214         15        640: 100% 262/262 [03:30<00:00,  1.24it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:22<00:00,  1.49it/s]\n","                   all       1035       1035       0.99      0.982      0.992      0.958\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     22/999      12.7G    0.01367   0.004468   0.006723          9        640: 100% 262/262 [03:31<00:00,  1.24it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:20<00:00,  1.61it/s]\n","                   all       1035       1035      0.994      0.995      0.995      0.958\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     23/999      12.7G    0.01322   0.004379   0.006472         16        640: 100% 262/262 [03:31<00:00,  1.24it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:23<00:00,  1.41it/s]\n","                   all       1035       1035      0.992      0.987      0.993       0.96\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     24/999      12.7G    0.01283   0.004304   0.006837         10        640: 100% 262/262 [03:34<00:00,  1.22it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:22<00:00,  1.49it/s]\n","                   all       1035       1035      0.993      0.981      0.994      0.967\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     25/999      12.7G    0.01275   0.004384   0.006561         11        640: 100% 262/262 [03:31<00:00,  1.24it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:20<00:00,  1.58it/s]\n","                   all       1035       1035      0.977      0.978      0.988      0.957\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     26/999      12.7G     0.0127   0.004321   0.006823         16        640: 100% 262/262 [03:32<00:00,  1.23it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:22<00:00,  1.50it/s]\n","                   all       1035       1035      0.992      0.993      0.994      0.958\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     27/999      12.7G    0.01243   0.004297   0.006405         14        640: 100% 262/262 [03:32<00:00,  1.23it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:20<00:00,  1.58it/s]\n","                   all       1035       1035       0.99      0.993      0.993      0.967\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     28/999      12.7G    0.01225    0.00418   0.006214         14        640: 100% 262/262 [03:31<00:00,  1.24it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:22<00:00,  1.46it/s]\n","                   all       1035       1035      0.987      0.992      0.993      0.971\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     29/999      12.7G    0.01215   0.004223   0.006609         10        640: 100% 262/262 [03:31<00:00,  1.24it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:20<00:00,  1.57it/s]\n","                   all       1035       1035      0.991      0.988      0.993      0.966\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     30/999      12.7G    0.01192   0.004203   0.006011         12        640: 100% 262/262 [03:32<00:00,  1.23it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:21<00:00,  1.52it/s]\n","                   all       1035       1035      0.986      0.975      0.993      0.964\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     31/999      12.7G    0.01184   0.004245   0.005864         17        640: 100% 262/262 [03:30<00:00,  1.24it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:20<00:00,  1.59it/s]\n","                   all       1035       1035      0.993      0.994      0.995      0.975\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     32/999      12.7G    0.01176   0.004042   0.004884         16        640: 100% 262/262 [03:31<00:00,  1.24it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:20<00:00,  1.60it/s]\n","                   all       1035       1035      0.995      0.997      0.995      0.965\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     33/999      12.7G    0.01189   0.004033   0.005819         15        640: 100% 262/262 [03:31<00:00,  1.24it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:20<00:00,  1.58it/s]\n","                   all       1035       1035      0.987      0.997      0.995      0.966\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     34/999      12.7G    0.01198   0.004161   0.005858         14        640: 100% 262/262 [03:32<00:00,  1.23it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:21<00:00,  1.52it/s]\n","                   all       1035       1035      0.991      0.989      0.995      0.965\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     35/999      12.7G    0.01189   0.004125    0.00599         13        640: 100% 262/262 [03:32<00:00,  1.23it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:21<00:00,  1.53it/s]\n","                   all       1035       1035      0.994      0.997      0.994      0.977\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     36/999      12.7G    0.01153   0.004023   0.005911         15        640: 100% 262/262 [03:33<00:00,  1.23it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:20<00:00,  1.57it/s]\n","                   all       1035       1035      0.988      0.993      0.994      0.983\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     37/999      12.7G    0.01116   0.003911   0.005829         12        640: 100% 262/262 [03:32<00:00,  1.23it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:22<00:00,  1.46it/s]\n","                   all       1035       1035      0.992      0.992      0.994      0.981\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     38/999      12.7G    0.01104   0.003881   0.005946         16        640: 100% 262/262 [03:31<00:00,  1.24it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:20<00:00,  1.58it/s]\n","                   all       1035       1035      0.994      0.994      0.995      0.982\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     39/999      12.7G    0.01091   0.003967   0.005806         16        640: 100% 262/262 [03:30<00:00,  1.25it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:22<00:00,  1.45it/s]\n","                   all       1035       1035      0.994      0.991      0.994      0.975\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     40/999      12.7G    0.01123   0.003974   0.005801         17        640: 100% 262/262 [03:32<00:00,  1.23it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:21<00:00,  1.51it/s]\n","                   all       1035       1035      0.996      0.992      0.995      0.978\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     41/999      12.7G     0.0113   0.003981   0.005568         13        640: 100% 262/262 [03:32<00:00,  1.23it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:21<00:00,  1.55it/s]\n","                   all       1035       1035      0.998      0.996      0.995       0.98\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     42/999      12.7G    0.01054   0.003833   0.004895         20        640: 100% 262/262 [03:35<00:00,  1.22it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:22<00:00,  1.48it/s]\n","                   all       1035       1035      0.989      0.991      0.995      0.981\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     43/999      12.7G    0.01067    0.00384   0.005633         16        640: 100% 262/262 [03:34<00:00,  1.22it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:22<00:00,  1.49it/s]\n","                   all       1035       1035      0.998      0.999      0.995      0.984\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     44/999      12.7G     0.0108   0.003915   0.004247         10        640: 100% 262/262 [03:34<00:00,  1.22it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:21<00:00,  1.55it/s]\n","                   all       1035       1035      0.999      0.998      0.995      0.984\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     45/999      12.7G    0.01059   0.003756   0.004465         14        640: 100% 262/262 [03:38<00:00,  1.20it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:21<00:00,  1.52it/s]\n","                   all       1035       1035      0.996      0.997      0.995      0.986\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     46/999      12.7G    0.01067   0.003795   0.004266         17        640: 100% 262/262 [03:36<00:00,  1.21it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:21<00:00,  1.54it/s]\n","                   all       1035       1035      0.992      0.995      0.995      0.983\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     47/999      12.7G    0.01077   0.003789    0.00525         14        640: 100% 262/262 [03:34<00:00,  1.22it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:22<00:00,  1.46it/s]\n","                   all       1035       1035      0.993      0.993      0.995      0.982\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     48/999      12.7G    0.01112   0.003801   0.005076         10        640: 100% 262/262 [03:35<00:00,  1.22it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:22<00:00,  1.44it/s]\n","                   all       1035       1035      0.995      0.996      0.994      0.979\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     49/999      12.7G    0.01063   0.003821   0.005139         18        640: 100% 262/262 [03:35<00:00,  1.22it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:22<00:00,  1.47it/s]\n","                   all       1035       1035      0.996      0.996      0.995      0.985\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     50/999      12.7G    0.01028   0.003772    0.00515         17        640: 100% 262/262 [03:35<00:00,  1.21it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:21<00:00,  1.53it/s]\n","                   all       1035       1035      0.998      0.997      0.995      0.986\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     51/999      12.7G     0.0106   0.003755   0.004813         18        640: 100% 262/262 [03:37<00:00,  1.21it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:20<00:00,  1.58it/s]\n","                   all       1035       1035      0.998      0.995      0.995      0.987\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     52/999      12.7G    0.01031   0.003734   0.004877         16        640: 100% 262/262 [03:34<00:00,  1.22it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:21<00:00,  1.56it/s]\n","                   all       1035       1035      0.993      0.993      0.994      0.985\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     53/999      12.7G    0.01032   0.003728   0.004671         20        640: 100% 262/262 [03:36<00:00,  1.21it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:22<00:00,  1.44it/s]\n","                   all       1035       1035      0.997      0.997      0.995      0.987\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     54/999      12.7G    0.01006   0.003676   0.004803         16        640: 100% 262/262 [03:35<00:00,  1.21it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:23<00:00,  1.42it/s]\n","                   all       1035       1035      0.994      0.994      0.995      0.988\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     55/999      12.7G    0.01006   0.003698   0.004443         17        640: 100% 262/262 [03:35<00:00,  1.21it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:21<00:00,  1.50it/s]\n","                   all       1035       1035      0.994       0.99      0.994      0.984\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     56/999      12.7G   0.009929    0.00359   0.004941         17        640: 100% 262/262 [03:35<00:00,  1.21it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:21<00:00,  1.57it/s]\n","                   all       1035       1035      0.996      0.992      0.995      0.986\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     57/999      12.7G    0.01004   0.003676   0.005325         18        640: 100% 262/262 [03:36<00:00,  1.21it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:21<00:00,  1.56it/s]\n","                   all       1035       1035      0.993      0.999      0.995      0.987\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     58/999      12.7G    0.01016   0.003688   0.004768         15        640: 100% 262/262 [03:34<00:00,  1.22it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:22<00:00,  1.46it/s]\n","                   all       1035       1035      0.999      0.999      0.995      0.988\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     59/999      12.7G    0.01008   0.003613   0.004435         25        640: 100% 262/262 [03:34<00:00,  1.22it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:21<00:00,  1.51it/s]\n","                   all       1035       1035      0.995      0.999      0.994      0.987\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     60/999      12.7G   0.009898   0.003608   0.004462         13        640: 100% 262/262 [03:34<00:00,  1.22it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:21<00:00,  1.57it/s]\n","                   all       1035       1035      0.995      0.997      0.995      0.988\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     61/999      12.7G   0.009907   0.003618   0.003963         21        640: 100% 262/262 [03:33<00:00,  1.23it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:22<00:00,  1.46it/s]\n","                   all       1035       1035      0.997      0.997      0.993      0.987\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     62/999      12.7G   0.009699    0.00353   0.004075         17        640: 100% 262/262 [03:33<00:00,  1.23it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:21<00:00,  1.56it/s]\n","                   all       1035       1035      0.991      0.997      0.995       0.99\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     63/999      12.7G   0.009691   0.003571   0.004105         16        640: 100% 262/262 [03:33<00:00,  1.23it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:20<00:00,  1.58it/s]\n","                   all       1035       1035      0.995      0.997      0.995      0.988\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     64/999      12.7G    0.01002   0.003555   0.004147         11        640: 100% 262/262 [03:33<00:00,  1.23it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:22<00:00,  1.45it/s]\n","                   all       1035       1035      0.999      0.999      0.995      0.987\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     65/999      12.7G   0.009646   0.003591   0.004169         15        640: 100% 262/262 [03:34<00:00,  1.22it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:22<00:00,  1.47it/s]\n","                   all       1035       1035      0.999          1      0.995      0.988\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     66/999      12.7G   0.009467   0.003586   0.003641         18        640: 100% 262/262 [03:33<00:00,  1.23it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:21<00:00,  1.56it/s]\n","                   all       1035       1035      0.999      0.999      0.995      0.987\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     67/999      12.7G   0.009693   0.003561   0.004058         20        640: 100% 262/262 [03:30<00:00,  1.24it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:22<00:00,  1.49it/s]\n","                   all       1035       1035      0.998      0.998      0.995      0.989\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     68/999      12.7G   0.009599   0.003509    0.00389         15        640: 100% 262/262 [03:30<00:00,  1.24it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:20<00:00,  1.63it/s]\n","                   all       1035       1035      0.997      0.997      0.994      0.988\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","     69/999      12.7G   0.009487   0.003624   0.003413         18        640: 100% 262/262 [03:31<00:00,  1.24it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:22<00:00,  1.47it/s]\n","                   all       1035       1035      0.998      0.998      0.995       0.99\n","Stopping training early as no improvement observed in last 7 epochs. Best results observed at epoch 62, best model saved as best.pt.\n","To update EarlyStopping(patience=7) pass a new patience value, i.e. `python train.py --patience 300` or use `--patience 0` to disable EarlyStopping.\n","\n","70 epochs completed in 4.620 hours.\n","Optimizer stripped from /content/yolov5/trained/train_money_data/weights/last.pt, 92.8MB\n","Optimizer stripped from /content/yolov5/trained/train_money_data/weights/best.pt, 92.8MB\n","\n","Validating /content/yolov5/trained/train_money_data/weights/best.pt...\n","Fusing layers... \n","YOLOv5l summary: 267 layers, 46145973 parameters, 0 gradients, 107.8 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:23<00:00,  1.41it/s]\n","                   all       1035       1035      0.991      0.997      0.995       0.99\n","                    10       1035         87      0.992          1      0.995      0.988\n","                    50       1035         87      0.995          1      0.995      0.985\n","                   100       1035         81       0.95          1      0.995       0.99\n","                   500       1035         85          1      0.978      0.995      0.987\n","                  1000       1035        173      0.998          1      0.995      0.991\n","                  5000       1035        165      0.996          1      0.995      0.994\n","                 10000       1035        171      0.998          1      0.995      0.992\n","                 50000       1035        186      0.998          1      0.995      0.993\n","Results saved to \u001b[1m/content/yolov5/trained/train_money_data\u001b[0m\n"]}]},{"cell_type":"markdown","metadata":{"id":"u2YESAa5fc4M"},"source":["## 4.탐지 : detect.py\n","---\n","- **세부요구사항**\n","    - 학습 과정에서 생성된 가중치 파일을 이용하세요.\n","    - IoU threshold를 0.25 이하로 설정하세요.\n","    - confidence threshold를 0.75 이상으로 설정하세요.\n","---\n","- 여러분이 **직접 촬영한 화폐 사진과 동영상**을 탐지 과정에 이용하여 결과를 확인하세요.\n","    - 조건\n","        1. 화폐의 수를 늘려가며 촬영 해보세요.\n","            - ex) 50원 하나, 50원 둘, 50원 셋, ...\n","        2. 화폐의 종류를 늘려가며 촬영 해보세요.\n","            - ex) 50원 하나와 100원 하나, 50원 하나와 100원 하나와 1000원 하나, ...\n","        3. 사진은 최소 30장 이상, 동영상은 최소 하나 이상 촬영하여 사용 해보세요.\n","---"]},{"cell_type":"code","source":["test_data = zipfile.ZipFile( '/content/drive/MyDrive/Datasets/test.zip' )"],"metadata":{"id":"_Pfi_0l0cqEx","executionInfo":{"status":"ok","timestamp":1679931608233,"user_tz":-540,"elapsed":612,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["test_data.extractall('/content/drive/MyDrive/Datasets/')"],"metadata":{"id":"rk2blPIZcqzy","executionInfo":{"status":"ok","timestamp":1679931627330,"user_tz":-540,"elapsed":19100,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["!cd yolov5; python detect.py \\\n","    --weights '/content/yolov5/trained/money/weights/best.pt' \\\n","    --source '/content/drive/MyDrive/Datasets/test/00e9142def4da14905847fbc307d6bfa.jpg' \\\n","    --project '/content/yolov5/detected/' \\\n","    --name 'images' \\\n","    --img 640 \\\n","    --conf-thres 0.5 \\\n","    --iou-thres 0.4 \\\n","    --line-thickness 2 \\\n","    --exist-ok"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A13gGvNNcqwK","executionInfo":{"status":"ok","timestamp":1679931634629,"user_tz":-540,"elapsed":7332,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}},"outputId":"980dcda0-a2c9-4953-a160-c839801b2702"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov5/trained/money/weights/best.pt'], source=/content/drive/MyDrive/Datasets/test/00e9142def4da14905847fbc307d6bfa.jpg, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.5, iou_thres=0.4, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=/content/yolov5/detected/, name=images, exist_ok=True, line_thickness=2, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n","YOLOv5 🚀 v7.0-129-gb54fd0a Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n","\n","Traceback (most recent call last):\n","  File \"/content/yolov5/detect.py\", line 261, in <module>\n","    main(opt)\n","  File \"/content/yolov5/detect.py\", line 256, in main\n","    run(**vars(opt))\n","  File \"/usr/local/lib/python3.9/dist-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n","    return func(*args, **kwargs)\n","  File \"/content/yolov5/detect.py\", line 98, in run\n","    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)\n","  File \"/content/yolov5/models/common.py\", line 344, in __init__\n","    model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)\n","  File \"/content/yolov5/models/experimental.py\", line 79, in attempt_load\n","    ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n","  File \"/usr/local/lib/python3.9/dist-packages/torch/serialization.py\", line 771, in load\n","    with _open_file_like(f, 'rb') as opened_file:\n","  File \"/usr/local/lib/python3.9/dist-packages/torch/serialization.py\", line 270, in _open_file_like\n","    return _open_file(name_or_buffer, mode)\n","  File \"/usr/local/lib/python3.9/dist-packages/torch/serialization.py\", line 251, in __init__\n","    super(_open_file, self).__init__(open(name, mode))\n","FileNotFoundError: [Errno 2] No such file or directory: '/content/yolov5/trained/money/weights/best.pt'\n"]}]},{"cell_type":"code","source":["from IPython.display import Image\n","from google.colab import files"],"metadata":{"id":"fEAW28pmcqrb","executionInfo":{"status":"ok","timestamp":1679931634630,"user_tz":-540,"elapsed":29,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["Image(filename='/content/yolov3/detected/images/00e9142def4da14905847fbc307d6bfa.jpg', width=640)"],"metadata":{"id":"yzgQ2Qkhc3Cl","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"error","timestamp":1679931634630,"user_tz":-540,"elapsed":28,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}},"outputId":"1fbab79e-a252-47a6-d4ee-d83d60259286"},"execution_count":38,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-38-c70c4d1c12ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/yolov3/detected/images/00e9142def4da14905847fbc307d6bfa.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m   1201\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretina\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m         super(Image, self).__init__(data=data, url=url, filename=filename, \n\u001b[0m\u001b[1;32m   1204\u001b[0m                 metadata=metadata)\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1233\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    650\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/yolov3/detected/images/00e9142def4da14905847fbc307d6bfa.jpg'"]}]},{"cell_type":"code","source":["!cd yolov5; python detect.py \\\n","    --weights '/content/yolov5/trained/train_money_data/weights/best.pt' \\\n","    --source '/content/drive/MyDrive/Datasets/test/' \\\n","    --project '/content/yolov5/detected/' \\\n","    --name 'images' \\\n","    --img 640 \\\n","    --conf-thres 0.5 \\\n","    --iou-thres 0.4 \\\n","    --line-thickness 2 \\\n","    --exist-ok"],"metadata":{"id":"9rK0ClfTcjEZ","executionInfo":{"status":"aborted","timestamp":1679931634632,"user_tz":-540,"elapsed":10,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import urllib.request\n","import os\n","\n","def download_session_folder():\n","    # Replace the URL with your own Cloud Storage URL\n","    url = \"/content/yolov5/detected/images\"\n","\n","    # Replace the folder name with your own folder name\n","    folder_name = \"week5_session\"\n","\n","    # Download the zip file from the Cloud Storage URL\n","    urllib.request.urlretrieve(url, f\"{folder_name}.zip\")\n","\n","    # Unzip the downloaded file\n","    os.system(f\"unzip {folder_name}.zip\")\n","\n","    # Remove the zip file\n","    os.system(f\"rm {folder_name}.zip\")\n","\n","    print(\"Session folder download complete.\")\n","\n","download_session_folder()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":360},"id":"lUs9y1vTcllL","executionInfo":{"status":"error","timestamp":1679646364557,"user_tz":-540,"elapsed":449,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}},"outputId":"b80f8762-a773-4e7a-b921-060631816925"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-732a32765a11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Session folder download complete.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mdownload_session_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-42-732a32765a11>\u001b[0m in \u001b[0;36mdownload_session_folder\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Download the zip file from the Cloud Storage URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{folder_name}.zip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Unzip the downloaded file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0murl_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_splittype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;31m# accept a URL or a Request object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullurl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullurl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfullurl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, url, data, headers, origin_req_host, unverifiable, method)\u001b[0m\n\u001b[1;32m    318\u001b[0m                  \u001b[0morigin_req_host\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munverifiable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                  method=None):\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munredirected_hdrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36mfull_url\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfragment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_splittag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeleter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_splittype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unknown url type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_splithost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: unknown url type: '/content/yolov5/detected/images'"]}]}]}