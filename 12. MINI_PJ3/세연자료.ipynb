{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLojLUpcGNbk"
      },
      "source": [
        "# **차량 공유업체의 차량 파손 여부 분류하기**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbrllJY8JdkF"
      },
      "source": [
        "## 0.미션\n",
        "\n",
        "* 1) 미션1 : Data Preprocessing\n",
        "    - **과제 수행 목표**\n",
        "        - 본인의 구글 드라이브에 모델링 수행을 위해 적절한 폴더 및 파일로 **일관성 있게 정리**해야 합니다.\n",
        "        - 제공된 데이터 : Car_Images.zip\n",
        "            * Car_Images : 차량의 정상/파손 이미지 무작위 수집"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hgdg96jE-mmd"
      },
      "source": [
        "* 2) 미션2 : CNN 모델링\n",
        "    - **과제 수행 목표**\n",
        "        - Tensorflow Keras를 이용하여 모델을 3개 이상 생성하세요.\n",
        "            - 모델 구조와 파라미터는 자유롭게 구성하세요.\n",
        "            - 단, 세부 목차에서 명시한 부분은 지켜주세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRrUY4ud_rJV"
      },
      "source": [
        "* 3) 미션3 : Data Argumentation & Transfer Learning\n",
        "    - **과제 수행 목표**\n",
        "        - 성능 개선을 위해 다음의 두가지를 시도하세요.\n",
        "            * Data Augmentation을 적용하세요.(Image Generator)\n",
        "            * Transfer Learning(VGG16)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MdjZtxfGNKz"
      },
      "source": [
        "## 1.환경설정 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QgFWzN9xhlr"
      },
      "source": [
        "### (1) 데이터셋 폴더 생성\n",
        "- **세부요구사항**\n",
        "    - C드라이브에 Datasets라는 폴더를 만드세요.\n",
        "        - 구글드라이브를 사용하는경우 드라이브 첫 화면에 Datasets 라는 폴더를 만드세요. ('/content/drive/MyDrive/Datasets/')\n",
        "    - 해당 폴더 안에 Car_Images.zip 파일을 넣으세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Elg8NL8vwUs5"
      },
      "source": [
        "* 구글 Colab을 이용하는 경우"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWUbDvBzwiTq",
        "outputId": "6168bb56-d207-43ce-d443-894cbe3df963"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sVNbCKnLUGc"
      },
      "source": [
        "### (2) 데이터셋 불러오기 \n",
        "- **세부요구사항**\n",
        "    - Car_Images.zip 파일을 C:/Datasets/ 경로에 압축 해제합니다.\n",
        "    - zipfile 모듈을 이용하거나 다른 방식을 사용해도 됩니다.\n",
        "        - 참고 자료 : [zipfile document](https://docs.python.org/3/library/zipfile.html#zipfile-objects)\n",
        "    - 폴더구조(로컬)\n",
        "        * C:/Datasets/ : 압축파일\n",
        "        * C:/Datasets/Car_Images_train/ : 압축 해제한 이미지 저장소\n",
        "    - 폴더구조(구글드라이브브)\n",
        "        * /content/drive/MyDrive/Datasets/ : 압축파일\n",
        "        * /content/drive/MyDrive/Datasets/Car_Images_train/ : 압축 해제한 이미지 저장소\n",
        "    - 압축을 해제하면 다음과 같은 두 하위 폴더가 생성됩니다.\n",
        "        * normal, abnormal : 각 폴더에는 이미지들이 있습니다.\n",
        "        * 이후 단계에서 해당 경로로 부터 validation, test 셋을 추출하게 됩니다.\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "K2-8EaA9x4Xm"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import glob\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hMkstFLKx4Xm"
      },
      "outputs": [],
      "source": [
        "# 압축파일 경로\n",
        "# 구글 드라이브인 경우 경로에 맞게 지정하세요.\n",
        "# dataset_path  = '/content/drive/MyDrive/Datasets/'\n",
        "dataset_path = 'C:/Datasets/'\n",
        "\n",
        "file_path = dataset_path + 'Car_Images.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sgT_RB14Lwza"
      },
      "outputs": [],
      "source": [
        "# 압축 해제\n",
        "# data = zipfile.ZipFile(file_path)\n",
        "# data.extractall(/content/drive/MyDrive/Datasets/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hgC0axQyMhI"
      },
      "source": [
        "### (3) 이미지 저장을 위한 폴더 생성\n",
        "- **세부요구사항**\n",
        "    - train, validation, test 을 위해 각각 하위 폴더 normal과 abnormal를 준비합니다.\n",
        "        - train\n",
        "            * 정상 이미지 저장소 : C:/Datasets/Car_Images_train/normal/ \n",
        "                * 구글드라이브 :   /content/drive/MyDrive/Datasets/Car_Images_train/normal/\n",
        "            * 파손 이미지 저장소 : C:/Datasets/Car_Images_train/abnormal/\n",
        "                * 구글드라이브 : /content/drive/MyDrive/Datasets/Car_Images_train/abnormal/\n",
        "        - val, test 역시 동일한 구조로 생성합니다.\n",
        "    - 직접 탐색기에서 폴더를 생성할 수도 있고, os 모듈을 이용하여 코드로 작성할 수도 있습니다.\n",
        "        - 참고 자료 : [os document](https://docs.python.org/3/library/os.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rc8GnuauOzLf"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 각각 경로 지정\n",
        "\n",
        "\n",
        "\n",
        "# train 폴더는 압축을 해제하면서 이미 생성 되어 있습니다.\n",
        "os.makedirs('/content/drive/MyDrive/datasets/Car_Images_train/normal')\n",
        "os.makedirs('/content/drive/MyDrive/datasets/Car_Images_train/abnormal')\n",
        "\n",
        "# test 폴더 만들기 os.mkdir()\n",
        "os.makedirs('/content/drive/MyDrive/datasets/Car_Images_test/normal')\n",
        "os.makedirs('/content/drive/MyDrive/datasets/Car_Images_test/abnormal')\n",
        "\n",
        "# validation 폴더 만들기\n",
        "os.makedirs('/content/drive/MyDrive/datasets/Car_Images_val/normal')\n",
        "os.makedirs('/content/drive/MyDrive/datasets/Car_Images_val/abnormal')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYZKJrP0GtPh"
      },
      "source": [
        "## 2.데이터 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-ilpDQfInAE"
      },
      "source": [
        "### (1) 데이터 분할 : Training set | Validation set | Test set 생성\n",
        "- **세부요구사항**\n",
        "    - Training set, Validation set, Test set을 만듭니다.\n",
        "        * size\n",
        "            * test : 전체에서 20%를 추출합니다.\n",
        "            * validation : test를 떼어낸 나머지에서 다시 20%를 추출합니다.\n",
        "        * 데이터는 랜덤하게 추출해야 합니다.\n",
        "            - random, shutil 모듈을 이용하여 랜덤하게 추출할 수 있습니다.\n",
        "                - [random document](https://docs.python.org/3/library/random.html) | [shutil document](https://docs.python.org/3/library/shutil.html)\n",
        "            * 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFMSDA26RS-E"
      },
      "source": [
        "#### 1) test, validation 크기를 지정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhQ_Gu_KNR2g"
      },
      "outputs": [],
      "source": [
        "import random, shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVHsJi9Cpy1y"
      },
      "outputs": [],
      "source": [
        "data_n_path = '/content/drive/MyDrive/Car_Images.zip (Unzipped Files)/normal'\n",
        "data_ab_path = '/content/drive/MyDrive/Car_Images.zip (Unzipped Files)/abnormal'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdU7X9e70dBu",
        "outputId": "e735fcc4-7a29-4b0d-a336-b96ccd84437a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(302, 303)"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 전체 이미지 갯수를 확인합니다.\n",
        "len(os.listdir(data_n_path)) , len(os.listdir(data_ab_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oa2mxylBDVM5",
        "outputId": "8cf12ab2-bf6c-4ccd-e34e-38c7da36a067"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[60, 61]\n",
            "[48, 48]\n",
            "[194, 194]\n"
          ]
        }
      ],
      "source": [
        "# test 사이즈 : 전체 이미지의 20%\n",
        "te_data_num = [round(len(os.listdir(data_n_path))*0.2), round(len(os.listdir(data_ab_path))*0.2)]\n",
        "print(te_data_num)\n",
        "\n",
        "# validation 사이즈 : test를 제외한 나머지 중에서 20%\n",
        "val_data_num = [ round((len(os.listdir(data_n_path))-te_data_num[0])*0.2) , round((len(os.listdir(data_n_path))-te_data_num[1])*0.2) ]\n",
        "print(val_data_num)\n",
        "\n",
        "# train 사이즈\n",
        "train_data_num = [len(os.listdir(data_n_path)) - te_data_num[0] - val_data_num[0],\n",
        "                  len(os.listdir(data_ab_path))- te_data_num[1] - val_data_num[1]]\n",
        "print(train_data_num)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmRhrViWRXgL"
      },
      "source": [
        "#### 2) test 셋 추출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qvfp2dCpxHs4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import glob\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnYZK1gDyCto"
      },
      "outputs": [],
      "source": [
        "normal_data = os.listdir(data_n_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJVAEo-T0kcT"
      },
      "outputs": [],
      "source": [
        "abnormal_data = os.listdir(data_ab_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSwovHr2Fon1"
      },
      "outputs": [],
      "source": [
        "np.random.seed(2023)\n",
        "random.shuffle(normal_data)\n",
        "random.shuffle(abnormal_data )\n",
        "test_n = normal_data[:te_data_num[0]]\n",
        "test_ab = abnormal_data[:te_data_num[1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AImO1ujiI2IY",
        "outputId": "49874eba-e323-4940-8ecc-3b94357b8ddb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "60 61\n"
          ]
        }
      ],
      "source": [
        "# 추출 후 이미지 갯수 확인\n",
        "print(len(test_n), len(test_ab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtIiEr1IT1u9"
      },
      "outputs": [],
      "source": [
        "test_n_path = '/content/drive/MyDrive/datasets/Car_Images_test/normal'\n",
        "test_ab_path = '/content/drive/MyDrive/datasets/Car_Images_test/abnormal'\n",
        "val_n_path = '/content/drive/MyDrive/datasets/Car_Images_val/normal'\n",
        "val_ab_path = '/content/drive/MyDrive/datasets/Car_Images_val/abnormal'\n",
        "train_n_path = '/content/drive/MyDrive/datasets/Car_Images_train/normal'\n",
        "train_ab_path = '/content/drive/MyDrive/datasets/Car_Images_train/abnormal'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42YA2cP06aSq"
      },
      "outputs": [],
      "source": [
        "for i in test_n :\n",
        "    src_path = os.path.join('/content/drive/MyDrive/Car_Images.zip (Unzipped Files)/normal', i)\n",
        "    dst_path = os.path.join(test_n_path, i)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "\n",
        "for i in test_ab :\n",
        "    src_path = os.path.join('/content/drive/MyDrive/Car_Images.zip (Unzipped Files)/abnormal', i)\n",
        "    dst_path = os.path.join(test_ab_path, i)\n",
        "    shutil.copy(src_path, dst_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V4mh3hxRpR2"
      },
      "source": [
        "#### 3) validation 셋 추출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXYmEdCjAEDu",
        "outputId": "9cd5c4a1-35cf-47e3-87c5-f0e96d3f2ffa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "48 48\n"
          ]
        }
      ],
      "source": [
        "val_n = normal_data[te_data_num[0]:val_data_num[0]+te_data_num[0]]\n",
        "val_ab = abnormal_data[te_data_num[1]:val_data_num[1]+te_data_num[1]]\n",
        "\n",
        "print(len(val_n), len(val_ab))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gZ0Y_h1WWgy"
      },
      "outputs": [],
      "source": [
        "for i in val_n :\n",
        "    src_path = os.path.join('/content/drive/MyDrive/Car_Images.zip (Unzipped Files)/normal', i)\n",
        "    dst_path = os.path.join(val_n_path, i)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "\n",
        "for i in val_ab :\n",
        "    src_path = os.path.join('/content/drive/MyDrive/Car_Images.zip (Unzipped Files)/abnormal', i)\n",
        "    dst_path = os.path.join(val_ab_path, i)\n",
        "    shutil.copy(src_path, dst_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96uVIWxh4Dd6"
      },
      "source": [
        "- train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBSxuvvx4A9g"
      },
      "outputs": [],
      "source": [
        "train_n = normal_data[val_data_num[0]+te_data_num[0]:]\n",
        "train_ab = abnormal_data[val_data_num[1]+te_data_num[1]:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wdOVxLH5jPc",
        "outputId": "92c61ea5-602e-49c0-9fb3-bd8ffaab79ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "194 194\n"
          ]
        }
      ],
      "source": [
        "print(len(train_n), len(train_ab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swd1Xz39ZIi0"
      },
      "outputs": [],
      "source": [
        "for i in train_n :\n",
        "    src_path = os.path.join('/content/drive/MyDrive/Car_Images.zip (Unzipped Files)/normal', i)\n",
        "    dst_path = os.path.join(train_n_path, i)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "\n",
        "for i in train_ab :\n",
        "    src_path = os.path.join('/content/drive/MyDrive/Car_Images.zip (Unzipped Files)/abnormal', i)\n",
        "    dst_path = os.path.join(train_ab_path, i)\n",
        "    shutil.copy(src_path, dst_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haSO004sgyyu"
      },
      "source": [
        "### (2) 데이터 복사 및 이동\n",
        "- **세부요구사항**\n",
        "    - 분할된 데이터를 복사 이동합니다.\n",
        "        - 새로운 폴더에 저장하는 데이터로 \"3.모델링I\"에서 사용합니다.\n",
        "        - 기존 폴더는 \"4.모델링II > (1) Data Augmentation\"에서 사용합니다.\n",
        "    - Training set | Validation set | Test set의 데이터를 **새로운 폴더**에 복사하세요.\n",
        "        - 새로운 폴더 명\n",
        "            * copy_images/trainset\n",
        "            * copy_images/validset\n",
        "            * copy_images/testset\n",
        "        - 새로운 폴더에는 normal, abnormal 파일 모두를 복사합니다. \n",
        "            * 파일을 구분하기 위해 abnormal 파일들은 파일명 앞에 접두사 'ab_'를 붙입시다.\n",
        "        - os, shutil 모듈을 활용하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UbNfTY4kOSZ"
      },
      "source": [
        "#### 1) abnormal 파일 복사"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VypSMpiknk4"
      },
      "outputs": [],
      "source": [
        "from distutils.dir_util import copy_tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhkKqLfTkjGI"
      },
      "source": [
        "* 복사하기 : shutil.copytree()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cv6gafRyz6ul"
      },
      "outputs": [],
      "source": [
        "def rename1(data, paths):\n",
        "    for i in data :\n",
        "        old = os.path.join(paths, i)\n",
        "        new = os.path.join(paths, 'ab_'+i)\n",
        "        os.rename(old, new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xbd2MXK6rue_"
      },
      "outputs": [],
      "source": [
        "rename1(val_ab, val_ab_path)\n",
        "rename1(test_ab, test_ab_path)\n",
        "rename1(train_ab, train_ab_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-XpA6cX4UM1",
        "outputId": "b83b7094-e9df-426d-b370-0f40a2efdb25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/MyDrive/copy_images/’: File exists\n",
            "mkdir: cannot create directory ‘/content/drive/MyDrive/copy_images/’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir /content/drive/MyDrive/copy_images/; mkdir /content/drive/MyDrive/copy_images/testset/\n",
        "!mkdir /content/drive/MyDrive/copy_images/; mkdir /content/drive/MyDrive/copy_images/trainset/\n",
        "!mkdir /content/drive/MyDrive/copy_images/; mkdir /content/drive/MyDrive/copy_images/validset/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTMVxJJJya98",
        "outputId": "3980e50e-15a7-4b38-f1da-5c66bd4387ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 15.12.31 - dents of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 15.00.43 - dents of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 17.27.06 - slightly dented car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 17.25.14 - slightly dented car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 15.13.25 - dents of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 15.06.35 - dents of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 00.14.22 - a part of car without scratch.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 15.08.48 - dents of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-10 22.04.39 - scratched car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 01.31.38 - slightly damaged car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 15.08.50 - dents of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 01.23.56 - slightly damaged car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 01.21.48 - scratched car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 18.42.59 - slightly dented car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 17.22.16 - scratched car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 18.41.30 - slightly dented car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 14.48.33 - dents of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-10 23.57.31 - a part of car without blemish.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 01.29.06 - scratched car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 14.59.08 - dents of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 14.50.43 - dents of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 18.42.29 - slightly dented car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 17.17.35 - scratched car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 15.12.06 - dents of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 14.59.32 - dents of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 01.23.26 - slightly damaged car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 00.04.45 - a part of car without blemish.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 17.16.53 - damaged car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 15.06.13 - dents of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 17.27.58 - slightly dented car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 15.03.31 - dents of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 14.55.34 - dents of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 15.09.57 - dents of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 17.15.16 - scratched car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-10 18.54.19 - slightly damaged car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 18.43.31 - slightly dented car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 15.01.57 - dents of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 14.57.51 - dents of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 18.46.24 - scratched car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-10 22.37.56 - photo of a part of car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 00.03.13 - a part of car without blemish.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 18.45.52 - scratched car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 17.18.47 - scratched car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-10 23.59.49 - a part of car without blemish.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 17.18.02 - scratched car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-10 23.44.29 - photo of a part of car without blemish.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 15.11.09 - dents of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/ab_DALL¡¤E 2023-03-11 15.09.38 - dents of a car.png']"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "copy_tree(\"/content/drive/MyDrive/datasets/Car_Images_test/abnormal\", \"/content/drive/MyDrive/copy_images/testset\")\n",
        "copy_tree(\"/content/drive/MyDrive/datasets/Car_Images_train/abnormal\", \"/content/drive/MyDrive/copy_images/trainset\")\n",
        "copy_tree(\"/content/drive/MyDrive/datasets/Car_Images_val/abnormal\", \"/content/drive/MyDrive/copy_images/validset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU0T-ypHkV6D"
      },
      "source": [
        "* abnormal 이미지 이름의 접두어 \"ab_\" 붙이기 : os.rename"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBPQKtoXmnB0"
      },
      "source": [
        "    - li = [test_ab, train_ab, val_ab]\n",
        "    - paths = [test_ab_path, train_ab_path, val_ab_path]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nk6xITmTksyK"
      },
      "source": [
        "#### 2) normal 파일 복사"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vw3DmdTS17RM",
        "outputId": "e98c9336-9a05-45ff-d0fe-6e39c2f2fc50"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-11 01.36.44 - a part of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-11 14.26.19 - part of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-10 23.31.56 - photo of a part of car without blemish.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-10 23.31.20 - photo of a part of car without blemish.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-11 14.25.48 - part of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-10 23.35.37 - photo of a part of car without blemish.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-11 14.37.35 - photo of part of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-11 00.57.21 - photo of a part of car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-10 22.23.54 - photo of a part of car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-11 14.26.16 - part of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-10 18.52.44 - photo of a part of car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-10 23.39.17 - photo of a part of car without blemish.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-11 14.25.24 - part of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-11 17.09.46 - a part of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-10 23.41.16 - photo of a part of car without blemish.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-10 23.37.20 - photo of a part of car without blemish.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-11 01.28.20 - a part of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-11 14.35.46 - part of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-11 14.24.58 - part of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-10 23.32.42 - photo of a part of car without blemish.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-11 01.01.17 - photo of a part of car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-11 14.12.34 - part of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-11 00.51.44 - photo of a part of car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-10 23.32.16 - photo of a part of car without blemish.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-11 14.42.03 - photo of part of a car (1).png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-10 23.35.40 - photo of a part of car without blemish.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-11 00.04.11 - a part of car without blemish.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-10 23.41.20 - photo of a part of car without blemish.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-10 23.36.45 - photo of a part of car without blemish.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-10 18.52.40 - photo of a part of car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-10 22.22.18 - photo of a part of car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-10 23.32.22 - photo of a part of car without blemish.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-10 18.50.11 - photo of a part of car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-11 01.01.47 - photo of a part of car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-10 23.38.57 - photo of a part of car without blemish.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-11 01.04.23 - photo of a part of car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-11 01.36.08 - photo of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-10 23.38.51 - photo of a part of car without blemish.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-11 14.30.55 - part of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-11 01.16.35 - a part of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-11 01.16.03 - a part of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-11 00.38.05 - photo of a part of car without blemish.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-10 18.50.29 - photo of a part of car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-11 14.28.25 - part of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-11 14.44.02 - photo of part of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-11 14.43.57 - photo of part of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-11 01.35.01 - photo of a car.png',\n",
              " '/content/drive/MyDrive/copy_images/validset/DALL¡¤E 2023-03-11 01.12.33 - a part of a car.png']"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "copy_tree(\"/content/drive/MyDrive/datasets/Car_Images_test/normal\", \"/content/drive/MyDrive/copy_images/testset\")\n",
        "copy_tree(\"/content/drive/MyDrive/datasets/Car_Images_train/normal\", \"/content/drive/MyDrive/copy_images/trainset\")\n",
        "copy_tree(\"/content/drive/MyDrive/datasets/Car_Images_val/normal\", \"/content/drive/MyDrive/copy_images/validset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzEXHZrqkz88"
      },
      "source": [
        "* 데이터 갯수 조회"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugNprP9d-Gti",
        "outputId": "a3304bbe-c7b3-4d86-d964-d04679ee3486"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "121\n",
            "388\n",
            "96\n"
          ]
        }
      ],
      "source": [
        "print(len(os.listdir('/content/drive/MyDrive/copy_images/testset')))\n",
        "print(len(os.listdir('/content/drive/MyDrive/copy_images/trainset')))\n",
        "print(len(os.listdir('/content/drive/MyDrive/copy_images/validset')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfYDW1Pj7ZdU"
      },
      "source": [
        "## 3.모델링 I\n",
        "* **세부요구사항**\n",
        "    * 모델링을 위한 데이터 구조 만들기\n",
        "        * x : 이미지를 array로 변환합니다.\n",
        "        * y : 이미지 갯수만큼 normal - 0, abnormal - 1 로 array를 만듭니다.\n",
        "    * 모델을 최소 3개 이상 만들고 성능을 비교합니다.\n",
        "        * 모델 학습 과정에 알맞은 보조 지표를 사용하세요.\n",
        "        * 전처리 과정에서 생성한 Validation set을 적절하게 사용하세요.\n",
        "        * Early Stopping을 반드시 사용하세요.\n",
        "            * 최적의 가중치를 모델에 적용하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Rg553KIvxE6W"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIfqg6e0xE6A"
      },
      "source": [
        "### (1) X : image to array\n",
        "- **세부요구사항**\n",
        "    * 모델링을 위해서는 np.array 형태로 데이터셋을 만들어야 합니다.\n",
        "    * Training set / Validation set / Test set의 X는 이미지 형태로 되어있습니다. \n",
        "    * 이미지 파일을 불러와 train, valid, test 각각 array 형태로 변환해 봅시다.\n",
        "        * 각 폴더로 부터 이미지 목록을 만들고\n",
        "        * 이미지 한장씩 적절한 크기로 로딩하여 (keras.utils.load_img)\n",
        "            * 이미지가 너무 크면 학습시간이 많이 걸리고, 메모리 부족현상이 발생될 수 있습니다.\n",
        "            * 이미지 크기를 280 * 280 * 3 이내의 크기를 설정하여 로딩하시오.\n",
        "            * array로 변환 (keras.utils.img_to_array, np.expand_dims)\n",
        "        * 데이터셋에 추가합니다.(데이터셋도 array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FovkIeSDT367"
      },
      "source": [
        "#### 1) 이미지 목록 만들기\n",
        "* train, validation, test 폴더로 부터 이미지 목록을 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "X022f0QMxE6W"
      },
      "outputs": [],
      "source": [
        "# 이미지 목록 저장\n",
        "img_train_list = os.listdir('/content/drive/MyDrive/copy_images/trainset')\n",
        "img_valid_list = os.listdir('/content/drive/MyDrive/copy_images/validset')\n",
        "img_test_list = os.listdir('/content/drive/MyDrive/copy_images/testset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rgvW_LQfxE6X"
      },
      "outputs": [],
      "source": [
        "# 메모리, 처리시간을 위해서 이미지 크기 조정\n",
        "img_size = 280 ## 사이즈 조정 가능"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSt88mjPV33u"
      },
      "source": [
        "#### 2) 이미지들을 배열 데이터셋으로 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tTEJiPyxyaR-"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DEX8chzzx9PU"
      },
      "outputs": [],
      "source": [
        "files = glob.glob('/content/drive/MyDrive/copy_images/trainset/*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rhEdBiKfxE6Y"
      },
      "outputs": [],
      "source": [
        "images = []\n",
        "\n",
        "for path in files:\n",
        "    img = image.load_img(path, target_size=(img_size,img_size) )\n",
        "    img = image.img_to_array(img)\n",
        "    images.append(img)\n",
        "    \n",
        "    # plt.imshow(image.load_img(path))\n",
        "    # plt.show()\n",
        "    x_train = np.array(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WIo8U3AQzpam"
      },
      "outputs": [],
      "source": [
        "files = glob.glob('/content/drive/MyDrive/copy_images/testset/*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vfeiIjLPzrmk"
      },
      "outputs": [],
      "source": [
        "images = []\n",
        "\n",
        "for path in files:\n",
        "    img = image.load_img(path, target_size=(img_size,img_size) )\n",
        "    img = image.img_to_array(img)\n",
        "    images.append(img)\n",
        "    \n",
        "    # plt.imshow(image.load_img(path))\n",
        "    # plt.show()\n",
        "    x_test = np.array(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0vtR4OQfz1Ir"
      },
      "outputs": [],
      "source": [
        "files = glob.glob('/content/drive/MyDrive/copy_images/validset/*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ARSAcs9iz3Ej"
      },
      "outputs": [],
      "source": [
        "images = []\n",
        "\n",
        "for path in files:\n",
        "    img = image.load_img(path, target_size=(img_size,img_size) )\n",
        "    img = image.img_to_array(img)\n",
        "    images.append(img)\n",
        "    \n",
        "    # plt.imshow(image.load_img(path))\n",
        "    # plt.show()\n",
        "    x_val = np.array(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRTHe1lBz6V9",
        "outputId": "81024bd3-c0a7-4043-b634-f3c793d29a12"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((388, 280, 280, 3), (96, 280, 280, 3), (121, 280, 280, 3))"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape, x_val.shape, x_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doUM37LxxE6Z"
      },
      "source": [
        "### (2) y : 클래스 만들기\n",
        "- **세부요구사항**\n",
        "    - Training set / Validation set / Test set의 y를 생성합니다.\n",
        "        - 각각 normal, abnormal 데이터의 갯수를 다시 확인하고\n",
        "        - normal을 0, abnormal을 1로 지정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nl1Uv9UxE6b",
        "outputId": "d65555cf-baca-487b-a867-b825835cbfb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "388\n",
            "194\n",
            "---\n",
            "96\n",
            "48\n",
            "---\n",
            "121\n",
            "61\n"
          ]
        }
      ],
      "source": [
        "# 데이터 갯수 확인\n",
        "print( len(img_train_list) )\n",
        "print( len([val for val in img_train_list if val.startswith('ab_')]) )\n",
        "print('---')\n",
        "print( len(img_valid_list) )\n",
        "print( len([val for val in img_valid_list if val.startswith('ab_')]) )\n",
        "print('---')\n",
        "print( len(img_test_list) )\n",
        "print( len([val for val in img_test_list if val.startswith('ab_')]) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIfaCLlNn04C"
      },
      "source": [
        "* y_train, y_valid, y_test 만들기\n",
        "    * normal, abnormal 데이터의 갯수를 다시 확인하고 normal을 0, abnormal을 1로 지정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "YVrPQdhTxE6b"
      },
      "outputs": [],
      "source": [
        "y_train = []\n",
        "for name in img_train_list:\n",
        "    if 'ab_' in str(name) :\n",
        "        y_train.append(1)\n",
        "    else :\n",
        "        y_train.append(0)\n",
        "\n",
        "y_train = np.array(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mcTtb77z04Jg"
      },
      "outputs": [],
      "source": [
        "y_test= []\n",
        "for name in img_test_list:\n",
        "    if 'ab_' in str(name) :\n",
        "        y_test.append(1)\n",
        "    else :\n",
        "        y_test.append(0)\n",
        "\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "abtU115Q6ehk"
      },
      "outputs": [],
      "source": [
        "y_valid= []\n",
        "for name in img_valid_list:\n",
        "    if 'ab_' in str(name) :\n",
        "        y_valid.append(1)\n",
        "    else :\n",
        "        y_valid.append(0)\n",
        "\n",
        "y_val = np.array(y_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xm0m3U976pUE",
        "outputId": "0258f284-6571-4971-fb02-c7d72d312901"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(388,) (121,) (96,)\n"
          ]
        }
      ],
      "source": [
        "print(y_train.shape, y_test.shape, y_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z586wXFu7ZgT"
      },
      "source": [
        "### (3) 모델1\n",
        "- **세부요구사항**\n",
        "    - Conv2D, MaxPooling2D, Flatten, Dense 레이어들을 이용하여 모델을 설계\n",
        "    - 학습시 validation_data로 validation set을 사용하시오.\n",
        "    - 반드시 Early Stopping 적용\n",
        "    - 평가시, confusion matrix, accuracy, recall, precision, f1 score 등을 이용하시오."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHtrSqEX95Z-"
      },
      "source": [
        "min-max scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "DkwzkyrP98R2"
      },
      "outputs": [],
      "source": [
        "mean_n, std_n = x_train.mean(), x_train.std()\n",
        "x_train = (x_train - mean_n) / std_n\n",
        "x_test = (x_test - mean_n) / std_n\n",
        "x_val = (x_val - mean_n) / std_n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szODzVXa_VD1",
        "outputId": "51693d8b-f9db-4242-c779-e62dd1135207"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5.1392874e-07, 1.0)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.mean(), x_train.std()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "279_FA05Bt5F"
      },
      "source": [
        "categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "CkkCh2Y8B2dT"
      },
      "outputs": [],
      "source": [
        "class_n = len(np.unique(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "nlNEunDjBwqB"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train, class_n)\n",
        "y_test = to_categorical(y_test, class_n)\n",
        "y_val = to_categorical(y_val, class_n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIvIO6RKa0mp"
      },
      "source": [
        "#### 1) 구조 설계"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "7TtIIz6XJQ5E"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.keras.layers import Dense, Input, Flatten, BatchNormalization, Dropout, Conv2D, AvgPool2D, MaxPool2D\n",
        "from tensorflow.keras.models import Model, Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHM91_bha3Kc"
      },
      "source": [
        "#### 2) 학습\n",
        "* EarlyStopping 설정하고 학습시키기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHnFVZuKa42f",
        "outputId": "de506300-26b0-4397-84b6-53f670e284be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 280, 280, 3)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 280, 280, 6)       456       \n",
            "                                                                 \n",
            " average_pooling2d (AverageP  (None, 140, 140, 6)      0         \n",
            " ooling2D)                                                       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 140, 140, 6)      24        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 136, 136, 16)      2416      \n",
            "                                                                 \n",
            " average_pooling2d_1 (Averag  (None, 68, 68, 16)       0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 68, 68, 16)       64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 73984)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 120)               8878200   \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 120)              480       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 84)               336       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 84)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 170       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,892,310\n",
            "Trainable params: 8,891,858\n",
            "Non-trainable params: 452\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 세션클리어\n",
        "clear_session()\n",
        "\n",
        "# 모델 layer 엮기\n",
        "il = Input(shape=(280, 280, 3))\n",
        "\n",
        "cl = Conv2D(filters = 6,\n",
        "            kernel_size = (5,5),\n",
        "            strides = (1,1),\n",
        "            padding = 'same',\n",
        "            activation = 'relu')(il)\n",
        "pl = AvgPool2D(pool_size = (2,2),\n",
        "               strides = (2,2))(cl)\n",
        "bl = BatchNormalization()(pl)\n",
        "\n",
        "cl = Conv2D(filters = 16,\n",
        "            kernel_size = (5,5),\n",
        "            strides = (1,1),\n",
        "            padding =  'valid',\n",
        "            activation = 'relu')(bl)\n",
        "pl = AvgPool2D(pool_size = (2,2),\n",
        "               strides = (2,2))(cl)\n",
        "bl = BatchNormalization()(pl)\n",
        "\n",
        "fl = Flatten()(bl)\n",
        "hl = Dense(120, activation = 'relu')(fl)\n",
        "bl = BatchNormalization()(hl)\n",
        "\n",
        "hl = Dense(84, activation = 'relu')(bl)\n",
        "bl = BatchNormalization()(hl)\n",
        "dl = Dropout(0.2)(bl)\n",
        "\n",
        "ol = Dense(class_n, activation = 'sigmoid')(dl)\n",
        "\n",
        "# 모델 처음, 끝 지정\n",
        "model = Model(il, ol)\n",
        "\n",
        "# 모델 compile\n",
        "model.compile(loss = keras.losses.binary_crossentropy,\n",
        "              metrics = ['accuracy'],\n",
        "              optimizer = 'rmsprop')\n",
        "\n",
        "# 양념\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "BnrTSupKa42f"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "WtqWeQtzNyP2"
      },
      "outputs": [],
      "source": [
        "es = EarlyStopping(monitor = 'val_loss',\n",
        "                   patience = 10,\n",
        "                   min_delta = 0, \n",
        "                   verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "0mkV9iql_4gs"
      },
      "outputs": [],
      "source": [
        "mcp = ModelCheckpoint(filepath = '/content/drive/MyDrive/Lenet.h5', # 모델 저장 경로\n",
        "\t\t\t\t\t\tmonitor = 'val_loss' ,               # 모델 저장의 관심 대상\n",
        "\t\t\t\t\t\tverbose = 1,                         # 어느 시점에서 저장되는지 알려줌\n",
        "\t\t\t\t\t\tsave_best_only = True,               # 최고 성능 모델만 저장\n",
        "\t\t\t\t\t\tsave_weights_only = False)           # 가중치만 저장할 것인지, 모델 구조를 저장할 것인지"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gQMBZjr_5U9",
        "outputId": "c078d060-f0ec-4dba-8d95-04190dddd5e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10000\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.5387 - accuracy: 0.7474\n",
            "Epoch 1: val_loss improved from inf to 1.06939, saving model to /content/drive/MyDrive/Lenet.h5\n",
            "13/13 [==============================] - 5s 192ms/step - loss: 0.5382 - accuracy: 0.7474 - val_loss: 1.0694 - val_accuracy: 0.5521\n",
            "Epoch 2/10000\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.3304 - accuracy: 0.8724\n",
            "Epoch 2: val_loss improved from 1.06939 to 0.77307, saving model to /content/drive/MyDrive/Lenet.h5\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.3330 - accuracy: 0.8711 - val_loss: 0.7731 - val_accuracy: 0.5729\n",
            "Epoch 3/10000\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 0.2290 - accuracy: 0.9290\n",
            "Epoch 3: val_loss improved from 0.77307 to 0.57443, saving model to /content/drive/MyDrive/Lenet.h5\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.2432 - accuracy: 0.9201 - val_loss: 0.5744 - val_accuracy: 0.7396\n",
            "Epoch 4/10000\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.1639 - accuracy: 0.9588\n",
            "Epoch 4: val_loss improved from 0.57443 to 0.50326, saving model to /content/drive/MyDrive/Lenet.h5\n",
            "13/13 [==============================] - 1s 67ms/step - loss: 0.1639 - accuracy: 0.9588 - val_loss: 0.5033 - val_accuracy: 0.8021\n",
            "Epoch 5/10000\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0927 - accuracy: 0.9794\n",
            "Epoch 5: val_loss improved from 0.50326 to 0.48219, saving model to /content/drive/MyDrive/Lenet.h5\n",
            "13/13 [==============================] - 1s 67ms/step - loss: 0.0927 - accuracy: 0.9794 - val_loss: 0.4822 - val_accuracy: 0.8021\n",
            "Epoch 6/10000\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.0642 - accuracy: 0.9948\n",
            "Epoch 6: val_loss did not improve from 0.48219\n",
            "13/13 [==============================] - 1s 51ms/step - loss: 0.0720 - accuracy: 0.9923 - val_loss: 0.4861 - val_accuracy: 0.7812\n",
            "Epoch 7/10000\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0504 - accuracy: 0.9923\n",
            "Epoch 7: val_loss improved from 0.48219 to 0.45807, saving model to /content/drive/MyDrive/Lenet.h5\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.0504 - accuracy: 0.9923 - val_loss: 0.4581 - val_accuracy: 0.8229\n",
            "Epoch 8/10000\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 0.9897\n",
            "Epoch 8: val_loss did not improve from 0.45807\n",
            "13/13 [==============================] - 1s 55ms/step - loss: 0.0465 - accuracy: 0.9897 - val_loss: 0.5060 - val_accuracy: 0.7604\n",
            "Epoch 9/10000\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.0473 - accuracy: 0.9896\n",
            "Epoch 9: val_loss did not improve from 0.45807\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.0479 - accuracy: 0.9897 - val_loss: 0.5244 - val_accuracy: 0.8333\n",
            "Epoch 10/10000\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9974\n",
            "Epoch 10: val_loss did not improve from 0.45807\n",
            "13/13 [==============================] - 1s 44ms/step - loss: 0.0330 - accuracy: 0.9974 - val_loss: 0.5661 - val_accuracy: 0.7708\n",
            "Epoch 11/10000\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0309 - accuracy: 0.9923\n",
            "Epoch 11: val_loss improved from 0.45807 to 0.42944, saving model to /content/drive/MyDrive/Lenet.h5\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.0309 - accuracy: 0.9923 - val_loss: 0.4294 - val_accuracy: 0.8542\n",
            "Epoch 12/10000\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 1.0000\n",
            "Epoch 12: val_loss did not improve from 0.42944\n",
            "13/13 [==============================] - 1s 42ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.4869 - val_accuracy: 0.8229\n",
            "Epoch 13/10000\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 0.0369 - accuracy: 0.9886\n",
            "Epoch 13: val_loss did not improve from 0.42944\n",
            "13/13 [==============================] - 1s 43ms/step - loss: 0.0398 - accuracy: 0.9871 - val_loss: 0.6465 - val_accuracy: 0.7188\n",
            "Epoch 14/10000\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0410 - accuracy: 0.9871\n",
            "Epoch 14: val_loss did not improve from 0.42944\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.0410 - accuracy: 0.9871 - val_loss: 0.5693 - val_accuracy: 0.7917\n",
            "Epoch 15/10000\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0261 - accuracy: 0.9974\n",
            "Epoch 15: val_loss did not improve from 0.42944\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.0261 - accuracy: 0.9974 - val_loss: 0.5682 - val_accuracy: 0.8125\n",
            "Epoch 16/10000\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9974\n",
            "Epoch 16: val_loss did not improve from 0.42944\n",
            "13/13 [==============================] - 1s 43ms/step - loss: 0.0179 - accuracy: 0.9974 - val_loss: 0.5047 - val_accuracy: 0.8333\n",
            "Epoch 17/10000\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 1.0000\n",
            "Epoch 17: val_loss did not improve from 0.42944\n",
            "13/13 [==============================] - 1s 40ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.4913 - val_accuracy: 0.8542\n",
            "Epoch 18/10000\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 18: val_loss did not improve from 0.42944\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.5426 - val_accuracy: 0.8750\n",
            "Epoch 19/10000\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0323 - accuracy: 0.9897\n",
            "Epoch 19: val_loss did not improve from 0.42944\n",
            "13/13 [==============================] - 1s 42ms/step - loss: 0.0323 - accuracy: 0.9897 - val_loss: 0.6030 - val_accuracy: 0.7917\n",
            "Epoch 20/10000\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 1.0000\n",
            "Epoch 20: val_loss did not improve from 0.42944\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.6061 - val_accuracy: 0.8229\n",
            "Epoch 21/10000\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 1.0000\n",
            "Epoch 21: val_loss did not improve from 0.42944\n",
            "13/13 [==============================] - 1s 42ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.7563 - val_accuracy: 0.8229\n",
            "Epoch 21: early stopping\n"
          ]
        }
      ],
      "source": [
        "# 데이터를 넣어서 학습시키자!\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs = 10000, verbose = 1,\n",
        "                    callbacks = [es, mcp], validation_data = [x_val, y_val])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zage6-Z0a6DX"
      },
      "source": [
        "#### 3) test set으로 예측하고 평가하기\n",
        "* 평가는 confusion_matrix, classification_report 활용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xkFFlFdbBZb",
        "outputId": "6a20708a-8821-48a8-ff0f-c99d5c49f177"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 16ms/step\n",
            "(121, 2)\n",
            "(121,)\n",
            "[[50 10]\n",
            " [ 9 52]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.83      0.84        60\n",
            "           1       0.84      0.85      0.85        61\n",
            "\n",
            "    accuracy                           0.84       121\n",
            "   macro avg       0.84      0.84      0.84       121\n",
            "weighted avg       0.84      0.84      0.84       121\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred.shape\n",
        "single_y_pred = y_pred.argmax(axis=1)\n",
        "single_y_pred.shape\n",
        "print(y_test.shape)\n",
        "single_test_y = y_test.argmax(axis=1)\n",
        "print(single_test_y.shape)\n",
        "print(confusion_matrix(single_test_y, single_y_pred))\n",
        "print(classification_report(single_test_y, single_y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRoacK2mcLPb"
      },
      "source": [
        "### (4) 모델2\n",
        "- **세부요구사항**\n",
        "    - Conv2D, MaxPooling2D, Flatten, Dense 레이어들을 이용하여 모델을 설계\n",
        "    - 학습시 validation_data로 validation set을 사용하시오.\n",
        "    - 반드시 Early Stopping 적용\n",
        "    - 평가시, confusion matrix, accuracy, recall, precision, f1 score 등을 이용하시오."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WTwG8NFoLBQ"
      },
      "source": [
        "#### 1) 구조 설계"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHu5gey1oLBR",
        "outputId": "87ff554a-3c38-4082-f761-f9600ca98764"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 280, 280, 3)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 68, 68, 96)        28896     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 33, 33, 96)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 33, 33, 96)       384       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 33, 33, 256)       614656    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 32, 32, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 32, 32, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 32, 32, 384)       393600    \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 32, 32, 256)       393472    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 16, 16, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 16, 16, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 65536)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               8388736   \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                4128      \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 32)               128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,826,626\n",
            "Trainable params: 9,825,090\n",
            "Non-trainable params: 1,536\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 세션클리어\n",
        "clear_session()\n",
        "\n",
        "# 모델 layer 엮기\n",
        "il = Input(shape=(280, 280, 3))\n",
        "\n",
        "cl = Conv2D(filters = 96,\n",
        "            kernel_size = (10,10),\n",
        "            strides = (4,4),\n",
        "            padding = 'valid',\n",
        "            activation = 'relu')(il)\n",
        "pl = MaxPool2D(pool_size = (3,3),\n",
        "               strides = (2,2))(cl)\n",
        "bl = BatchNormalization()(pl)\n",
        "\n",
        "cl = Conv2D(filters = 256,\n",
        "            kernel_size = (5,5),\n",
        "            strides = (1,1),\n",
        "            padding =  'same',\n",
        "            activation = 'relu')(bl)\n",
        "pl = MaxPool2D(pool_size = (2,2),\n",
        "               strides = (1,1))(cl)\n",
        "bl = BatchNormalization()(pl)\n",
        "\n",
        "cl = Conv2D(filters = 384,\n",
        "            kernel_size = (2,2),\n",
        "            strides = (1,1),\n",
        "            padding =  'same',\n",
        "            activation = 'relu')(bl)\n",
        "\n",
        "cl = Conv2D(filters = 256,\n",
        "            kernel_size = (2,2),\n",
        "            strides = (1,1),\n",
        "            padding =  'same',\n",
        "            activation = 'relu')(cl)\n",
        "\n",
        "pl = MaxPool2D(pool_size = (2,2),\n",
        "               strides = (2,2))(cl)\n",
        "bl = BatchNormalization()(pl)\n",
        "\n",
        "fl = Flatten()(bl)\n",
        "hl = Dense(128, activation = 'relu')(fl)\n",
        "bl = BatchNormalization()(hl)\n",
        "\n",
        "hl = Dense(32, activation = 'relu')(bl)\n",
        "bl = BatchNormalization()(hl)\n",
        "dl = Dropout(0.3)(bl)\n",
        "\n",
        "ol = Dense(class_n, activation = 'sigmoid')(dl)\n",
        "\n",
        "# 모델 처음, 끝 지정\n",
        "model = Model(il, ol)\n",
        "\n",
        "# 모델 compile\n",
        "model.compile(loss = keras.losses.binary_crossentropy,\n",
        "              metrics = ['accuracy'],\n",
        "              optimizer = 'rmsprop')\n",
        "\n",
        "# 양념\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqTzgRTroLBR"
      },
      "source": [
        "#### 2) 학습\n",
        "* EarlyStopping 설정하고 학습시키기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "id": "lcVDXnpQoLBR"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "SwoBwtQmOOjL"
      },
      "outputs": [],
      "source": [
        "es = EarlyStopping(monitor = 'val_loss',\n",
        "                   patience = 10,\n",
        "                   min_delta = 0, \n",
        "                   verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "gH0xz08NKPa1"
      },
      "outputs": [],
      "source": [
        "# mcp = ModelCheckpoint(filepath = '/content/drive/MyDrive/Alexnet2.h5', # 모델 저장 경로\n",
        "# \t\t\t\t\t\tmonitor = 'val_loss' ,               # 모델 저장의 관심 대상\n",
        "# \t\t\t\t\t\tverbose = 1,                         # 어느 시점에서 저장되는지 알려줌\n",
        "# \t\t\t\t\t\tsave_best_only = True,               # 최고 성능 모델만 저장\n",
        "# \t\t\t\t\t\tsave_weights_only = True)           # 가중치만 저장할 것인지, 모델 구조를 저장할 것인지"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "id": "1rZBhK5jD3jd"
      },
      "outputs": [],
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.01, min_delta=0,\n",
        "                              patience=10, min_lr=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlcYwfInHlYm",
        "outputId": "6f1992c3-4d48-4682-a71d-118b1e4e29d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10000\n",
            "13/13 [==============================] - 4s 111ms/step - loss: 0.5432 - accuracy: 0.7784 - val_loss: 10.3608 - val_accuracy: 0.5312 - lr: 0.0010\n",
            "Epoch 2/10000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.4630 - accuracy: 0.8119 - val_loss: 3.5174 - val_accuracy: 0.6771 - lr: 0.0010\n",
            "Epoch 3/10000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.3500 - accuracy: 0.8789 - val_loss: 3.0588 - val_accuracy: 0.6771 - lr: 0.0010\n",
            "Epoch 4/10000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.3577 - accuracy: 0.8402 - val_loss: 6.9186 - val_accuracy: 0.5312 - lr: 0.0010\n",
            "Epoch 5/10000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.4170 - accuracy: 0.8299 - val_loss: 3.3018 - val_accuracy: 0.5625 - lr: 0.0010\n",
            "Epoch 6/10000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.3164 - accuracy: 0.8918 - val_loss: 3.2768 - val_accuracy: 0.5625 - lr: 0.0010\n",
            "Epoch 7/10000\n",
            "13/13 [==============================] - 1s 91ms/step - loss: 0.2723 - accuracy: 0.9021 - val_loss: 2.5730 - val_accuracy: 0.5208 - lr: 0.0010\n",
            "Epoch 8/10000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.2336 - accuracy: 0.9201 - val_loss: 4.2382 - val_accuracy: 0.6667 - lr: 0.0010\n",
            "Epoch 9/10000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.2125 - accuracy: 0.9407 - val_loss: 3.1172 - val_accuracy: 0.6354 - lr: 0.0010\n",
            "Epoch 10/10000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.1274 - accuracy: 0.9716 - val_loss: 2.3068 - val_accuracy: 0.7083 - lr: 0.0010\n",
            "Epoch 11/10000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.2087 - accuracy: 0.9330 - val_loss: 2.2076 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 12/10000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.1312 - accuracy: 0.9665 - val_loss: 2.4274 - val_accuracy: 0.6562 - lr: 0.0010\n",
            "Epoch 13/10000\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 0.0973 - accuracy: 0.9691 - val_loss: 1.3685 - val_accuracy: 0.7396 - lr: 0.0010\n",
            "Epoch 14/10000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.0447 - accuracy: 0.9974 - val_loss: 1.1494 - val_accuracy: 0.7917 - lr: 0.0010\n",
            "Epoch 15/10000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.0919 - accuracy: 0.9794 - val_loss: 3.1286 - val_accuracy: 0.5833 - lr: 0.0010\n",
            "Epoch 16/10000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.0734 - accuracy: 0.9923 - val_loss: 1.9761 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 17/10000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.0453 - accuracy: 0.9974 - val_loss: 0.8807 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 18/10000\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 0.0317 - accuracy: 0.9974 - val_loss: 1.2769 - val_accuracy: 0.7292 - lr: 0.0010\n",
            "Epoch 19/10000\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 0.0775 - accuracy: 0.9768 - val_loss: 0.7421 - val_accuracy: 0.7604 - lr: 0.0010\n",
            "Epoch 20/10000\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 0.0602 - accuracy: 0.9897 - val_loss: 1.5863 - val_accuracy: 0.6042 - lr: 0.0010\n",
            "Epoch 21/10000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.1583 - accuracy: 0.9588 - val_loss: 0.8525 - val_accuracy: 0.8125 - lr: 0.0010\n",
            "Epoch 22/10000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.0578 - accuracy: 0.9871 - val_loss: 0.8880 - val_accuracy: 0.8333 - lr: 0.0010\n",
            "Epoch 23/10000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.0252 - accuracy: 0.9974 - val_loss: 0.8212 - val_accuracy: 0.8229 - lr: 0.0010\n",
            "Epoch 24/10000\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 0.0251 - accuracy: 0.9948 - val_loss: 0.7449 - val_accuracy: 0.8021 - lr: 0.0010\n",
            "Epoch 25/10000\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 0.0282 - accuracy: 0.9974 - val_loss: 0.6668 - val_accuracy: 0.8333 - lr: 0.0010\n",
            "Epoch 26/10000\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 0.0170 - accuracy: 0.9974 - val_loss: 1.9903 - val_accuracy: 0.6771 - lr: 0.0010\n",
            "Epoch 27/10000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.0291 - accuracy: 0.9948 - val_loss: 1.0333 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 28/10000\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 0.0662 - accuracy: 0.9845 - val_loss: 0.9129 - val_accuracy: 0.7917 - lr: 0.0010\n",
            "Epoch 29/10000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.0885 - val_accuracy: 0.7812 - lr: 0.0010\n",
            "Epoch 30/10000\n",
            "13/13 [==============================] - 1s 91ms/step - loss: 0.0402 - accuracy: 0.9923 - val_loss: 1.3422 - val_accuracy: 0.7604 - lr: 0.0010\n",
            "Epoch 31/10000\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 0.0265 - accuracy: 0.9923 - val_loss: 1.7732 - val_accuracy: 0.6042 - lr: 0.0010\n",
            "Epoch 32/10000\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 0.0626 - accuracy: 0.9845 - val_loss: 1.1894 - val_accuracy: 0.7917 - lr: 0.0010\n",
            "Epoch 33/10000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.0320 - accuracy: 0.9923 - val_loss: 1.0335 - val_accuracy: 0.8021 - lr: 0.0010\n",
            "Epoch 34/10000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.0239 - accuracy: 0.9923 - val_loss: 0.9241 - val_accuracy: 0.7917 - lr: 0.0010\n",
            "Epoch 35/10000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.1475 - val_accuracy: 0.7604 - lr: 0.0010\n",
            "Epoch 35: early stopping\n"
          ]
        }
      ],
      "source": [
        "# 데이터를 넣어서 학습시키자!\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs = 10000, verbose = 1,\n",
        "                    callbacks = [es, reduce_lr], validation_data = [x_val, y_val])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxZ0U7K1oLBS"
      },
      "source": [
        "#### 3) test set으로 예측하고 평가하기\n",
        "* 평가는 confusion_matrix, classification_report 활용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShruikbsoLBS",
        "outputId": "51d72aec-bc74-4eeb-d02b-bbd26ed5294f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 25ms/step\n",
            "(121, 2)\n",
            "(121,)\n",
            "[[59  1]\n",
            " [21 40]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.98      0.84        60\n",
            "           1       0.98      0.66      0.78        61\n",
            "\n",
            "    accuracy                           0.82       121\n",
            "   macro avg       0.86      0.82      0.81       121\n",
            "weighted avg       0.86      0.82      0.81       121\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred.shape\n",
        "single_y_pred = y_pred.argmax(axis=1)\n",
        "single_y_pred.shape\n",
        "print(y_test.shape)\n",
        "single_test_y = y_test.argmax(axis=1)\n",
        "print(single_test_y.shape)\n",
        "print(confusion_matrix(single_test_y, single_y_pred))\n",
        "print(classification_report(single_test_y, single_y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRqzBw8eccwj"
      },
      "source": [
        "### (5) 모델3\n",
        "- **세부요구사항**\n",
        "    - Conv2D, MaxPooling2D, Flatten, Dense 레이어들을 이용하여 모델을 설계\n",
        "    - 학습시 validation_data로 validation set을 사용하시오.\n",
        "    - 반드시 Early Stopping 적용\n",
        "    - 평가시, confusion matrix, accuracy, recall, precision, f1 score 등을 이용하시오."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtNd8u5RoNJo"
      },
      "source": [
        "#### 1) 구조 설계"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KM-Npn6WoNJo",
        "outputId": "312d6f8c-475c-4a63-bf96-f6ccb63f24f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 280, 280, 3)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 280, 280, 64)      1792      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 280, 280, 64)      36928     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 140, 140, 64)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 140, 140, 64)     256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 140, 140, 128)     73856     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 140, 140, 128)     147584    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 70, 70, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 70, 70, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 627200)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                40140864  \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 64)               256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 40,402,178\n",
            "Trainable params: 40,401,666\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 세션 클리어\n",
        "clear_session()\n",
        "\n",
        "# 모델 레이어 엮기\n",
        "il = Input(shape=(280, 280, 3))\n",
        "\n",
        "cl = Conv2D(filters = 64,\n",
        "            kernel_size = (3,3),\n",
        "            padding = 'same',\n",
        "            activation = 'relu')(il)\n",
        "\n",
        "cl = Conv2D(filters = 64,\n",
        "            kernel_size = (3,3),\n",
        "            padding = 'same',\n",
        "            activation = 'relu')(cl)\n",
        "pl = MaxPool2D(pool_size=(2,2))(cl)\n",
        "bl = BatchNormalization()(pl)\n",
        "\n",
        "cl = Conv2D(filters = 128,\n",
        "            kernel_size = (3,3),\n",
        "            padding = 'same',\n",
        "            activation = 'relu')(bl)\n",
        "cl = Conv2D(filters = 128,\n",
        "            kernel_size = (3,3),\n",
        "            padding = 'same',\n",
        "            activation = 'relu')(cl)\n",
        "pl = MaxPool2D(pool_size=(2,2))(cl)\n",
        "bl = BatchNormalization()(pl)\n",
        "\n",
        "fl = Flatten()(bl)\n",
        "hl = Dense(64)(fl)\n",
        "bl = BatchNormalization()(hl)\n",
        "dl = Dropout(0.3)(bl)\n",
        "\n",
        "ol = Dense(2, activation = 'sigmoid')(dl)\n",
        "\n",
        "# 모델 처음, 끝 지정\n",
        "model = Model(il, ol )\n",
        "\n",
        "# 모델 compile\n",
        "model.compile(loss = keras.losses.binary_crossentropy,\n",
        "              metrics = ['accuracy'],\n",
        "              optimizer = 'rmsprop')\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zgVkXLHoNJo"
      },
      "source": [
        "#### 2) 학습\n",
        "* EarlyStopping 설정하고 학습시키기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "dUsrHwZQOS9Y"
      },
      "outputs": [],
      "source": [
        "es = EarlyStopping(monitor = 'val_loss',\n",
        "                   patience = 10,\n",
        "                   min_delta = 0, \n",
        "                   verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "gTlUNbkhoNJo"
      },
      "outputs": [],
      "source": [
        "# mcp = ModelCheckpoint(filepath = '/content/drive/MyDrive/Vgget.h5', # 모델 저장 경로\n",
        "# \t\t\t\t\t\tmonitor = 'val_loss' ,               # 모델 저장의 관심 대상\n",
        "# \t\t\t\t\t\tverbose = 1,                         # 어느 시점에서 저장되는지 알려줌\n",
        "# \t\t\t\t\t\tsave_best_only = True,               # 최고 성능 모델만 저장\n",
        "# \t\t\t\t\t\tsave_weights_only = False)           # 가중치만 저장할 것인지, 모델 구조를 저장할 것인지"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLoVxXkJXetI"
      },
      "outputs": [],
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.01, min_delta=0,\n",
        "                              patience=10, min_lr=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4GYo0dboNJo",
        "outputId": "a1839d81-4952-40af-89ad-e79cf391e383"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10000\n",
            "13/13 [==============================] - 7s 367ms/step - loss: 0.8566 - accuracy: 0.7062 - val_loss: 3.8625 - val_accuracy: 0.5000\n",
            "Epoch 2/10000\n",
            "13/13 [==============================] - 4s 332ms/step - loss: 0.4896 - accuracy: 0.8144 - val_loss: 1.6128 - val_accuracy: 0.6042\n",
            "Epoch 3/10000\n",
            "13/13 [==============================] - 4s 330ms/step - loss: 0.4682 - accuracy: 0.8402 - val_loss: 0.7153 - val_accuracy: 0.8438\n",
            "Epoch 4/10000\n",
            "13/13 [==============================] - 4s 333ms/step - loss: 0.3556 - accuracy: 0.8711 - val_loss: 1.1261 - val_accuracy: 0.7917\n",
            "Epoch 5/10000\n",
            "13/13 [==============================] - 4s 332ms/step - loss: 0.2804 - accuracy: 0.9046 - val_loss: 0.7210 - val_accuracy: 0.8333\n",
            "Epoch 6/10000\n",
            "13/13 [==============================] - 4s 334ms/step - loss: 0.2720 - accuracy: 0.8892 - val_loss: 1.0658 - val_accuracy: 0.7292\n",
            "Epoch 7/10000\n",
            "13/13 [==============================] - 4s 338ms/step - loss: 0.2244 - accuracy: 0.9330 - val_loss: 0.5266 - val_accuracy: 0.8229\n",
            "Epoch 8/10000\n",
            "13/13 [==============================] - 4s 336ms/step - loss: 0.1286 - accuracy: 0.9639 - val_loss: 0.8483 - val_accuracy: 0.7188\n",
            "Epoch 9/10000\n",
            "13/13 [==============================] - 4s 335ms/step - loss: 0.2189 - accuracy: 0.9046 - val_loss: 0.6234 - val_accuracy: 0.8021\n",
            "Epoch 10/10000\n",
            "13/13 [==============================] - 4s 340ms/step - loss: 0.1086 - accuracy: 0.9742 - val_loss: 0.6123 - val_accuracy: 0.8125\n",
            "Epoch 11/10000\n",
            "13/13 [==============================] - 4s 337ms/step - loss: 0.0759 - accuracy: 0.9871 - val_loss: 0.5495 - val_accuracy: 0.8333\n",
            "Epoch 12/10000\n",
            "13/13 [==============================] - 4s 337ms/step - loss: 0.0453 - accuracy: 0.9948 - val_loss: 0.7148 - val_accuracy: 0.7292\n",
            "Epoch 13/10000\n",
            "13/13 [==============================] - 4s 342ms/step - loss: 0.0348 - accuracy: 0.9974 - val_loss: 0.6784 - val_accuracy: 0.8125\n",
            "Epoch 14/10000\n",
            "13/13 [==============================] - 4s 337ms/step - loss: 0.0314 - accuracy: 0.9948 - val_loss: 0.6649 - val_accuracy: 0.8542\n",
            "Epoch 15/10000\n",
            "13/13 [==============================] - 4s 340ms/step - loss: 0.0221 - accuracy: 0.9974 - val_loss: 1.0534 - val_accuracy: 0.8125\n",
            "Epoch 16/10000\n",
            "13/13 [==============================] - 4s 342ms/step - loss: 0.0447 - accuracy: 0.9923 - val_loss: 2.8145 - val_accuracy: 0.4896\n",
            "Epoch 17/10000\n",
            "13/13 [==============================] - 4s 340ms/step - loss: 0.2052 - accuracy: 0.9356 - val_loss: 0.8545 - val_accuracy: 0.7812\n",
            "Epoch 17: early stopping\n"
          ]
        }
      ],
      "source": [
        "# 데이터를 넣어서 학습시키자!\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs = 10000, verbose = 1,\n",
        "                    callbacks = [es, reduce_lr], validation_data = [x_val, y_val])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZV9zbsroNJo"
      },
      "source": [
        "#### 3) test set으로 예측하고 평가하기\n",
        "* 평가는 confusion_matrix, classification_report 활용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sc9UmjZ0oNJo",
        "outputId": "ca499405-a31a-4fad-caac-237da02502c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 1s 112ms/step\n",
            "(121, 2)\n",
            "(121,)\n",
            "[[50 10]\n",
            " [10 51]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.83      0.83        60\n",
            "           1       0.84      0.84      0.84        61\n",
            "\n",
            "    accuracy                           0.83       121\n",
            "   macro avg       0.83      0.83      0.83       121\n",
            "weighted avg       0.83      0.83      0.83       121\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred.shape\n",
        "single_y_pred = y_pred.argmax(axis=1)\n",
        "single_y_pred.shape\n",
        "print(y_test.shape)\n",
        "single_test_y = y_test.argmax(axis=1)\n",
        "print(single_test_y.shape)\n",
        "print(confusion_matrix(single_test_y, single_y_pred))\n",
        "print(classification_report(single_test_y, single_y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1poqRJcuq90F",
        "outputId": "656f23f8-0514-43e3-b915-7c7518d941ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 280, 280, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 140, 140, 32)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 140, 140, 64)      18496     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 140, 140, 64)     256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 70, 70, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 70, 70, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 70, 70, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 35, 35, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 35, 35, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 35, 35, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 18, 18, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 18, 18, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 18, 18, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 9, 9, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 20736)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               2654336   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,081,986\n",
            "Trainable params: 3,080,962\n",
            "Non-trainable params: 1,024\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (280,280,3)))\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
        "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
        "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
        "model.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
        "model.add(Conv2D(256 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units = 128 , activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units = 2 , activation = 'sigmoid'))\n",
        "model.compile(optimizer = \"rmsprop\" , loss = 'binary_crossentropy' , metrics = ['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "wtDK6-HhreTk"
      },
      "outputs": [],
      "source": [
        "es = EarlyStopping(monitor = 'val_loss',\n",
        "                   patience = 10,\n",
        "                   min_delta = 0, \n",
        "                   verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "ULqk7i0lrfkU"
      },
      "outputs": [],
      "source": [
        "# mcp = ModelCheckpoint(filepath = '/content/drive/MyDrive/kaggle.h5', # 모델 저장 경로\n",
        "# \t\t\t\t\t\tmonitor = 'val_loss' ,               # 모델 저장의 관심 대상\n",
        "# \t\t\t\t\t\tverbose = 1,                         # 어느 시점에서 저장되는지 알려줌\n",
        "# \t\t\t\t\t\tsave_best_only = True,               # 최고 성능 모델만 저장\n",
        "# \t\t\t\t\t\tsave_weights_only = False)           # 가중치만 저장할 것인지, 모델 구조를 저장할 것인지"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2C3jBcrrkTD",
        "outputId": "4eb310eb-d25b-45d5-b2f9-bbe5eef504fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10000\n",
            "13/13 [==============================] - 5s 122ms/step - loss: 4.0961 - accuracy: 0.6933 - val_loss: 0.5903 - val_accuracy: 0.7812\n",
            "Epoch 2/10000\n",
            "13/13 [==============================] - 1s 93ms/step - loss: 0.5008 - accuracy: 0.8376 - val_loss: 0.5443 - val_accuracy: 0.8125\n",
            "Epoch 3/10000\n",
            "13/13 [==============================] - 1s 93ms/step - loss: 0.4950 - accuracy: 0.8351 - val_loss: 0.6535 - val_accuracy: 0.8021\n",
            "Epoch 4/10000\n",
            "13/13 [==============================] - 1s 93ms/step - loss: 0.3823 - accuracy: 0.8814 - val_loss: 0.9523 - val_accuracy: 0.7292\n",
            "Epoch 5/10000\n",
            "13/13 [==============================] - 1s 94ms/step - loss: 0.4369 - accuracy: 0.8479 - val_loss: 0.8363 - val_accuracy: 0.8229\n",
            "Epoch 6/10000\n",
            "13/13 [==============================] - 1s 93ms/step - loss: 0.2480 - accuracy: 0.9046 - val_loss: 1.4302 - val_accuracy: 0.7708\n",
            "Epoch 7/10000\n",
            "13/13 [==============================] - 1s 91ms/step - loss: 0.2234 - accuracy: 0.9227 - val_loss: 1.2737 - val_accuracy: 0.7708\n",
            "Epoch 8/10000\n",
            "13/13 [==============================] - 1s 95ms/step - loss: 0.3865 - accuracy: 0.8814 - val_loss: 1.9013 - val_accuracy: 0.7396\n",
            "Epoch 9/10000\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 0.1871 - accuracy: 0.9407 - val_loss: 2.0424 - val_accuracy: 0.7500\n",
            "Epoch 10/10000\n",
            "13/13 [==============================] - 1s 94ms/step - loss: 0.0902 - accuracy: 0.9691 - val_loss: 3.0934 - val_accuracy: 0.6979\n",
            "Epoch 11/10000\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 0.2857 - accuracy: 0.9253 - val_loss: 4.3179 - val_accuracy: 0.7188\n",
            "Epoch 12/10000\n",
            "13/13 [==============================] - 1s 91ms/step - loss: 0.1458 - accuracy: 0.9485 - val_loss: 3.7513 - val_accuracy: 0.7604\n",
            "Epoch 12: early stopping\n"
          ]
        }
      ],
      "source": [
        "# 데이터를 넣어서 학습시키자!\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs = 10000, verbose = 1,\n",
        "                    callbacks = [es, reduce_lr], validation_data = [x_val, y_val])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7YFqcJvvJZp",
        "outputId": "df13138d-479d-4328-bdca-89146cb9964e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 26ms/step\n",
            "(121, 2)\n",
            "(121,)\n",
            "[[35 25]\n",
            " [ 7 54]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.58      0.69        60\n",
            "           1       0.68      0.89      0.77        61\n",
            "\n",
            "    accuracy                           0.74       121\n",
            "   macro avg       0.76      0.73      0.73       121\n",
            "weighted avg       0.76      0.74      0.73       121\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred.shape\n",
        "single_y_pred = y_pred.argmax(axis=1)\n",
        "single_y_pred.shape\n",
        "print(y_test.shape)\n",
        "single_test_y = y_test.argmax(axis=1)\n",
        "print(single_test_y.shape)\n",
        "print(confusion_matrix(single_test_y, single_y_pred))\n",
        "print(classification_report(single_test_y, single_y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDGri_03tsR-",
        "outputId": "49399e5a-948a-40b5-e2bf-ded2da796cd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 3s 207ms/step\n",
            "(121, 2)\n",
            "(121,)\n",
            "[[60  0]\n",
            " [61  0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.66        60\n",
            "           1       0.00      0.00      0.00        61\n",
            "\n",
            "    accuracy                           0.50       121\n",
            "   macro avg       0.25      0.50      0.33       121\n",
            "weighted avg       0.25      0.50      0.33       121\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "model_path='/content/drive/MyDrive/first_model.h5'\n",
        "# 모델 파일 불러오기\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred.shape\n",
        "single_y_pred = y_pred.argmax(axis=1)\n",
        "single_y_pred.shape\n",
        "print(y_test.shape)\n",
        "single_test_y = y_test.argmax(axis=1)\n",
        "print(single_test_y.shape)\n",
        "print(confusion_matrix(single_test_y, single_y_pred))\n",
        "print(classification_report(single_test_y, single_y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouCRBdKPxCut"
      },
      "source": [
        "### (1) Data Augmentation\n",
        "- **세부요구사항**\n",
        "    * 모델 학습에 이용할 이미지 데이터를 증강시키세요.\n",
        "    * Keras의 ImageDataGenerator를 이용\n",
        "        - [ImageDataGenerator document](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator)\n",
        "\n",
        "    * image generator를 이용하여 학습\n",
        "        * 모델 구조는 이미 생성한 1,2,3 중 하나를 선택하여 학습\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "qe6yjs8F7Zox"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "wYae9YFt8Q03"
      },
      "outputs": [],
      "source": [
        "img_size = 280 ## 사이즈 조정 가능\n",
        "\n",
        "train_path = '/content/drive/MyDrive/datasets/Car_Images_train/'\n",
        "valid_path = '/content/drive/MyDrive/datasets/Car_Images_val/'\n",
        "test_path = '/content/drive/MyDrive/datasets/Car_Images_test/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IP4jIyTGfXD_"
      },
      "source": [
        "#### 1) ImageGenerator 생성\n",
        "* ImageDataGenerator 함수 사용\n",
        "    * 주요 옵션\n",
        "        * rotation_range: 무작위 회전을 적용할 각도 범위\n",
        "        * zoom_range: 무작위 줌을 적용할 범위 [1-zoom_range, 1+zoom_range]\n",
        "        * horizontal_flip: 무작위 좌우반전을 적용할지 여부\n",
        "        * vertical_flip: 무작위 상하반전을 적용할지 여부\n",
        "        * rescale: 텐서의 모든 값을 rescale 값으로 나누어줌 (이 경우에는 255로 나누어서 0~1사이의 값으로 변경)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "LKPPSwYn7Zrj"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
        "                                   rotation_range = 10,\n",
        "                                   zoom_range = [0, 0.5],\n",
        "                                   horizontal_flip=False,\n",
        "                                   vertical_flip = False,\n",
        "                                   width_shift_range = 0.1,\n",
        "                                   height_shift_range = 0.1,\n",
        "                                   fill_mode ='wrap', \n",
        "                                   rescale=1./255,)\n",
        "valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
        "                                   rotation_range = 10,\n",
        "                                   zoom_range = [0, 0.5],\n",
        "                                   horizontal_flip=False,\n",
        "                                   vertical_flip = False,\n",
        "                                   width_shift_range = 0.1,\n",
        "                                   height_shift_range = 0.1,\n",
        "                                   fill_mode ='wrap', \n",
        "                                   rescale=1./255,)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKwSYYkufanb"
      },
      "source": [
        "#### 2) 경로로 부터 이미지 불러 올 준비\n",
        "* .flow_from_directory 이용\n",
        "    * 디렉토리에서 이미지를 가져와서 데이터 증강을 적용하고 batch 단위로 제공하는 generator를 생성합니다.\n",
        "    * 이미지를 불러올 때 target_size로 크기를 맞추고, \n",
        "    * class_mode로 이진 분류(binary)를 수행하도록 지정합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDswLUlEKq4z",
        "outputId": "7c091c7b-75bb-4115-b654-db5307939de8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 388 images belonging to 2 classes.\n",
            "Found 96 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_flow_gen = train_datagen.flow_from_directory(directory = train_path,\n",
        "                                                   target_size = (280,280),\n",
        "                                                   classes = ['normal', 'abnormal'],\n",
        "                                                   class_mode = 'binary',\n",
        "                                                   shuffle = True)\n",
        "val_flow_gen = valid_datagen.flow_from_directory(directory= valid_path,\n",
        "                                                 target_size = (280, 280),\n",
        "                                                 classes = ['normal', 'abnormal'],\n",
        "                                                 class_mode = 'binary',\n",
        "                                                 shuffle = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4RPCjU5f662"
      },
      "source": [
        "#### 3) 학습\n",
        "- **세부요구사항**\n",
        "    - Conv2D, MaxPooling2D, Flatten, Dense 레이어들을 이용하여 모델을 설계\n",
        "    - 학습시 train_generator 이용. \n",
        "    - validation_data = valid_generator 지정\n",
        "    - Early Stopping 적용\n",
        "    - 평가시, confusion matrix, accuracy, recall, precision, f1 score 등을 이용하시오."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVMLsXw6f663"
      },
      "source": [
        "* 구조 설계"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw2_G7zdf663"
      },
      "source": [
        "* 학습\n",
        "    * EarlyStopping 설정하기\n",
        "    * 학습 데이터에 train_generator, validation_data=valid_generator 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6m5mRE9Nf663",
        "outputId": "5f457cc3-bed6-4ade-cd8d-2282501fc795"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 280, 280, 3)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 280, 280, 6)       456       \n",
            "                                                                 \n",
            " average_pooling2d (AverageP  (None, 140, 140, 6)      0         \n",
            " ooling2D)                                                       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 140, 140, 6)      24        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 136, 136, 16)      2416      \n",
            "                                                                 \n",
            " average_pooling2d_1 (Averag  (None, 68, 68, 16)       0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 68, 68, 16)       64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 73984)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 120)               8878200   \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 120)              480       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 84)               336       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 84)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 85        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,892,225\n",
            "Trainable params: 8,891,773\n",
            "Non-trainable params: 452\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 세션클리어\n",
        "clear_session()\n",
        "\n",
        "# 모델 layer 엮기\n",
        "il = Input(shape=(280, 280, 3))\n",
        "\n",
        "cl = Conv2D(filters = 6,\n",
        "            kernel_size = (5,5),\n",
        "            strides = (1,1),\n",
        "            padding = 'same',\n",
        "            activation = 'relu')(il)\n",
        "pl = AvgPool2D(pool_size = (2,2),\n",
        "               strides = (2,2))(cl)\n",
        "bl = BatchNormalization()(pl)\n",
        "\n",
        "cl = Conv2D(filters = 16,\n",
        "            kernel_size = (5,5),\n",
        "            strides = (1,1),\n",
        "            padding =  'valid',\n",
        "            activation = 'relu')(bl)\n",
        "pl = AvgPool2D(pool_size = (2,2),\n",
        "               strides = (2,2))(cl)\n",
        "bl = BatchNormalization()(pl)\n",
        "\n",
        "fl = Flatten()(bl)\n",
        "hl = Dense(120, activation = 'relu')(fl)\n",
        "bl = BatchNormalization()(hl)\n",
        "\n",
        "hl = Dense(84, activation = 'relu')(bl)\n",
        "bl = BatchNormalization()(hl)\n",
        "dl = Dropout(0.2)(bl)\n",
        "\n",
        "ol = Dense(1, activation = 'sigmoid')(dl)\n",
        "\n",
        "# 모델 처음, 끝 지정\n",
        "model = Model(il, ol)\n",
        "\n",
        "# 모델 compile\n",
        "# optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
        "model.compile(loss = keras.losses.binary_crossentropy,\n",
        "              metrics = ['accuracy'],\n",
        "              optimizer = 'rmsprop')\n",
        "\n",
        "# 양념\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "yCWzBSYqf663"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "0rTgGFTpNgca"
      },
      "outputs": [],
      "source": [
        "es = EarlyStopping(monitor = 'val_loss',\n",
        "                   patience = 10,\n",
        "                   min_delta = 0, \n",
        "                   verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "J_SvjQmrXl2b"
      },
      "outputs": [],
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
        "                              patience=10, min_lr=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhVYmndDNbDX",
        "outputId": "71c69e66-7a3e-4c5b-a7c6-5827fb2c2455"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10000\n",
            "13/13 [==============================] - 33s 2s/step - loss: 0.6519 - accuracy: 0.6856 - val_loss: 0.6776 - val_accuracy: 0.5729 - lr: 0.0010\n",
            "Epoch 2/10000\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.6236 - accuracy: 0.6933 - val_loss: 0.6731 - val_accuracy: 0.6146 - lr: 0.0010\n",
            "Epoch 3/10000\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.6124 - accuracy: 0.6624 - val_loss: 0.6371 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 4/10000\n",
            "13/13 [==============================] - 25s 2s/step - loss: 0.6196 - accuracy: 0.7165 - val_loss: 0.6407 - val_accuracy: 0.6667 - lr: 0.0010\n",
            "Epoch 5/10000\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.5298 - accuracy: 0.7474 - val_loss: 0.6365 - val_accuracy: 0.6979 - lr: 0.0010\n",
            "Epoch 6/10000\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.5260 - accuracy: 0.7423 - val_loss: 0.6743 - val_accuracy: 0.5729 - lr: 0.0010\n",
            "Epoch 7/10000\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.5692 - accuracy: 0.7294 - val_loss: 0.6438 - val_accuracy: 0.6042 - lr: 0.0010\n",
            "Epoch 8/10000\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.5808 - accuracy: 0.7088 - val_loss: 0.6055 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 9/10000\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.5559 - accuracy: 0.7552 - val_loss: 0.6009 - val_accuracy: 0.6667 - lr: 0.0010\n",
            "Epoch 10/10000\n",
            "13/13 [==============================] - 25s 2s/step - loss: 0.4537 - accuracy: 0.8093 - val_loss: 0.6602 - val_accuracy: 0.5625 - lr: 0.0010\n",
            "Epoch 11/10000\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.5105 - accuracy: 0.7474 - val_loss: 0.6364 - val_accuracy: 0.5729 - lr: 0.0010\n",
            "Epoch 12/10000\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.5328 - accuracy: 0.7577 - val_loss: 0.5731 - val_accuracy: 0.7604 - lr: 0.0010\n",
            "Epoch 13/10000\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.5245 - accuracy: 0.7758 - val_loss: 0.5679 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 14/10000\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.5707 - accuracy: 0.7500 - val_loss: 0.5410 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 15/10000\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.5250 - accuracy: 0.7552 - val_loss: 0.5709 - val_accuracy: 0.7292 - lr: 0.0010\n",
            "Epoch 16/10000\n",
            "13/13 [==============================] - 25s 2s/step - loss: 0.4756 - accuracy: 0.7758 - val_loss: 0.5265 - val_accuracy: 0.7812 - lr: 0.0010\n",
            "Epoch 17/10000\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.5143 - accuracy: 0.7526 - val_loss: 0.5335 - val_accuracy: 0.7708 - lr: 0.0010\n",
            "Epoch 18/10000\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.5676 - accuracy: 0.7294 - val_loss: 0.5776 - val_accuracy: 0.7188 - lr: 0.0010\n",
            "Epoch 19/10000\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.4925 - accuracy: 0.7784 - val_loss: 0.5403 - val_accuracy: 0.8021 - lr: 0.0010\n",
            "Epoch 20/10000\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.5311 - accuracy: 0.7655 - val_loss: 0.5407 - val_accuracy: 0.7812 - lr: 0.0010\n",
            "Epoch 21/10000\n",
            "13/13 [==============================] - 24s 2s/step - loss: 0.5081 - accuracy: 0.7603 - val_loss: 0.5943 - val_accuracy: 0.7188 - lr: 0.0010\n",
            "Epoch 22/10000\n",
            "13/13 [==============================] - 25s 2s/step - loss: 0.4785 - accuracy: 0.7680 - val_loss: 0.5288 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 23/10000\n",
            "13/13 [==============================] - 25s 2s/step - loss: 0.5231 - accuracy: 0.7912 - val_loss: 0.4977 - val_accuracy: 0.7604 - lr: 0.0010\n",
            "Epoch 24/10000\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.5185 - accuracy: 0.7680"
          ]
        }
      ],
      "source": [
        "# 데이터를 넣어서 학습시키자!\n",
        "history = model.fit(train_flow_gen,\n",
        "                    epochs = 10000, verbose = 1,batch_size = 100,\n",
        "                    callbacks = [es, reduce_lr], validation_data = [val_flow_gen])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdKiY1uIf663"
      },
      "source": [
        "#### 4) 성능 평가\n",
        "* 평가는 confusion_matrix, classification_report 활용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMQxGhIH7BS8",
        "outputId": "3be27198-b483-4028-c4c5-7f429d07d33e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 22ms/step\n",
            "(121, 2)\n",
            "(121,)\n",
            "[[60  0]\n",
            " [61  0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.66        60\n",
            "           1       0.00      0.00      0.00        61\n",
            "\n",
            "    accuracy                           0.50       121\n",
            "   macro avg       0.25      0.50      0.33       121\n",
            "weighted avg       0.25      0.50      0.33       121\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred.shape\n",
        "single_y_pred = y_pred.argmax(axis=1)\n",
        "single_y_pred.shape\n",
        "print(y_test.shape)\n",
        "single_test_y = y_test.argmax(axis=1)\n",
        "print(single_test_y.shape)\n",
        "print(confusion_matrix(single_test_y, single_y_pred))\n",
        "print(classification_report(single_test_y, single_y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1iv22vSxXle"
      },
      "source": [
        "### (2) Transfer Learning\n",
        "- **세부요구사항**\n",
        "    * VGG16 모델은 1000개의 클래스를 분류하는 데 사용된 ImageNet 데이터셋을 기반으로 사전 학습된 가중치를 가지고 있습니다. \n",
        "        * 따라서 이 모델은 이미지 분류 문제에 대한 높은 성능을 보입니다.\n",
        "        * 이 모델은 보통 전이학습(transfer learning)에서 기본적으로 사용되며, 특히 대규모 데이터셋이 없을 때는 기본 모델로 사용되어 fine-tuning을 수행합니다.\n",
        "    * VGG16 함수로 부터 base_model 저장\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnS12YhDxXle"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3kyvCwIiAfi"
      },
      "source": [
        "#### 1) VGG16 불러와서 저장하기\n",
        "* include_top=False로 설정하여 분류기를 제외하고 미리 학습된 가중치 imagenet을 로드합니다.\n",
        "* .trainable을 True로 설정하여 모델의 모든 레이어들이 fine-tuning에 대해 업데이트되도록 합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFf3IxbBGe9B"
      },
      "outputs": [],
      "source": [
        "base_model = VGG16(                 )\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-JjBLZZiIxA"
      },
      "source": [
        "#### 2) VGG16과 연결한 구조 설계\n",
        "* VGG16을 불러와서 Flatten, Dense 등으로 레이어 연결하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yg4KhHQ8xXlf"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# VGG16 모델 불러오기\n",
        "vgg_model = VGG16(weights='imagenet',\n",
        "                  include_top=False, \n",
        "                  input_shape=(280, 280, 3))\n",
        "\n",
        "# 기존 모델과 VGG16 연결하기\n",
        "last_layer = model.get_layer('dense_2').output\n",
        "x = Flatten()(vgg_model.output)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dense(2, activation='sigmoid')(x)\n",
        "new_model = Model(inputs=vgg_model.input, outputs=x)\n",
        "\n",
        "new_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# VGG16 모델의 가중치 동결하기\n",
        "for layer in vgg_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "history = new_model.fit(x_train, y_train, epochs = 10000, verbose = 1, callbacks = [es], validation_data =(x_val,y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5V5heiDxxXlf"
      },
      "source": [
        "#### 3) 학습\n",
        "- **세부요구사항**\n",
        "    - 모델 학습 과정에 알맞은 보조 지표를 사용하세요.\n",
        "    - 데이터\n",
        "        * Image Generator를 연결하거나\n",
        "        * 기존 train, validation 셋을 이용해도 됩니다.\n",
        "        - Early Stopping을 반드시 사용하세요.\n",
        "        - 최적의 가중치를 모델에 적용하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtqQIS-HxXlg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zg0L88Gwf4l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbhiWcS5i735"
      },
      "source": [
        "#### 4) 성능 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ik4AFzCQi735"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkkSsyMoi735"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGuQMUJNxXSy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
