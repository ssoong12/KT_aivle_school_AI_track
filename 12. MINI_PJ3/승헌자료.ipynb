{"cells":[{"cell_type":"markdown","metadata":{"id":"JLojLUpcGNbk"},"source":["# **차량 공유업체의 차량 파손 여부 분류하기**"]},{"cell_type":"markdown","source":["## 0.미션\n","\n","* 1) 미션1 : Data Preprocessing\n","    - **과제 수행 목표**\n","        - 본인의 구글 드라이브에 모델링 수행을 위해 적절한 폴더 및 파일로 **일관성 있게 정리**해야 합니다.\n","        - 제공된 데이터 : Car_Images.zip\n","            * Car_Images : 차량의 정상/파손 이미지 무작위 수집"],"metadata":{"id":"BbrllJY8JdkF"}},{"cell_type":"markdown","source":["* 2) 미션2 : CNN 모델링\n","    - **과제 수행 목표**\n","        - Tensorflow Keras를 이용하여 모델을 3개 이상 생성하세요.\n","            - 모델 구조와 파라미터는 자유롭게 구성하세요.\n","            - 단, 세부 목차에서 명시한 부분은 지켜주세요."],"metadata":{"id":"Hgdg96jE-mmd"}},{"cell_type":"markdown","source":["* 3) 미션3 : Data Argumentation & Transfer Learning\n","    - **과제 수행 목표**\n","        - 성능 개선을 위해 다음의 두가지를 시도하세요.\n","            * Data Augmentation을 적용하세요.(Image Generator)\n","            * Transfer Learning(VGG16)\n"],"metadata":{"id":"VRrUY4ud_rJV"}},{"cell_type":"markdown","metadata":{"id":"7MdjZtxfGNKz"},"source":["## 1.환경설정 "]},{"cell_type":"markdown","metadata":{"id":"6QgFWzN9xhlr"},"source":["### (1) 데이터셋 폴더 생성\n","- **세부요구사항**\n","    - C드라이브에 Datasets라는 폴더를 만드세요.\n","        - 구글드라이브를 사용하는경우 드라이브 첫 화면에 Datasets 라는 폴더를 만드세요. ('/content/drive/MyDrive/Datasets/')\n","    - 해당 폴더 안에 Car_Images.zip 파일을 넣으세요."]},{"cell_type":"markdown","source":["* 구글 Colab을 이용하는 경우"],"metadata":{"id":"Elg8NL8vwUs5"}},{"cell_type":"markdown","source":[],"metadata":{"id":"rVIGq060aIlj"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"kWUbDvBzwiTq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679366939188,"user_tz":-540,"elapsed":21418,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}},"outputId":"2255ffbd-5cea-4e61-8d41-89415d065f28"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"0sVNbCKnLUGc"},"source":["### (2) 데이터셋 불러오기 \n","- **세부요구사항**\n","    - Car_Images.zip 파일을 C:/Datasets/ 경로에 압축 해제합니다.\n","    - zipfile 모듈을 이용하거나 다른 방식을 사용해도 됩니다.\n","        - 참고 자료 : [zipfile document](https://docs.python.org/3/library/zipfile.html#zipfile-objects)\n","    - 폴더구조(로컬)\n","        * C:/Datasets/ : 압축파일\n","        * C:/Datasets/Car_Images_train/ : 압축 해제한 이미지 저장소\n","    - 폴더구조(구글드라이브브)\n","        * /content/drive/MyDrive/Datasets/ : 압축파일\n","        * /content/drive/MyDrive/Datasets/Car_Images_train/ : 압축 해제한 이미지 저장소\n","    - 압축을 해제하면 다음과 같은 두 하위 폴더가 생성됩니다.\n","        * normal, abnormal : 각 폴더에는 이미지들이 있습니다.\n","        * 이후 단계에서 해당 경로로 부터 validation, test 셋을 추출하게 됩니다.\n","        "]},{"cell_type":"code","execution_count":2,"metadata":{"id":"K2-8EaA9x4Xm","executionInfo":{"status":"ok","timestamp":1679366956143,"user_tz":-540,"elapsed":427,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"outputs":[],"source":["import zipfile\n","import os"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"hMkstFLKx4Xm","executionInfo":{"status":"ok","timestamp":1679367374618,"user_tz":-540,"elapsed":307,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"outputs":[],"source":["# 압축파일 경로\n","# 구글 드라이브인 경우 경로에 맞게 지정하세요.\n","dataset_path  = '/content/drive/MyDrive/Datasets/'\n","\n","file_path = dataset_path + 'Car_Images.zip'"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"sgT_RB14Lwza","executionInfo":{"status":"ok","timestamp":1679367393648,"user_tz":-540,"elapsed":17192,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"outputs":[],"source":["#폴더 만들기\n","mkdir_path = dataset_path+'Car_Images_train/'\n","os.makedirs(mkdir_path, exist_ok=True)\n","\n","#만든 폴더에 압축 해제\n","zipfile.ZipFile(file_path).extractall(mkdir_path)"]},{"cell_type":"markdown","metadata":{"id":"8hgC0axQyMhI"},"source":["### (3) 이미지 저장을 위한 폴더 생성\n","- **세부요구사항**\n","    - train, validation, test 을 위해 각각 하위 폴더 normal과 abnormal를 준비합니다.\n","        - train\n","            * 정상 이미지 저장소 : C:/Datasets/Car_Images_train/normal/ \n","                * 구글드라이브 :   /content/drive/MyDrive/Datasets/Car_Images_train/normal/\n","            * 파손 이미지 저장소 : C:/Datasets/Car_Images_train/abnormal/\n","                * 구글드라이브 : /content/drive/MyDrive/Datasets/Car_Images_train/abnormal/\n","        - val, test 역시 동일한 구조로 생성합니다.\n","    - 직접 탐색기에서 폴더를 생성할 수도 있고, os 모듈을 이용하여 코드로 작성할 수도 있습니다.\n","        - 참고 자료 : [os document](https://docs.python.org/3/library/os.html)"]},{"cell_type":"code","source":["len(os.listdir(dataset_path + 'Car_Images_train/normal/')), len(os.listdir(dataset_path + 'Car_Images_train/abnormal/'))"],"metadata":{"id":"fuPkpOSmdwsq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679367410172,"user_tz":-540,"elapsed":311,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}},"outputId":"71e39b9d-f074-4d8f-86e1-ee94a1969ab1"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(302, 303)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["#test data 폴더 만들기\n","path = dataset_path+'Car_Images_test/'\n","os.makedirs(path, exist_ok=True)\n","\n","#val data 폴더 만들기\n","path = dataset_path+'Car_Images_val/'\n","os.makedirs(path, exist_ok=True)"],"metadata":{"id":"HmahpLS-essK","executionInfo":{"status":"ok","timestamp":1679367416181,"user_tz":-540,"elapsed":277,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FYZKJrP0GtPh"},"source":["## 2.데이터 전처리"]},{"cell_type":"markdown","metadata":{"id":"j-ilpDQfInAE"},"source":["### (1) 데이터 분할 : Training set | Validation set | Test set 생성\n","- **세부요구사항**\n","    - Training set, Validation set, Test set을 만듭니다.\n","        * size\n","            * test : 전체에서 20%를 추출합니다.\n","            * validation : test를 떼어낸 나머지에서 다시 20%를 추출합니다.\n","        * 데이터는 랜덤하게 추출해야 합니다.\n","            - random, shutil 모듈을 이용하여 랜덤하게 추출할 수 있습니다.\n","                - [random document](https://docs.python.org/3/library/random.html) | [shutil document](https://docs.python.org/3/library/shutil.html)\n","            * 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n","---"]},{"cell_type":"markdown","source":["#### 1) test, validation 크기를 지정"],"metadata":{"id":"mFMSDA26RS-E"}},{"cell_type":"code","execution_count":10,"metadata":{"id":"JhQ_Gu_KNR2g","executionInfo":{"status":"ok","timestamp":1679367450594,"user_tz":-540,"elapsed":280,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"outputs":[],"source":["import random, shutil"]},{"cell_type":"code","source":["tr_n_path = mkdir_path + 'normal/'\n","tr_ab_path  = mkdir_path + 'abnormal/'"],"metadata":{"id":"WaUbXFGqgJ8l","executionInfo":{"status":"ok","timestamp":1679367456764,"user_tz":-540,"elapsed":274,"user":{"displayName":"쑹쨩","userId":"02967438864685795672"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# 전체 이미지 갯수를 확인합니다.\n","len(os.listdir(tr_n_path)) , len(os.listdir(tr_ab_path))"],"metadata":{"id":"G5uoeGZ2fSfg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test 사이즈 : 전체 이미지의 20%\n","te_data_num = [round(len(os.listdir(tr_n_path))*0.2), round(len(os.listdir(tr_ab_path))*0.2)]\n","print(te_data_num)\n","\n","# validation 사이즈 : test를 제외한 나머지 중에서 20%\n","val_data_num = [ round((len(os.listdir(tr_n_path))-te_data_num[0])*0.2) , round((len(os.listdir(tr_ab_path))-te_data_num[1])*0.2) ]\n","print(val_data_num)\n","\n","# train 사이즈\n","train_data_num = [len(os.listdir(tr_n_path)) - te_data_num[0] - val_data_num[0], len(os.listdir(tr_ab_path))- te_data_num[1] - val_data_num[1]]\n","print(train_data_num)"],"metadata":{"id":"W_6gbiCOfTe8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 2) test 셋 추출"],"metadata":{"id":"RmRhrViWRXgL"}},{"cell_type":"code","source":["from tensorflow.keras.utils import load_img"],"metadata":{"id":"41_mpytxjLv0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#나뉘기전(현재의 train) 데이터와 해당 데이터 경로 가져오기\n","n_img_path_list = os.listdir(tr_n_path)\n","ab_img_path_list = os.listdir(tr_ab_path)"],"metadata":{"id":"LVploijVk9Xu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_img_path_list[:5]"],"metadata":{"id":"hWVhkQNMmjoh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#섞기\n","random.seed(2023)\n","random.shuffle(n_img_path_list)\n","random.shuffle(ab_img_path_list)"],"metadata":{"id":"prN1Hg9Umdnx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_img_path_list[:5]"],"metadata":{"id":"yLXomMvPnAF1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test data 개수 만큼 test로 분리\n","test_n_path = n_img_path_list[:te_data_num[0]]\n","test_ab_path = ab_img_path_list[:te_data_num[1]]\n","\n","#나머지는 train\n","train_n_path = n_img_path_list[te_data_num[0]:]\n","train_ab_path = ab_img_path_list[te_data_num[1]:]"],"metadata":{"id":"60zHPdkrmIW2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 3) validation 셋 추출"],"metadata":{"id":"2V4mh3hxRpR2"}},{"cell_type":"markdown","source":["val_data 슬라이싱, train_data 슬라이싱"],"metadata":{"id":"AAY-QZ5NyUiy"}},{"cell_type":"code","source":["#train data에서 val data 개수 만큼 val로 분리\n","val_n_path = train_n_path[:val_data_num[0]]\n","val_ab_path = train_ab_path[:val_data_num[1]]\n","\n","#나머지는 train\n","train_n_path = train_n_path[val_data_num[0]:]\n","train_ab_path = train_ab_path[val_data_num[1]:]"],"metadata":{"id":"gF0xUsLpohto"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(train_n_path), len(train_ab_path), len(test_n_path), len(test_ab_path), len(val_n_path), len(val_ab_path)"],"metadata":{"id":"7w4W2TIRpC0X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"haSO004sgyyu"},"source":["### (2) 데이터 복사 및 이동\n","- **세부요구사항**\n","    - 분할된 데이터를 복사 이동합니다.\n","        - 새로운 폴더에 저장하는 데이터로 \"3.모델링I\"에서 사용합니다.\n","        - 기존 폴더는 \"4.모델링II > (1) Data Augmentation\"에서 사용합니다.\n","    - Training set | Validation set | Test set의 데이터를 **새로운 폴더**에 복사하세요.\n","        - 새로운 폴더 명\n","            * copy_images/trainset\n","            * copy_images/validset\n","            * copy_images/testset\n","        - 새로운 폴더에는 normal, abnormal 파일 모두를 복사합니다. \n","            * 파일을 구분하기 위해 abnormal 파일들은 파일명 앞에 접두사 'ab_'를 붙입시다.\n","        - os, shutil 모듈을 활용하세요."]},{"cell_type":"code","source":["os.makedirs(dataset_path+'copy_images/trainset', exist_ok= True)\n","os.makedirs(dataset_path+'copy_images/validset', exist_ok= True)\n","os.makedirs(dataset_path+'copy_images/testset', exist_ok= True)"],"metadata":{"id":"9Yi828ZkB-Vh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"oICly_TWjwG_"}},{"cell_type":"code","source":["def copyfile_splited(filenames, src, dest):\n","    bin_class = src.split('/')[-2]\n","    for filename in filenames:\n","        if 'ab' in bin_class:# ab_ 구분 처리\n","            shutil.copy(src+filename, dest+'ab_'+filename)    \n","        else:\n","            shutil.copy(src+filename, dest+filename)"],"metadata":{"id":"pDl6l2_7q-Gc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["copyfile_s plited(train_n_path, dataset_path + 'Car_Images_train/normal/', dataset_path+'copy_images/trainset/')\n","copyfile_splited(train_ab_path, dataset_path + 'Car_Images_train/abnormal/', dataset_path+'copy_images/trainset/')\n","\n","copyfile_splited(test_n_path, dataset_path + 'Car_Images_train/normal/', dataset_path+'copy_images/testset/')\n","copyfile_splited(test_ab_path, dataset_path + 'Car_Images_train/abnormal/', dataset_path+'copy_images/testset/')\n","\n","copyfile_splited(val_n_path, dataset_path + 'Car_Images_train/normal/', dataset_path+'copy_images/validset/')\n","copyfile_splited(val_ab_path, dataset_path + 'Car_Images_train/abnormal/', dataset_path+'copy_images/validset/')"],"metadata":{"id":"u8Uq4rbGveUk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(os.listdir('/content/drive/MyDrive/Datasets/copy_images/testset')), len(os.listdir('/content/drive/MyDrive/Datasets/copy_images/trainset')), len(os.listdir('/content/drive/MyDrive/Datasets/copy_images/validset')),"],"metadata":{"id":"Fa9ZKMbAwoe1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 1) abnormal 파일 복사"],"metadata":{"id":"3UbNfTY4kOSZ"}},{"cell_type":"markdown","source":["* 복사하기 : shutil.copytree()"],"metadata":{"id":"zhkKqLfTkjGI"}},{"cell_type":"markdown","source":["* abnormal 이미지 이름의 접두어 \"ab_\" 붙이기 : os.rename"],"metadata":{"id":"mU0T-ypHkV6D"}},{"cell_type":"markdown","source":["**새로운 폴더 만들기(train, test, val)**"],"metadata":{"id":"8iI5CoBct0i-"}},{"cell_type":"markdown","source":["#### 2) normal 파일 복사"],"metadata":{"id":"Nk6xITmTksyK"}},{"cell_type":"markdown","source":["* 데이터 갯수 조회"],"metadata":{"id":"xzEXHZrqkz88"}},{"cell_type":"markdown","metadata":{"id":"VfYDW1Pj7ZdU"},"source":["## 3.모델링 I\n","* **세부요구사항**\n","    * 모델링을 위한 데이터 구조 만들기\n","        * x : 이미지를 array로 변환합니다.\n","        * y : 이미지 갯수만큼 normal - 0, abnormal - 1 로 array를 만듭니다.\n","    * 모델을 최소 3개 이상 만들고 성능을 비교합니다.\n","        * 모델 학습 과정에 알맞은 보조 지표를 사용하세요.\n","        * 전처리 과정에서 생성한 Validation set을 적절하게 사용하세요.\n","        * Early Stopping을 반드시 사용하세요.\n","            * 최적의 가중치를 모델에 적용하세요."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rg553KIvxE6W"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.callbacks import EarlyStopping\n","from sklearn.metrics import classification_report, confusion_matrix"]},{"cell_type":"markdown","metadata":{"id":"wIfqg6e0xE6A"},"source":["### (1) X : image to array\n","- **세부요구사항**\n","    * 모델링을 위해서는 np.array 형태로 데이터셋을 만들어야 합니다.\n","    * Training set / Validation set / Test set의 X는 이미지 형태로 되어있습니다. \n","    * 이미지 파일을 불러와 train, valid, test 각각 array 형태로 변환해 봅시다.\n","        * 각 폴더로 부터 이미지 목록을 만들고\n","        * 이미지 한장씩 적절한 크기로 로딩하여 (keras.utils.load_img)\n","            * 이미지가 너무 크면 학습시간이 많이 걸리고, 메모리 부족현상이 발생될 수 있습니다.\n","            * 이미지 크기를 280 * 280 * 3 이내의 크기를 설정하여 로딩하시오.\n","            * array로 변환 (keras.utils.img_to_array, np.expand_dims)\n","        * 데이터셋에 추가합니다.(데이터셋도 array)"]},{"cell_type":"markdown","source":["#### 1) 이미지 목록 만들기\n","* train, validation, test 폴더로 부터 이미지 목록을 생성합니다."],"metadata":{"id":"FovkIeSDT367"}},{"cell_type":"code","source":["from tensorflow.keras.utils import load_img, img_to_array"],"metadata":{"id":"dxoSoeR_2mpn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"Tbshppas3Joj"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"X022f0QMxE6W"},"outputs":[],"source":["# 이미지 목록 저장\n","img_train_list = os.listdir(dataset_path + 'copy_images/trainset/')\n","img_test_list = os.listdir(dataset_path + 'copy_images/testset/')\n","img_valid_list = os.listdir(dataset_path + 'copy_images/validset/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rgvW_LQfxE6X"},"outputs":[],"source":["# 메모리, 처리시간을 위해서 이미지 크기 조정\n","img_size = 280 ## 사이즈 조정 가능"]},{"cell_type":"markdown","source":["#### 2) 이미지들을 배열 데이터셋으로 만들기"],"metadata":{"id":"LSt88mjPV33u"}},{"cell_type":"code","source":[],"metadata":{"id":"XZteS3SrOa87"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def make_img_to_array(path, img_list, img_size):\n","    temp_x = []\n","    img_arr_x = []\n","    #x데이터 개수만큼 abnormal : 0, normal : 1\n","    temp_y = [1]*len(img_list)\n","\n","    #각 이미지 별 데이터 만들기\n","    for idx, img_name in enumerate(img_list):\n","        temp_x.append(load_img(path + img_name, target_size=(img_size, img_size)))\n","        \n","        #abnormal은 0\n","        if 'ab' == img_name[:2]:\n","            temp_y[idx] = 0\n","\n","    #img를 array로 변환\n","    for img in temp_x:\n","        img_arr_x.append(img_to_array(img))    \n","\n","    return [np.array(img_arr_x), np.array(temp_y)]"],"metadata":{"id":"M4j8zBZG4PhH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x, train_y = make_img_to_array(dataset_path + 'copy_images/trainset/', img_train_list, img_size)\n","test_x, test_y = make_img_to_array(dataset_path + 'copy_images/testset/', img_test_list, img_size)\n","val_x, val_y = make_img_to_array(dataset_path + 'copy_images/validset/', img_valid_list, img_size)"],"metadata":{"id":"bfRIDOvf4xU3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x.shape, train_y.shape, test_x.shape, test_y.shape, val_x.shape, val_y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Oc0aUs39pfn","executionInfo":{"status":"ok","timestamp":1679358635539,"user_tz":-540,"elapsed":11,"user":{"displayName":"이승헌","userId":"14109543146458016797"}},"outputId":"028be418-6f81-4d8c-8d5c-120747099189"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((388, 280, 280, 3),\n"," (388,),\n"," (121, 280, 280, 3),\n"," (121,),\n"," (96, 280, 280, 3),\n"," (96,))"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"doUM37LxxE6Z"},"source":["### (2) y : 클래스 만들기\n","- **세부요구사항**\n","    - Training set / Validation set / Test set의 y를 생성합니다.\n","        - 각각 normal, abnormal 데이터의 갯수를 다시 확인하고\n","        - normal을 0, abnormal을 1로 지정합니다."]},{"cell_type":"markdown","source":["* y_train, y_valid, y_test 만들기\n","    * normal, abnormal 데이터의 갯수를 다시 확인하고 normal을 0, abnormal을 1로 지정합니다."],"metadata":{"id":"HIfaCLlNn04C"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"YVrPQdhTxE6b"},"outputs":[],"source":["\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Z586wXFu7ZgT"},"source":["### (3) 모델1\n","- **세부요구사항**\n","    - Conv2D, MaxPooling2D, Flatten, Dense 레이어들을 이용하여 모델을 설계\n","    - 학습시 validation_data로 validation set을 사용하시오.\n","    - 반드시 Early Stopping 적용\n","    - 평가시, confusion matrix, accuracy, recall, precision, f1 score 등을 이용하시오."]},{"cell_type":"code","source":["train_x.max(), train_x.min()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f78byY29N4RN","executionInfo":{"status":"ok","timestamp":1679327546688,"user_tz":-540,"elapsed":14,"user":{"displayName":"이승헌","userId":"14109543146458016797"}},"outputId":"72e8ddb6-af7a-4410-d363-12dace527d49"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(255.0, 0.0)"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# max_n, min_n = train_x.max(), train_x.min()\n","\n","# train_x = (train_x - min_n)/(max_n - min_n)\n","# test_x = (test_x - min_n)/(max_n - min_n)\n","# val_x = (val_x - min_n)/(max_n - min_n)"],"metadata":{"id":"8BmOdX_4Nb14"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mean_n = train_x.mean()\n","std_n = train_x.std()\n","\n","train_x = (train_x - mean_n) / std_n\n","test_x = (test_x - mean_n) / std_n\n","val_x = (val_x - mean_n) / std_n"],"metadata":{"id":"i9iwJkqKitmX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x.max(), train_x.min(), test_x.max(), test_x.min(), val_x.max(), val_x.min()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nyV4X_DzOBUy","executionInfo":{"status":"ok","timestamp":1679358647106,"user_tz":-540,"elapsed":580,"user":{"displayName":"이승헌","userId":"14109543146458016797"}},"outputId":"4a2ae223-943e-4111-c088-2e2137e283fd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1.9317106, -1.9624671, 1.9317106, -1.9624671, 1.9317106, -1.9624671)"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["from tensorflow.keras.utils import to_categorical\n","\n","class_n = len(np.unique(train_y))"],"metadata":{"id":"9KiIgf6MOGkz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_y = to_categorical(train_y, class_n)\n","test_y = to_categorical(test_y, class_n)\n","val_y = to_categorical(val_y, class_n)"],"metadata":{"id":"P_F4ssbZPDaU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"llX_ePK1Pn6x","executionInfo":{"status":"ok","timestamp":1679327546689,"user_tz":-540,"elapsed":8,"user":{"displayName":"이승헌","userId":"14109543146458016797"}},"outputId":"416b0dd1-d042-41f0-d950-476b94f58bcd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(388, 2)"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["#### 1) 구조 설계"],"metadata":{"id":"NIvIO6RKa0mp"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"7TtIIz6XJQ5E"},"outputs":[],"source":["from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPool2D, BatchNormalization, Dropout, Flatten\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.models import Model"]},{"cell_type":"code","source":["clear_session()\n","\n","il = Input(shape = (img_size, img_size, 3))\n","\n","hl = Conv2D(filters = 32, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(il)\n","hl = Conv2D(filters = 32, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D(filters = 32, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = BatchNormalization()(hl)\n","hl = MaxPool2D(pool_size= (2, 2), strides = (2, 2))(hl)\n","\n","hl = Conv2D(filters = 64, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D(filters = 64, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D(filters = 64, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = BatchNormalization()(hl)\n","hl = MaxPool2D(pool_size= (2, 2), strides = (2, 2))(hl)\n","\n","hl = Conv2D(filters = 128, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D(filters = 128, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D(filters = 128, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = BatchNormalization()(hl)\n","hl = MaxPool2D(pool_size= (2, 2), strides = (2, 2))(hl)\n","\n","hl = Conv2D(filters = 256, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D(filters = 256, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D(filters = 256, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = BatchNormalization()(hl)\n","hl = MaxPool2D(pool_size= (2, 2), strides = (2, 2))(hl)\n","\n","hl = Conv2D(filters = 512, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D(filters = 512, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D(filters = 512, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = BatchNormalization()(hl)\n","hl = MaxPool2D(pool_size= (2, 2), strides = (2, 2))(hl)\n","\n","hl = Flatten()(hl)\n","hl = Dense(128, activation = 'relu')(hl)\n","hl = BatchNormalization()(hl)\n","hl = Dropout(0.35)(hl)\n","\n","ol = Dense(2, activation = 'sigmoid')(hl)\n","\n","model = Model(il, ol)\n","\n","model.compile(loss = 'binary_crossentropy', metrics = ['accuracy'], optimizer = 'adam')\n","\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VNeYwQJ6KVyP","executionInfo":{"status":"ok","timestamp":1679327551340,"user_tz":-540,"elapsed":4657,"user":{"displayName":"이승헌","userId":"14109543146458016797"}},"outputId":"f7ce1657-0b96-4c89-8870-9c75557c544b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 280, 280, 3)]     0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 280, 280, 32)      896       \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 280, 280, 32)      9248      \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 280, 280, 32)      9248      \n","                                                                 \n"," batch_normalization (BatchN  (None, 280, 280, 32)     128       \n"," ormalization)                                                   \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 140, 140, 32)     0         \n"," )                                                               \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 140, 140, 64)      18496     \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 140, 140, 64)      36928     \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 140, 140, 64)      36928     \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 140, 140, 64)     256       \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 70, 70, 64)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 70, 70, 128)       73856     \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 70, 70, 128)       147584    \n","                                                                 \n"," conv2d_8 (Conv2D)           (None, 70, 70, 128)       147584    \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 70, 70, 128)      512       \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 35, 35, 128)      0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_9 (Conv2D)           (None, 35, 35, 256)       295168    \n","                                                                 \n"," conv2d_10 (Conv2D)          (None, 35, 35, 256)       590080    \n","                                                                 \n"," conv2d_11 (Conv2D)          (None, 35, 35, 256)       590080    \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 35, 35, 256)      1024      \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 17, 17, 256)      0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_12 (Conv2D)          (None, 17, 17, 512)       1180160   \n","                                                                 \n"," conv2d_13 (Conv2D)          (None, 17, 17, 512)       2359808   \n","                                                                 \n"," conv2d_14 (Conv2D)          (None, 17, 17, 512)       2359808   \n","                                                                 \n"," batch_normalization_4 (Batc  (None, 17, 17, 512)      2048      \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_4 (MaxPooling  (None, 8, 8, 512)        0         \n"," 2D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 32768)             0         \n","                                                                 \n"," dense (Dense)               (None, 128)               4194432   \n","                                                                 \n"," batch_normalization_5 (Batc  (None, 128)              512       \n"," hNormalization)                                                 \n","                                                                 \n"," dropout (Dropout)           (None, 128)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 2)                 258       \n","                                                                 \n","=================================================================\n","Total params: 12,055,042\n","Trainable params: 12,052,802\n","Non-trainable params: 2,240\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["#### 2) 학습\n","* EarlyStopping 설정하고 학습시키기"],"metadata":{"id":"DHM91_bha3Kc"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"OHnFVZuKa42f"},"outputs":[],"source":["from tensorflow.keras.callbacks import EarlyStopping"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BnrTSupKa42f"},"outputs":[],"source":["es = EarlyStopping(monitor='val_loss', min_delta=0, patience=15, verbose = 1, restore_best_weights= True)"]},{"cell_type":"code","source":["model.fit(train_x, train_y, epochs= 1000, validation_data=(val_x, val_y), verbose = 1, callbacks= [es])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UtsGlCrRRlJa","executionInfo":{"status":"ok","timestamp":1679327811416,"user_tz":-540,"elapsed":260079,"user":{"displayName":"이승헌","userId":"14109543146458016797"}},"outputId":"f2250e87-39b3-4010-c823-53406b82af4b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/1000\n","13/13 [==============================] - 28s 571ms/step - loss: 0.6693 - accuracy: 0.7139 - val_loss: 11.7679 - val_accuracy: 0.5000\n","Epoch 2/1000\n","13/13 [==============================] - 5s 378ms/step - loss: 0.5055 - accuracy: 0.8119 - val_loss: 6.3403 - val_accuracy: 0.5208\n","Epoch 3/1000\n","13/13 [==============================] - 5s 379ms/step - loss: 0.4636 - accuracy: 0.8015 - val_loss: 4.4835 - val_accuracy: 0.5938\n","Epoch 4/1000\n","13/13 [==============================] - 5s 380ms/step - loss: 0.4640 - accuracy: 0.8247 - val_loss: 1.7304 - val_accuracy: 0.6667\n","Epoch 5/1000\n","13/13 [==============================] - 5s 381ms/step - loss: 0.4325 - accuracy: 0.8402 - val_loss: 0.6758 - val_accuracy: 0.8125\n","Epoch 6/1000\n","13/13 [==============================] - 5s 382ms/step - loss: 0.3670 - accuracy: 0.8608 - val_loss: 0.4560 - val_accuracy: 0.8333\n","Epoch 7/1000\n","13/13 [==============================] - 5s 378ms/step - loss: 0.3378 - accuracy: 0.8737 - val_loss: 0.6174 - val_accuracy: 0.7396\n","Epoch 8/1000\n","13/13 [==============================] - 5s 380ms/step - loss: 0.2930 - accuracy: 0.8737 - val_loss: 0.9196 - val_accuracy: 0.7083\n","Epoch 9/1000\n","13/13 [==============================] - 5s 381ms/step - loss: 0.3404 - accuracy: 0.8608 - val_loss: 0.7169 - val_accuracy: 0.7917\n","Epoch 10/1000\n","13/13 [==============================] - 5s 381ms/step - loss: 0.3623 - accuracy: 0.8557 - val_loss: 0.7120 - val_accuracy: 0.7708\n","Epoch 11/1000\n","13/13 [==============================] - 5s 381ms/step - loss: 0.3181 - accuracy: 0.8763 - val_loss: 0.4782 - val_accuracy: 0.7604\n","Epoch 12/1000\n","13/13 [==============================] - 5s 382ms/step - loss: 0.3161 - accuracy: 0.8814 - val_loss: 0.7584 - val_accuracy: 0.7500\n","Epoch 13/1000\n","13/13 [==============================] - 5s 384ms/step - loss: 0.2529 - accuracy: 0.9046 - val_loss: 0.7052 - val_accuracy: 0.7083\n","Epoch 14/1000\n","13/13 [==============================] - 5s 386ms/step - loss: 0.2382 - accuracy: 0.9304 - val_loss: 0.7415 - val_accuracy: 0.7188\n","Epoch 15/1000\n","13/13 [==============================] - 5s 386ms/step - loss: 0.2540 - accuracy: 0.9072 - val_loss: 0.9949 - val_accuracy: 0.6771\n","Epoch 16/1000\n","13/13 [==============================] - 5s 386ms/step - loss: 0.2636 - accuracy: 0.8943 - val_loss: 0.8551 - val_accuracy: 0.7292\n","Epoch 17/1000\n","13/13 [==============================] - 5s 387ms/step - loss: 0.2667 - accuracy: 0.8969 - val_loss: 0.6414 - val_accuracy: 0.7500\n","Epoch 18/1000\n","13/13 [==============================] - 5s 390ms/step - loss: 0.2396 - accuracy: 0.9124 - val_loss: 0.8556 - val_accuracy: 0.6979\n","Epoch 19/1000\n","13/13 [==============================] - 5s 397ms/step - loss: 0.1702 - accuracy: 0.9510 - val_loss: 0.3604 - val_accuracy: 0.8438\n","Epoch 20/1000\n","13/13 [==============================] - 5s 397ms/step - loss: 0.5577 - accuracy: 0.7835 - val_loss: 16.3985 - val_accuracy: 0.6354\n","Epoch 21/1000\n","13/13 [==============================] - 5s 397ms/step - loss: 0.4256 - accuracy: 0.8325 - val_loss: 28.4768 - val_accuracy: 0.5833\n","Epoch 22/1000\n","13/13 [==============================] - 5s 400ms/step - loss: 0.3640 - accuracy: 0.8660 - val_loss: 7.1006 - val_accuracy: 0.6146\n","Epoch 23/1000\n","13/13 [==============================] - 5s 402ms/step - loss: 0.3428 - accuracy: 0.8789 - val_loss: 1.0141 - val_accuracy: 0.7500\n","Epoch 24/1000\n","13/13 [==============================] - 5s 404ms/step - loss: 0.3230 - accuracy: 0.8814 - val_loss: 0.5646 - val_accuracy: 0.7917\n","Epoch 25/1000\n","13/13 [==============================] - 5s 407ms/step - loss: 0.3076 - accuracy: 0.8866 - val_loss: 0.4211 - val_accuracy: 0.8542\n","Epoch 26/1000\n","13/13 [==============================] - 5s 411ms/step - loss: 0.2440 - accuracy: 0.9046 - val_loss: 0.7134 - val_accuracy: 0.7708\n","Epoch 27/1000\n","13/13 [==============================] - 5s 413ms/step - loss: 0.2892 - accuracy: 0.8943 - val_loss: 0.6324 - val_accuracy: 0.6875\n","Epoch 28/1000\n","13/13 [==============================] - 5s 416ms/step - loss: 0.2367 - accuracy: 0.9149 - val_loss: 0.6882 - val_accuracy: 0.7812\n","Epoch 29/1000\n","13/13 [==============================] - 5s 412ms/step - loss: 0.1867 - accuracy: 0.9278 - val_loss: 0.3988 - val_accuracy: 0.8646\n","Epoch 30/1000\n","13/13 [==============================] - 5s 409ms/step - loss: 0.1648 - accuracy: 0.9407 - val_loss: 0.3983 - val_accuracy: 0.8646\n","Epoch 31/1000\n","13/13 [==============================] - 5s 411ms/step - loss: 0.1744 - accuracy: 0.9227 - val_loss: 0.3437 - val_accuracy: 0.8750\n","Epoch 32/1000\n","13/13 [==============================] - 5s 405ms/step - loss: 0.1786 - accuracy: 0.9381 - val_loss: 0.5855 - val_accuracy: 0.8438\n","Epoch 33/1000\n","13/13 [==============================] - 5s 403ms/step - loss: 0.1891 - accuracy: 0.9381 - val_loss: 0.9713 - val_accuracy: 0.7083\n","Epoch 34/1000\n","13/13 [==============================] - 5s 403ms/step - loss: 0.1700 - accuracy: 0.9536 - val_loss: 1.0959 - val_accuracy: 0.7292\n","Epoch 35/1000\n","13/13 [==============================] - 5s 402ms/step - loss: 0.1596 - accuracy: 0.9459 - val_loss: 0.6460 - val_accuracy: 0.7917\n","Epoch 36/1000\n","13/13 [==============================] - 5s 401ms/step - loss: 0.5064 - accuracy: 0.7861 - val_loss: 2.2330 - val_accuracy: 0.6979\n","Epoch 37/1000\n","13/13 [==============================] - 5s 401ms/step - loss: 0.4693 - accuracy: 0.7912 - val_loss: 10.4127 - val_accuracy: 0.5000\n","Epoch 38/1000\n","13/13 [==============================] - 5s 401ms/step - loss: 0.3939 - accuracy: 0.8351 - val_loss: 4.2973 - val_accuracy: 0.5312\n","Epoch 39/1000\n","13/13 [==============================] - 5s 402ms/step - loss: 0.3158 - accuracy: 0.8634 - val_loss: 3.8783 - val_accuracy: 0.5625\n","Epoch 40/1000\n","13/13 [==============================] - 5s 403ms/step - loss: 0.3162 - accuracy: 0.8840 - val_loss: 2.1617 - val_accuracy: 0.6042\n","Epoch 41/1000\n","13/13 [==============================] - 5s 403ms/step - loss: 0.2480 - accuracy: 0.9149 - val_loss: 1.4781 - val_accuracy: 0.7188\n","Epoch 42/1000\n","13/13 [==============================] - 5s 404ms/step - loss: 0.2111 - accuracy: 0.9201 - val_loss: 0.9608 - val_accuracy: 0.7917\n","Epoch 43/1000\n","13/13 [==============================] - 5s 405ms/step - loss: 0.1991 - accuracy: 0.9278 - val_loss: 0.5913 - val_accuracy: 0.8021\n","Epoch 44/1000\n","13/13 [==============================] - 5s 406ms/step - loss: 0.1908 - accuracy: 0.9407 - val_loss: 0.4257 - val_accuracy: 0.8438\n","Epoch 45/1000\n","13/13 [==============================] - 5s 406ms/step - loss: 0.1753 - accuracy: 0.9485 - val_loss: 0.4968 - val_accuracy: 0.8229\n","Epoch 46/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.1722 - accuracy: 0.9330Restoring model weights from the end of the best epoch: 31.\n","13/13 [==============================] - 5s 412ms/step - loss: 0.1722 - accuracy: 0.9330 - val_loss: 0.3724 - val_accuracy: 0.8646\n","Epoch 46: early stopping\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f46818db760>"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["#### 3) test set으로 예측하고 평가하기\n","* 평가는 confusion_matrix, classification_report 활용"],"metadata":{"id":"zage6-Z0a6DX"}},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, classification_report"],"metadata":{"id":"uCnrA_MmbC5z"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4xkFFlFdbBZb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679327813630,"user_tz":-540,"elapsed":2234,"user":{"displayName":"이승헌","userId":"14109543146458016797"}},"outputId":"5a83b2f7-c31c-41a4-d5e2-95d4b5fecccc"},"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 2s 670ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["(121, 2)"]},"metadata":{},"execution_count":24}],"source":["y_pred = model.predict(test_x)\n","y_pred.shape"]},{"cell_type":"code","source":["single_y_pred = y_pred.argmax(axis=1)\n","single_y_pred.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gIwQzG5RbBPd","executionInfo":{"status":"ok","timestamp":1679327813631,"user_tz":-540,"elapsed":10,"user":{"displayName":"이승헌","userId":"14109543146458016797"}},"outputId":"d92d8491-ff97-463b-ee01-f92af0cd98e1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(121,)"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["print(test_y.shape)\n","single_test_y = test_y.argmax(axis=1)\n","print(single_test_y.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bckpDInxbKTh","executionInfo":{"status":"ok","timestamp":1679327813631,"user_tz":-540,"elapsed":6,"user":{"displayName":"이승헌","userId":"14109543146458016797"}},"outputId":"d65ef504-3609-4a9c-dcfe-7a03cbb0c63e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(121, 2)\n","(121,)\n"]}]},{"cell_type":"code","source":["print(confusion_matrix(single_test_y, single_y_pred))\n","print(classification_report(single_test_y, single_y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HwTuQWCAbRtt","executionInfo":{"status":"ok","timestamp":1679327813995,"user_tz":-540,"elapsed":367,"user":{"displayName":"이승헌","userId":"14109543146458016797"}},"outputId":"f90191a8-c59e-4502-b46e-5027f3125b0f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[50 11]\n"," [11 49]]\n","              precision    recall  f1-score   support\n","\n","           0       0.82      0.82      0.82        61\n","           1       0.82      0.82      0.82        60\n","\n","    accuracy                           0.82       121\n","   macro avg       0.82      0.82      0.82       121\n","weighted avg       0.82      0.82      0.82       121\n","\n"]}]},{"cell_type":"code","source":["model.save(dataset_path + 'car_cruch_model1.h5')"],"metadata":{"id":"_aebQI_RUs0S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import load_model\n","model = load_model(dataset_path + 'car_cruch_model1.h5')\n"],"metadata":{"id":"AI9OaV8NW0jH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qRoacK2mcLPb"},"source":["### (4) 모델2\n","- **세부요구사항**\n","    - Conv2D, MaxPooling2D, Flatten, Dense 레이어들을 이용하여 모델을 설계\n","    - 학습시 validation_data로 validation set을 사용하시오.\n","    - 반드시 Early Stopping 적용\n","    - 평가시, confusion matrix, accuracy, recall, precision, f1 score 등을 이용하시오."]},{"cell_type":"markdown","source":["#### 1) 구조 설계"],"metadata":{"id":"5WTwG8NFoLBQ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"UHu5gey1oLBR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679328099766,"user_tz":-540,"elapsed":795,"user":{"displayName":"이승헌","userId":"14109543146458016797"}},"outputId":"1658420a-d9dd-4fd1-a895-ef5a3327468b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 280, 280, 3)]     0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 280, 280, 128)     3584      \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 280, 280, 128)     147584    \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 280, 280, 128)     147584    \n","                                                                 \n"," batch_normalization (BatchN  (None, 280, 280, 128)    512       \n"," ormalization)                                                   \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 140, 140, 128)    0         \n"," )                                                               \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 140, 140, 256)     295168    \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 140, 140, 256)     590080    \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 140, 140, 256)     590080    \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 140, 140, 256)    1024      \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 70, 70, 256)      0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 70, 70, 512)       1180160   \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 70, 70, 512)       2359808   \n","                                                                 \n"," conv2d_8 (Conv2D)           (None, 70, 70, 512)       2359808   \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 70, 70, 512)      2048      \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 35, 35, 512)      0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_9 (Conv2D)           (None, 35, 35, 256)       1179904   \n","                                                                 \n"," conv2d_10 (Conv2D)          (None, 35, 35, 256)       590080    \n","                                                                 \n"," conv2d_11 (Conv2D)          (None, 35, 35, 256)       590080    \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 35, 35, 256)      1024      \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 17, 17, 256)      0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_12 (Conv2D)          (None, 17, 17, 128)       295040    \n","                                                                 \n"," conv2d_13 (Conv2D)          (None, 17, 17, 128)       147584    \n","                                                                 \n"," conv2d_14 (Conv2D)          (None, 17, 17, 128)       147584    \n","                                                                 \n"," batch_normalization_4 (Batc  (None, 17, 17, 128)      512       \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_4 (MaxPooling  (None, 8, 8, 128)        0         \n"," 2D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 8192)              0         \n","                                                                 \n"," dense (Dense)               (None, 64)                524352    \n","                                                                 \n"," batch_normalization_5 (Batc  (None, 64)               256       \n"," hNormalization)                                                 \n","                                                                 \n"," dropout (Dropout)           (None, 64)                0         \n","                                                                 \n"," dense_1 (Dense)             (None, 2)                 130       \n","                                                                 \n","=================================================================\n","Total params: 11,153,986\n","Trainable params: 11,151,298\n","Non-trainable params: 2,688\n","_________________________________________________________________\n"]}],"source":["clear_session()\n","\n","il = Input(shape = (img_size, img_size, 3))\n","\n","hl = Conv2D(filters = 128, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(il)\n","hl = Conv2D(filters = 128, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D(filters = 128, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = BatchNormalization()(hl)\n","hl = MaxPool2D(pool_size= (2, 2), strides = (2, 2))(hl)\n","\n","hl = Conv2D(filters = 256, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D(filters = 256, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D(filters = 256, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = BatchNormalization()(hl)\n","hl = MaxPool2D(pool_size= (2, 2), strides = (2, 2))(hl)\n","\n","hl = Conv2D(filters = 512, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D(filters = 512, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D(filters = 512, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = BatchNormalization()(hl)\n","hl = MaxPool2D(pool_size= (2, 2), strides = (2, 2))(hl)\n","\n","hl = Conv2D(filters = 256, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D(filters = 256, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D(filters = 256, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = BatchNormalization()(hl)\n","hl = MaxPool2D(pool_size= (2, 2), strides = (2, 2))(hl)\n","\n","hl = Conv2D(filters = 128, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D(filters = 128, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = Conv2D(filters = 128, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation = 'relu')(hl)\n","hl = BatchNormalization()(hl)\n","hl = MaxPool2D(pool_size= (2, 2), strides = (2, 2))(hl)\n","\n","hl = Flatten()(hl)\n","hl = Dense(64, activation = 'relu')(hl)\n","\n","hl = BatchNormalization()(hl)\n","hl = Dropout(0.35)(hl)\n","\n","ol = Dense(2, activation = 'sigmoid')(hl)\n","\n","model = Model(il, ol)\n","\n","model.compile(loss = 'binary_crossentropy', metrics = ['accuracy'], optimizer = 'adam')\n","\n","model.summary()"]},{"cell_type":"markdown","source":["#### 2) 학습\n","* EarlyStopping 설정하고 학습시키기"],"metadata":{"id":"DqTzgRTroLBR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"lcVDXnpQoLBR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679329197402,"user_tz":-540,"elapsed":1090039,"user":{"displayName":"이승헌","userId":"14109543146458016797"}},"outputId":"1148f542-77c6-4887-ae02-f056f549e285"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/1000\n","13/13 [==============================] - 57s 3s/step - loss: 0.6331 - accuracy: 0.7423 - val_loss: 563.6505 - val_accuracy: 0.5104\n","Epoch 2/1000\n","13/13 [==============================] - 29s 2s/step - loss: 0.4674 - accuracy: 0.8067 - val_loss: 170.2813 - val_accuracy: 0.5833\n","Epoch 3/1000\n","13/13 [==============================] - 30s 2s/step - loss: 0.4984 - accuracy: 0.7809 - val_loss: 124.5266 - val_accuracy: 0.5521\n","Epoch 4/1000\n","13/13 [==============================] - 31s 2s/step - loss: 0.4321 - accuracy: 0.8222 - val_loss: 33.6600 - val_accuracy: 0.5729\n","Epoch 5/1000\n","13/13 [==============================] - 30s 2s/step - loss: 0.3772 - accuracy: 0.8454 - val_loss: 8.7819 - val_accuracy: 0.6979\n","Epoch 6/1000\n","13/13 [==============================] - 30s 2s/step - loss: 0.3217 - accuracy: 0.8660 - val_loss: 3.4716 - val_accuracy: 0.7083\n","Epoch 7/1000\n","13/13 [==============================] - 30s 2s/step - loss: 0.3569 - accuracy: 0.8737 - val_loss: 3.1598 - val_accuracy: 0.7292\n","Epoch 8/1000\n","13/13 [==============================] - 30s 2s/step - loss: 0.2865 - accuracy: 0.8866 - val_loss: 2.1299 - val_accuracy: 0.7292\n","Epoch 9/1000\n","13/13 [==============================] - 30s 2s/step - loss: 0.3162 - accuracy: 0.8711 - val_loss: 1.1462 - val_accuracy: 0.7292\n","Epoch 10/1000\n","13/13 [==============================] - 30s 2s/step - loss: 0.2414 - accuracy: 0.9330 - val_loss: 0.9574 - val_accuracy: 0.8125\n","Epoch 11/1000\n","13/13 [==============================] - 31s 2s/step - loss: 0.2409 - accuracy: 0.9098 - val_loss: 0.8217 - val_accuracy: 0.8021\n","Epoch 12/1000\n","13/13 [==============================] - 31s 2s/step - loss: 0.2107 - accuracy: 0.9304 - val_loss: 0.5382 - val_accuracy: 0.8021\n","Epoch 13/1000\n","13/13 [==============================] - 30s 2s/step - loss: 0.1850 - accuracy: 0.9356 - val_loss: 0.6937 - val_accuracy: 0.7396\n","Epoch 14/1000\n","13/13 [==============================] - 30s 2s/step - loss: 0.1874 - accuracy: 0.9330 - val_loss: 0.6866 - val_accuracy: 0.8125\n","Epoch 15/1000\n","13/13 [==============================] - 30s 2s/step - loss: 0.2161 - accuracy: 0.9149 - val_loss: 0.8127 - val_accuracy: 0.7708\n","Epoch 16/1000\n","13/13 [==============================] - 30s 2s/step - loss: 0.1888 - accuracy: 0.9485 - val_loss: 0.6804 - val_accuracy: 0.8333\n","Epoch 17/1000\n","13/13 [==============================] - 30s 2s/step - loss: 0.1915 - accuracy: 0.9459 - val_loss: 0.9586 - val_accuracy: 0.7708\n","Epoch 18/1000\n","13/13 [==============================] - 30s 2s/step - loss: 0.1867 - accuracy: 0.9407 - val_loss: 0.8213 - val_accuracy: 0.7396\n","Epoch 19/1000\n","13/13 [==============================] - 30s 2s/step - loss: 0.1356 - accuracy: 0.9639 - val_loss: 0.7839 - val_accuracy: 0.8438\n","Epoch 20/1000\n","13/13 [==============================] - 30s 2s/step - loss: 0.1114 - accuracy: 0.9691 - val_loss: 0.5162 - val_accuracy: 0.8646\n","Epoch 21/1000\n","13/13 [==============================] - 30s 2s/step - loss: 0.1009 - accuracy: 0.9665 - val_loss: 0.5679 - val_accuracy: 0.8438\n","Epoch 22/1000\n","13/13 [==============================] - 30s 2s/step - loss: 0.0854 - accuracy: 0.9897 - val_loss: 0.6811 - val_accuracy: 0.7604\n","Epoch 23/1000\n","13/13 [==============================] - 30s 2s/step - loss: 0.1489 - accuracy: 0.9485 - val_loss: 0.6773 - val_accuracy: 0.8438\n","Epoch 24/1000\n","13/13 [==============================] - 30s 2s/step - loss: 0.2493 - accuracy: 0.9021 - val_loss: 1.6931 - val_accuracy: 0.7188\n","Epoch 25/1000\n","13/13 [==============================] - 30s 2s/step - loss: 0.2383 - accuracy: 0.9149 - val_loss: 1.4735 - val_accuracy: 0.7292\n","Epoch 26/1000\n","13/13 [==============================] - 30s 2s/step - loss: 0.1555 - accuracy: 0.9485 - val_loss: 1.1550 - val_accuracy: 0.7083\n","Epoch 27/1000\n","13/13 [==============================] - 30s 2s/step - loss: 0.3542 - accuracy: 0.8531 - val_loss: 16.2636 - val_accuracy: 0.6458\n","Epoch 28/1000\n","13/13 [==============================] - 30s 2s/step - loss: 0.3537 - accuracy: 0.8479 - val_loss: 18.6253 - val_accuracy: 0.7083\n","Epoch 29/1000\n","13/13 [==============================] - 30s 2s/step - loss: 0.2887 - accuracy: 0.8686 - val_loss: 12.1995 - val_accuracy: 0.6771\n","Epoch 30/1000\n","13/13 [==============================] - 30s 2s/step - loss: 0.2572 - accuracy: 0.8995 - val_loss: 4.9346 - val_accuracy: 0.7500\n","Epoch 31/1000\n","13/13 [==============================] - 30s 2s/step - loss: 0.2063 - accuracy: 0.9330 - val_loss: 2.9699 - val_accuracy: 0.7188\n","Epoch 32/1000\n","13/13 [==============================] - 30s 2s/step - loss: 0.1773 - accuracy: 0.9356 - val_loss: 1.9934 - val_accuracy: 0.7500\n","Epoch 33/1000\n","13/13 [==============================] - 30s 2s/step - loss: 0.1974 - accuracy: 0.9278 - val_loss: 1.1065 - val_accuracy: 0.7500\n","Epoch 34/1000\n","13/13 [==============================] - 30s 2s/step - loss: 0.1560 - accuracy: 0.9433 - val_loss: 3.1965 - val_accuracy: 0.6042\n","Epoch 35/1000\n","13/13 [==============================] - ETA: 0s - loss: 0.4786 - accuracy: 0.7964Restoring model weights from the end of the best epoch: 20.\n","13/13 [==============================] - 30s 2s/step - loss: 0.4786 - accuracy: 0.7964 - val_loss: 11.5780 - val_accuracy: 0.7396\n","Epoch 35: early stopping\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f45aa1a9940>"]},"metadata":{},"execution_count":35}],"source":["model.fit(train_x, train_y, epochs= 1000, validation_data=(val_x, val_y), verbose = 1, callbacks= [es])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UAhXnGmXoLBS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679358706344,"user_tz":-540,"elapsed":22210,"user":{"displayName":"이승헌","userId":"14109543146458016797"}},"outputId":"ff84c94d-e3e0-4e00-f903-a06a73c84e8c"},"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 22s 2s/step\n"]},{"output_type":"execute_result","data":{"text/plain":["(121, 2)"]},"metadata":{},"execution_count":16}],"source":["y_pred = model.predict(test_x)\n","y_pred.shape"]},{"cell_type":"code","source":["single_y_pred = y_pred.argmax(axis=1)\n","single_y_pred.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XLQTI0UIo9KY","executionInfo":{"status":"ok","timestamp":1679358706345,"user_tz":-540,"elapsed":40,"user":{"displayName":"이승헌","userId":"14109543146458016797"}},"outputId":"97d2d3b7-8304-4d21-9876-c4e0640ca8b8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(121,)"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["print(test_y.shape)\n","single_test_y = test_y.argmax(axis=1)\n","print(single_test_y.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rVgZgV-No-7p","executionInfo":{"status":"ok","timestamp":1679358706345,"user_tz":-540,"elapsed":34,"user":{"displayName":"이승헌","userId":"14109543146458016797"}},"outputId":"24076e86-d028-4037-bf3e-72c9300fb8d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(121, 2)\n","(121,)\n"]}]},{"cell_type":"code","source":["print(confusion_matrix(single_test_y, single_y_pred))\n","print(classification_report(single_test_y, single_y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bwhqjpwIpA4y","executionInfo":{"status":"ok","timestamp":1679358706346,"user_tz":-540,"elapsed":30,"user":{"displayName":"이승헌","userId":"14109543146458016797"}},"outputId":"7a89c026-3e8f-4b29-e445-8c8db3977469"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[47 14]\n"," [ 4 56]]\n","              precision    recall  f1-score   support\n","\n","           0       0.92      0.77      0.84        61\n","           1       0.80      0.93      0.86        60\n","\n","    accuracy                           0.85       121\n","   macro avg       0.86      0.85      0.85       121\n","weighted avg       0.86      0.85      0.85       121\n","\n"]}]},{"cell_type":"code","source":["model.save(dataset_path + 'car_cruch_model2.h5')"],"metadata":{"id":"-FkBxFhZpDWt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import load_model\n","model = load_model(dataset_path + 'car_cruch_model2.h5')\n"],"metadata":{"id":"fSzI3lQ1pGTK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 3) test set으로 예측하고 평가하기\n","* 평가는 confusion_matrix, classification_report 활용"],"metadata":{"id":"qxZ0U7K1oLBS"}},{"cell_type":"markdown","metadata":{"id":"MRqzBw8eccwj"},"source":["### (5) 모델3\n","- **세부요구사항**\n","    - Conv2D, MaxPooling2D, Flatten, Dense 레이어들을 이용하여 모델을 설계\n","    - 학습시 validation_data로 validation set을 사용하시오.\n","    - 반드시 Early Stopping 적용\n","    - 평가시, confusion matrix, accuracy, recall, precision, f1 score 등을 이용하시오."]},{"cell_type":"markdown","source":["#### 1) 구조 설계"],"metadata":{"id":"LtNd8u5RoNJo"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"KM-Npn6WoNJo"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["#### 2) 학습\n","* EarlyStopping 설정하고 학습시키기"],"metadata":{"id":"4zgVkXLHoNJo"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"gTlUNbkhoNJo"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T4GYo0dboNJo"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["#### 3) test set으로 예측하고 평가하기\n","* 평가는 confusion_matrix, classification_report 활용"],"metadata":{"id":"uZV9zbsroNJo"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sc9UmjZ0oNJo"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aP-p0_y9oNJo"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"AxUpfhJ1xXle"},"source":["## 4.모델링 II\n","* **세부요구사항**\n","    - 성능을 높이기 위해서 다음의 두가지를 시도해 봅시다.\n","        - Data Augmentation을 통해 데이터를 증가 시킵니다.\n","            - ImageDataGenerator를 사용합니다.\n","        - 사전 학습된 모델(Transfer Learning)을 가져다 사용해 봅시다.\n","            - VGG16(이미지넷)을 사용해 봅시다."]},{"cell_type":"markdown","metadata":{"id":"ouCRBdKPxCut"},"source":["### (1) Data Augmentation\n","- **세부요구사항**\n","    * 모델 학습에 이용할 이미지 데이터를 증강시키세요.\n","    * Keras의 ImageDataGenerator를 이용\n","        - [ImageDataGenerator document](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator)\n","\n","    * image generator를 이용하여 학습\n","        * 모델 구조는 이미 생성한 1,2,3 중 하나를 선택하여 학습\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qe6yjs8F7Zox"},"outputs":[],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wYae9YFt8Q03"},"outputs":[],"source":["img_size = 280 ## 사이즈 조정 가능\n","\n","train_path = dataset_path+'Car_Images_train/'\n","valid_path = dataset_path+'Car_Images_valid/'"]},{"cell_type":"markdown","source":["#### 1) ImageGenerator 생성\n","* ImageDataGenerator 함수 사용\n","    * 주요 옵션\n","        * rotation_range: 무작위 회전을 적용할 각도 범위\n","        * zoom_range: 무작위 줌을 적용할 범위 [1-zoom_range, 1+zoom_range]\n","        * horizontal_flip: 무작위 좌우반전을 적용할지 여부\n","        * vertical_flip: 무작위 상하반전을 적용할지 여부\n","        * rescale: 텐서의 모든 값을 rescale 값으로 나누어줌 (이 경우에는 255로 나누어서 0~1사이의 값으로 변경)"],"metadata":{"id":"IP4jIyTGfXD_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"LKPPSwYn7Zrj"},"outputs":[],"source":["train_datagen = ImageDataGenerator(\n","        rotation_range=20,      # randomly rotate images in the range (degrees, 0 to 180)\n","        zoom_range = 0.2,       # randomly zoom image \n","        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n","        height_shift_range=0.1, # randomly shift images vertically (fraction of total height)\n","        horizontal_flip=True,   # randomly flip images\n","        vertical_flip=True)     # randomly flip images\n","\n","# 어떤 데이터를 바탕으로 제너레이팅 할 것인지, 미리 알려줌! 필수!\n","train_datagen.fit(train_x)\n","\n","# 학습 할 때마다, '실시간'으로 데이터를 생성(뻥튀기 autmentation)하여 학습에 활용하고, 버리고를 반복할 준비!\n","train_gen = train_datagen.flow(train_x, train_y, batch_size=128)\n","\n","valid_datagen = ImageDataGenerator(\n","        rotation_range=20,      # randomly rotate images in the range (degrees, 0 to 180)\n","        zoom_range = 0.2,       # randomly zoom image \n","        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n","        height_shift_range=0.1, # randomly shift images vertically (fraction of total height)\n","        horizontal_flip=True,   # randomly flip images\n","        vertical_flip=True)     # randomly flip images\n","\n","# 어떤 데이터를 바탕으로 제너레이팅 할 것인지, 미리 알려줌! 필수!\n","valid_datagen.fit(train_x)\n","\n","# 학습 할 때마다, '실시간'으로 데이터를 생성(뻥튀기 autmentation)하여 학습에 활용하고, 버리고를 반복할 준비!\n","valid_gen = valid_datagen.flow(train_x, train_y, batch_size=128)\n"]},{"cell_type":"markdown","source":["#### 2) 경로로 부터 이미지 불러 올 준비\n","* .flow_from_directory 이용\n","    * 디렉토리에서 이미지를 가져와서 데이터 증강을 적용하고 batch 단위로 제공하는 generator를 생성합니다.\n","    * 이미지를 불러올 때 target_size로 크기를 맞추고, \n","    * class_mode로 이진 분류(binary)를 수행하도록 지정합니다.\n"],"metadata":{"id":"dKwSYYkufanb"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"0bwvQ4hHSCwY"},"outputs":[],"source":["train_generator = \n","\n","valid_generator = \n"]},{"cell_type":"markdown","metadata":{"id":"g4RPCjU5f662"},"source":["#### 3) 학습\n","- **세부요구사항**\n","    - Conv2D, MaxPooling2D, Flatten, Dense 레이어들을 이용하여 모델을 설계\n","    - 학습시 train_generator 이용. \n","    - validation_data = valid_generator 지정\n","    - Early Stopping 적용\n","    - 평가시, confusion matrix, accuracy, recall, precision, f1 score 등을 이용하시오."]},{"cell_type":"markdown","source":["* 구조 설계"],"metadata":{"id":"wVMLsXw6f663"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"_W7rqgH1f663"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["* 학습\n","    * EarlyStopping 설정하기\n","    * 학습 데이터에 train_generator, validation_data=valid_generator 사용"],"metadata":{"id":"nw2_G7zdf663"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6m5mRE9Nf663"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yCWzBSYqf663"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["#### 4) 성능 평가\n","* 평가는 confusion_matrix, classification_report 활용"],"metadata":{"id":"BdKiY1uIf663"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1qjnvt0lf663"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bBl4Do0af663"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"S1iv22vSxXle"},"source":["### (2) Transfer Learning\n","- **세부요구사항**\n","    * VGG16 모델은 1000개의 클래스를 분류하는 데 사용된 ImageNet 데이터셋을 기반으로 사전 학습된 가중치를 가지고 있습니다. \n","        * 따라서 이 모델은 이미지 분류 문제에 대한 높은 성능을 보입니다.\n","        * 이 모델은 보통 전이학습(transfer learning)에서 기본적으로 사용되며, 특히 대규모 데이터셋이 없을 때는 기본 모델로 사용되어 fine-tuning을 수행합니다.\n","    * VGG16 함수로 부터 base_model 저장\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RnS12YhDxXle"},"outputs":[],"source":["from tensorflow.keras.applications import VGG16"]},{"cell_type":"markdown","source":["#### 1) VGG16 불러와서 저장하기\n","* include_top=False로 설정하여 분류기를 제외하고 미리 학습된 가중치 imagenet을 로드합니다.\n","* .trainable을 True로 설정하여 모델의 모든 레이어들이 fine-tuning에 대해 업데이트되도록 합니다.\n"],"metadata":{"id":"d3kyvCwIiAfi"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"kFf3IxbBGe9B"},"outputs":[],"source":["base_model = VGG16(                 )\n","\n","\n"]},{"cell_type":"markdown","source":["#### 2) VGG16과 연결한 구조 설계\n","* VGG16을 불러와서 Flatten, Dense 등으로 레이어 연결하기"],"metadata":{"id":"D-JjBLZZiIxA"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yg4KhHQ8xXlf"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"5V5heiDxxXlf"},"source":["#### 3) 학습\n","- **세부요구사항**\n","    - 모델 학습 과정에 알맞은 보조 지표를 사용하세요.\n","    - 데이터\n","        * Image Generator를 연결하거나\n","        * 기존 train, validation 셋을 이용해도 됩니다.\n","        - Early Stopping을 반드시 사용하세요.\n","        - 최적의 가중치를 모델에 적용하세요."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CtqQIS-HxXlg"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5zg0L88Gwf4l"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["#### 4) 성능 평가"],"metadata":{"id":"BbhiWcS5i735"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ik4AFzCQi735"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zkkSsyMoi735"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PGuQMUJNxXSy"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}