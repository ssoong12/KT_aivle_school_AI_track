{"cells":[{"cell_type":"markdown","metadata":{"id":"JLojLUpcGNbk"},"source":["# **차량 공유업체의 차량 파손 여부 분류하기**"]},{"cell_type":"markdown","source":["## 0.미션\n","\n","* 1) 미션1 : Data Preprocessing\n","    - **과제 수행 목표**\n","        - 본인의 구글 드라이브에 모델링 수행을 위해 적절한 폴더 및 파일로 **일관성 있게 정리**해야 합니다.\n","        - 제공된 데이터 : Car_Images.zip\n","            * Car_Images : 차량의 정상/파손 이미지 무작위 수집"],"metadata":{"id":"BbrllJY8JdkF"}},{"cell_type":"markdown","source":["* 2) 미션2 : CNN 모델링\n","    - **과제 수행 목표**\n","        - Tensorflow Keras를 이용하여 모델을 3개 이상 생성하세요.\n","            - 모델 구조와 파라미터는 자유롭게 구성하세요.\n","            - 단, 세부 목차에서 명시한 부분은 지켜주세요."],"metadata":{"id":"Hgdg96jE-mmd"}},{"cell_type":"markdown","source":["* 3) 미션3 : Data Argumentation & Transfer Learning\n","    - **과제 수행 목표**\n","        - 성능 개선을 위해 다음의 두가지를 시도하세요.\n","            * Data Augmentation을 적용하세요.(Image Generator)\n","            * Transfer Learning(VGG16)\n"],"metadata":{"id":"VRrUY4ud_rJV"}},{"cell_type":"markdown","metadata":{"id":"7MdjZtxfGNKz"},"source":["## 1.환경설정 "]},{"cell_type":"markdown","metadata":{"id":"6QgFWzN9xhlr"},"source":["### (1) 데이터셋 폴더 생성\n","- **세부요구사항**\n","    - C드라이브에 Datasets라는 폴더를 만드세요.\n","        - 구글드라이브를 사용하는경우 드라이브 첫 화면에 Datasets 라는 폴더를 만드세요. ('/content/drive/MyDrive/Datasets/')\n","    - 해당 폴더 안에 Car_Images.zip 파일을 넣으세요."]},{"cell_type":"markdown","source":["* 구글 Colab을 이용하는 경우"],"metadata":{"id":"Elg8NL8vwUs5"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"kWUbDvBzwiTq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679459796849,"user_tz":-540,"elapsed":20980,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"a82319f3-248f-439e-f0a5-3071f3b64d54"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"0sVNbCKnLUGc"},"source":["### (2) 데이터셋 불러오기 \n","- **세부요구사항**\n","    - Car_Images.zip 파일을 C:/Datasets/ 경로에 압축 해제합니다.\n","    - zipfile 모듈을 이용하거나 다른 방식을 사용해도 됩니다.\n","        - 참고 자료 : [zipfile document](https://docs.python.org/3/library/zipfile.html#zipfile-objects)\n","    - 폴더구조(로컬)\n","        * C:/Datasets/ : 압축파일\n","        * C:/Datasets/Car_Images_train/ : 압축 해제한 이미지 저장소\n","    - 폴더구조(구글드라이브브)\n","        * /content/drive/MyDrive/Datasets/ : 압축파일\n","        * /content/drive/MyDrive/Datasets/Car_Images_train/ : 압축 해제한 이미지 저장소\n","    - 압축을 해제하면 다음과 같은 두 하위 폴더가 생성됩니다.\n","        * normal, abnormal : 각 폴더에는 이미지들이 있습니다.\n","        * 이후 단계에서 해당 경로로 부터 validation, test 셋을 추출하게 됩니다.\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K2-8EaA9x4Xm"},"outputs":[],"source":["import zipfile"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"hMkstFLKx4Xm","executionInfo":{"status":"ok","timestamp":1679459801239,"user_tz":-540,"elapsed":266,"user":{"displayName":"고재훈","userId":"16865552768439394557"}}},"outputs":[],"source":["# 압축파일 경로\n","# 구글 드라이브인 경우 경로에 맞게 지정하세요.\n","dataset_path  = '/content/drive/MyDrive/Datasets/'\n","#dataset_path = 'C:/Datasets/'\n","\n","file_path = dataset_path + 'Car_Images'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sgT_RB14Lwza"},"outputs":[],"source":["# 압축 해제\n"]},{"cell_type":"markdown","metadata":{"id":"8hgC0axQyMhI"},"source":["### (3) 이미지 저장을 위한 폴더 생성\n","- **세부요구사항**\n","    - train, validation, test 을 위해 각각 하위 폴더 normal과 abnormal를 준비합니다.\n","        - train\n","            * 정상 이미지 저장소 : C:/Datasets/Car_Images_train/normal/ \n","                * 구글드라이브 :   /content/drive/MyDrive/Datasets/Car_Images_train/normal/\n","            * 파손 이미지 저장소 : C:/Datasets/Car_Images_train/abnormal/\n","                * 구글드라이브 : /content/drive/MyDrive/Datasets/Car_Images_train/abnormal/\n","        - val, test 역시 동일한 구조로 생성합니다.\n","    - 직접 탐색기에서 폴더를 생성할 수도 있고, os 모듈을 이용하여 코드로 작성할 수도 있습니다.\n","        - 참고 자료 : [os document](https://docs.python.org/3/library/os.html)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rc8GnuauOzLf"},"outputs":[],"source":["\n","# 각각 경로 지정\n","\n","\n","\n","# train 폴더는 압축을 해제하면서 이미 생성 되어 있습니다.\n","\n","# test 폴더 만들기 os.mkdir()\n","\n","\n","\n","# validation 폴더 만들기\n","\n"]},{"cell_type":"markdown","metadata":{"id":"FYZKJrP0GtPh"},"source":["## 2.데이터 전처리"]},{"cell_type":"markdown","metadata":{"id":"j-ilpDQfInAE"},"source":["### (1) 데이터 분할 : Training set | Validation set | Test set 생성\n","- **세부요구사항**\n","    - Training set, Validation set, Test set을 만듭니다.\n","        * size\n","            * test : 전체에서 20%를 추출합니다.\n","            * validation : test를 떼어낸 나머지에서 다시 20%를 추출합니다.\n","        * 데이터는 랜덤하게 추출해야 합니다.\n","            - random, shutil 모듈을 이용하여 랜덤하게 추출할 수 있습니다.\n","                - [random document](https://docs.python.org/3/library/random.html) | [shutil document](https://docs.python.org/3/library/shutil.html)\n","            * 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n","---"]},{"cell_type":"markdown","source":["#### 1) test, validation 크기를 지정"],"metadata":{"id":"mFMSDA26RS-E"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"JhQ_Gu_KNR2g","executionInfo":{"status":"ok","timestamp":1679445969451,"user_tz":-540,"elapsed":450,"user":{"displayName":"고재훈","userId":"16865552768439394557"}}},"outputs":[],"source":["import random, shutil, os\n","import numpy as np"]},{"cell_type":"code","source":[" tr_n_path = '/content/drive/MyDrive/Datasets/Car_Images_train/normal/'\n","tr_ab_path= '/content/drive/MyDrive/Datasets/Car_Images_train/abnormal/'\n","test_n_path = '/content/drive/MyDrive/Datasets/Car_Images_test/normal/'\n","test_ab_path= '/content/drive/MyDrive/Datasets/Car_Images_test/abnormal/'\n","val_n_path = '/content/drive/MyDrive/Datasets/Car_Images_val/normal/'\n","val_ab_path= '/content/drive/MyDrive/Datasets/Car_Images_val/abnormal/'\n","n_path='/content/drive/MyDrive/Datasets/Car_Images/normal'\n","ab_path='/content/drive/MyDrive/Datasets/Car_Images/abnormal'\n","os.listdir(tr_n_path)"],"metadata":{"id":"6V38GTs1rLCA"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PdU7X9e70dBu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679276468350,"user_tz":-540,"elapsed":261,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"34d10b3d-2360-4ed9-fd73-e23d0add309a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(302, 303)"]},"metadata":{},"execution_count":10}],"source":["# 전체 이미지 갯수를 확인합니다.\n","len(os.listdir(tr_n_path)) , len(os.listdir(tr_ab_path))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oa2mxylBDVM5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679277108615,"user_tz":-540,"elapsed":252,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"120114c0-7b9a-4d54-ad57-63bc2dccd196"},"outputs":[{"output_type":"stream","name":"stdout","text":["[60, 61]\n","[48, 48]\n","[194, 194]\n"]}],"source":["# test 사이즈 : 전체 이미지의 20%\n","te_data_num = [round(len(os.listdir(tr_n_path))*0.2), round(len(os.listdir(tr_ab_path))*0.2)]\n","print(te_data_num)\n","\n","# validation 사이즈 : test를 제외한 나머지 중에서 20%\n","val_data_num = [ round((len(os.listdir(tr_n_path))-te_data_num[0])*0.2) , round((len(os.listdir(tr_n_path))-te_data_num[1])*0.2) ]\n","print(val_data_num)\n","\n","# train 사이즈\n","train_data_num = [len(os.listdir(tr_n_path)) - te_data_num[0] - val_data_num[0],\n","                  len(os.listdir(tr_ab_path))- te_data_num[1] - val_data_num[1]]\n","print(train_data_num)"]},{"cell_type":"code","source":["img_n_list = os.listdir(tr_n_path)\n","img_ab_list = os.listdir(tr_ab_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fN9Lp-K-wzfl","executionInfo":{"status":"ok","timestamp":1679278612662,"user_tz":-540,"elapsed":271,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"a18bd31f-e975-4064-ed4d-61182215ec14"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['DALL¡¤E 2023-03-10 22.22.12 - photo of a part of car.png', 'DALL¡¤E 2023-03-10 18.50.29 - photo of a part of car.png', 'DALL¡¤E 2023-03-10 18.52.44 - photo of a part of car.png', 'DALL¡¤E 2023-03-10 18.50.25 - photo of a part of car.png', 'DALL¡¤E 2023-03-10 18.52.35 - photo of a part of car.png', 'DALL¡¤E 2023-03-10 18.50.18 - photo of a part of car.png', 'DALL¡¤E 2023-03-10 22.07.10 - photo of a part of car.png', 'DALL¡¤E 2023-03-10 18.52.40 - photo of a part of car.png', 'DALL¡¤E 2023-03-10 22.07.07 - photo of a part of car.png', 'DALL¡¤E 2023-03-10 18.50.11 - photo of a part of car.png', 'DALL¡¤E 2023-03-10 18.52.17 - photo of a part of car.png', 'DALL¡¤E 2023-03-10 18.52.13 - photo of a part of car.png', 'DALL¡¤E 2023-03-10 23.32.22 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.31.15 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.33.39 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.32.16 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 22.37.34 - photo of a part of car.png', 'DALL¡¤E 2023-03-10 22.23.54 - photo of a part of car.png', 'DALL¡¤E 2023-03-10 23.38.51 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.31.53 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 22.22.46 - photo of a part of car.png', 'DALL¡¤E 2023-03-10 23.38.57 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.38.19 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.31.56 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 22.22.48 - photo of a part of car.png', 'DALL¡¤E 2023-03-10 23.42.04 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.29.21 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.33.16 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.31.06 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.33.14 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.35.37 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.36.45 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.40.52 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.29.18 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 22.22.55 - photo of a part of car.png', 'DALL¡¤E 2023-03-10 23.27.50 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.34.47 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.28.24 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.31.12 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.40.56 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.41.41 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.32.47 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.32.42 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.31.20 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.37.20 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.32.44 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.31.51 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.28.18 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.41.20 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.41.16 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 22.24.15 - photo of a part of car.png', 'DALL¡¤E 2023-03-10 22.23.20 - photo of a part of clean car.png', 'DALL¡¤E 2023-03-10 23.35.40 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.32.14 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 22.24.18 - photo of a part of car.png', 'DALL¡¤E 2023-03-10 22.22.18 - photo of a part of car.png', 'DALL¡¤E 2023-03-10 23.37.25 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.39.17 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.29.56 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.53.24 - a part of car.png', 'DALL¡¤E 2023-03-10 23.51.24 - a part of car without blemish.png', 'DALL¡¤E 2023-03-11 00.04.36 - a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.55.49 - a part of car without blemish.png', 'DALL¡¤E 2023-03-11 00.05.29 - a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.52.28 - a part of car without blemish.png', 'DALL¡¤E 2023-03-11 00.04.07 - a part of car without blemish.png', 'DALL¡¤E 2023-03-11 00.20.04 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.51.48 - a part of car without blemish.png', 'DALL¡¤E 2023-03-11 00.21.18 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.55.54 - a part of car without blemish.png', 'DALL¡¤E 2023-03-11 00.32.47 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-11 00.25.07 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-11 00.04.04 - a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.56.41 - a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.58.50 - a part of car without blemish.png', 'DALL¡¤E 2023-03-11 00.03.18 - a part of car without blemish.png', 'DALL¡¤E 2023-03-11 00.21.24 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-11 00.16.30 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-11 00.18.25 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.51.20 - a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.42.09 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-11 00.20.00 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-11 00.04.11 - a part of car without blemish.png', 'DALL¡¤E 2023-03-11 00.21.21 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-11 00.32.49 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-11 00.32.41 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.55.59 - a part of car without blemish.png', 'DALL¡¤E 2023-03-11 00.18.27 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-11 00.25.03 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-11 00.05.30 - a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.43.03 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-11 00.25.50 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.49.38 - a part of car without blemish.png', 'DALL¡¤E 2023-03-11 00.16.32 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.46.24 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-11 00.18.21 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.46.27 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.43.01 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.59.32 - a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.58.53 - a part of car without blemish.png', 'DALL¡¤E 2023-03-10 23.43.06 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-11 00.25.42 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-11 00.22.47 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-11 00.17.19 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-11 00.57.16 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 01.02.17 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 00.57.59 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 01.01.49 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 00.51.38 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 00.51.44 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 00.39.47 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-11 00.58.44 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 00.38.03 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-11 01.01.47 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 00.39.44 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-11 00.49.10 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-11 01.02.14 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 00.58.02 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 00.38.05 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-11 00.55.42 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 01.01.20 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 00.52.55 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 01.01.22 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 00.57.21 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 00.52.58 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 00.39.49 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-11 01.00.12 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 00.36.19 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-11 01.01.51 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 00.36.22 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-11 00.58.41 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 01.02.38 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 00.36.24 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-11 00.57.18 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 00.51.42 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 00.32.52 - photo of a part of car without blemish.png', 'DALL¡¤E 2023-03-11 01.00.10 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 00.51.40 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 00.55.45 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 01.01.17 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 01.14.39 - a part of a car.png', 'DALL¡¤E 2023-03-11 01.14.42 - a part of a car.png', 'DALL¡¤E 2023-03-11 01.04.47 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 01.15.59 - a part of a car.png', 'DALL¡¤E 2023-03-11 01.07.50 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 01.06.32 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 01.07.48 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 01.14.11 - a part of a car.png', 'DALL¡¤E 2023-03-11 01.12.33 - a part of a car.png', 'DALL¡¤E 2023-03-11 01.04.23 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 01.15.24 - a part of a car.png', 'DALL¡¤E 2023-03-11 01.04.26 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 01.12.37 - a part of a car.png', 'DALL¡¤E 2023-03-11 01.07.42 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 01.06.10 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 01.13.52 - a part of a car.png', 'DALL¡¤E 2023-03-11 01.16.06 - a part of a car.png', 'DALL¡¤E 2023-03-11 01.02.44 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 01.16.03 - a part of a car.png', 'DALL¡¤E 2023-03-11 01.15.18 - a part of a car.png', 'DALL¡¤E 2023-03-11 01.15.21 - a part of a car.png', 'DALL¡¤E 2023-03-11 01.07.52 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 01.03.58 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 01.06.36 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 01.04.49 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 01.16.08 - a part of a car.png', 'DALL¡¤E 2023-03-11 01.02.41 - photo of a part of car.png', 'DALL¡¤E 2023-03-11 01.20.44 - a part of a car.png', 'DALL¡¤E 2023-03-11 01.36.49 - a part of a car.png', 'DALL¡¤E 2023-03-11 14.12.36 - part of a car.png', 'DALL¡¤E 2023-03-11 01.20.48 - a part of a car.png', 'DALL¡¤E 2023-03-11 01.18.02 - a part of a car.png', 'DALL¡¤E 2023-03-11 01.35.30 - photo of a car.png', 'DALL¡¤E 2023-03-11 01.34.21 - photo of a car.png', 'DALL¡¤E 2023-03-11 01.36.08 - photo of a car.png', 'DALL¡¤E 2023-03-11 14.13.06 - part of a car.png', 'DALL¡¤E 2023-03-11 01.36.06 - photo of a car.png', 'DALL¡¤E 2023-03-11 01.16.35 - a part of a car.png', 'DALL¡¤E 2023-03-11 01.18.05 - a part of a car.png', 'DALL¡¤E 2023-03-11 01.16.31 - a part of a car.png', 'DALL¡¤E 2023-03-11 01.36.44 - a part of a car.png', 'DALL¡¤E 2023-03-11 14.12.34 - part of a car.png', 'DALL¡¤E 2023-03-11 01.34.23 - photo of a car.png', 'DALL¡¤E 2023-03-11 01.33.43 - photo of a car.png', 'DALL¡¤E 2023-03-11 01.34.58 - photo of a car.png', 'DALL¡¤E 2023-03-11 01.20.46 - a part of a car.png', 'DALL¡¤E 2023-03-11 01.36.02 - photo of a car.png', 'DALL¡¤E 2023-03-11 01.18.07 - a part of a car.png', 'DALL¡¤E 2023-03-11 01.33.41 - photo of a car.png', 'DALL¡¤E 2023-03-11 01.28.20 - a part of a car.png', 'DALL¡¤E 2023-03-11 01.34.18 - photo of a car.png', 'DALL¡¤E 2023-03-11 01.36.47 - a part of a car.png', 'DALL¡¤E 2023-03-11 01.34.56 - photo of a car.png', 'DALL¡¤E 2023-03-11 14.12.31 - part of a car.png', 'DALL¡¤E 2023-03-11 01.35.01 - photo of a car.png', 'DALL¡¤E 2023-03-11 14.15.06 - part of a car.png', 'DALL¡¤E 2023-03-11 14.13.34 - part of a car.png', 'DALL¡¤E 2023-03-11 14.24.54 - part of a car.png', 'DALL¡¤E 2023-03-11 14.24.04 - part of a car.png', 'DALL¡¤E 2023-03-11 14.13.08 - part of a car.png', 'DALL¡¤E 2023-03-11 14.24.58 - part of a car.png', 'DALL¡¤E 2023-03-11 14.24.16 - part of a car.png', 'DALL¡¤E 2023-03-11 14.23.27 - part of a car.png', 'DALL¡¤E 2023-03-11 14.23.36 - part of a car.png', 'DALL¡¤E 2023-03-11 14.13.37 - part of a car.png', 'DALL¡¤E 2023-03-11 14.23.33 - part of a car.png', 'DALL¡¤E 2023-03-11 14.15.38 - part of a car.png', 'DALL¡¤E 2023-03-11 14.14.14 - part of a car.png', 'DALL¡¤E 2023-03-11 14.22.58 - part of a car.png', 'DALL¡¤E 2023-03-11 14.13.42 - part of a car.png', 'DALL¡¤E 2023-03-11 14.22.54 - part of a car.png', 'DALL¡¤E 2023-03-11 14.22.56 - part of a car.png', 'DALL¡¤E 2023-03-11 14.25.21 - part of a car.png', 'DALL¡¤E 2023-03-11 14.15.04 - part of a car.png', 'DALL¡¤E 2023-03-11 14.15.09 - part of a car.png', 'DALL¡¤E 2023-03-11 14.14.11 - part of a car.png', 'DALL¡¤E 2023-03-11 14.25.24 - part of a car.png', 'DALL¡¤E 2023-03-11 14.18.51 - part of a car.png', 'DALL¡¤E 2023-03-11 14.14.09 - part of a car.png', 'DALL¡¤E 2023-03-11 14.14.06 - part of a car.png', 'DALL¡¤E 2023-03-11 14.16.08 - part of a car.png', 'DALL¡¤E 2023-03-11 14.16.12 - part of a car.png', 'DALL¡¤E 2023-03-11 14.15.43 - part of a car.png', 'DALL¡¤E 2023-03-11 14.23.00 - part of a car.png', 'DALL¡¤E 2023-03-11 14.25.48 - part of a car.png', 'DALL¡¤E 2023-03-11 14.15.40 - part of a car.png', 'DALL¡¤E 2023-03-11 14.18.48 - part of a car.png', 'DALL¡¤E 2023-03-11 14.25.00 - part of a car.png', 'DALL¡¤E 2023-03-11 14.33.26 - part of a car.png', 'DALL¡¤E 2023-03-11 14.30.55 - part of a car.png', 'DALL¡¤E 2023-03-11 14.28.22 - part of a car.png', 'DALL¡¤E 2023-03-11 14.30.53 - part of a car.png', 'DALL¡¤E 2023-03-11 14.35.05 - part of a car.png', 'DALL¡¤E 2023-03-11 14.25.52 - part of a car.png', 'DALL¡¤E 2023-03-11 14.28.25 - part of a car.png', 'DALL¡¤E 2023-03-11 14.32.01 - part of a car.png', 'DALL¡¤E 2023-03-11 14.29.28 - part of a car.png', 'DALL¡¤E 2023-03-11 14.34.11 - part of a car.png', 'DALL¡¤E 2023-03-11 14.27.59 - part of a car.png', 'DALL¡¤E 2023-03-11 14.28.57 - part of a car.png', 'DALL¡¤E 2023-03-11 14.26.19 - part of a car.png', 'DALL¡¤E 2023-03-11 14.34.13 - part of a car.png', 'DALL¡¤E 2023-03-11 14.32.56 - part of a car.png', 'DALL¡¤E 2023-03-11 14.26.52 - part of a car.png', 'DALL¡¤E 2023-03-11 14.31.23 - part of a car.png', 'DALL¡¤E 2023-03-11 14.26.42 - part of a car.png', 'DALL¡¤E 2023-03-11 14.33.23 - part of a car.png', 'DALL¡¤E 2023-03-11 14.31.26 - part of a car.png', 'DALL¡¤E 2023-03-11 14.32.34 - part of a car.png', 'DALL¡¤E 2023-03-11 14.35.09 - part of a car.png', 'DALL¡¤E 2023-03-11 14.33.28 - part of a car.png', 'DALL¡¤E 2023-03-11 14.32.32 - part of a car.png', 'DALL¡¤E 2023-03-11 14.29.47 - part of a car.png', 'DALL¡¤E 2023-03-11 14.34.19 - part of a car.png', 'DALL¡¤E 2023-03-11 14.32.26 - part of a car.png', 'DALL¡¤E 2023-03-11 14.30.01 - part of a car.png', 'DALL¡¤E 2023-03-11 14.26.16 - part of a car.png', 'DALL¡¤E 2023-03-11 14.29.25 - part of a car.png', 'DALL¡¤E 2023-03-11 14.32.58 - part of a car.png', 'DALL¡¤E 2023-03-11 14.28.55 - part of a car.png', 'DALL¡¤E 2023-03-11 14.34.16 - part of a car.png', 'DALL¡¤E 2023-03-11 14.43.32 - photo of part of a car.png', 'DALL¡¤E 2023-03-11 14.39.44 - photo of part of a car.png', 'DALL¡¤E 2023-03-11 14.44.52 - photo of part of a car.png', 'DALL¡¤E 2023-03-11 14.35.46 - part of a car.png', 'DALL¡¤E 2023-03-11 14.42.05 - photo of part of a car.png', 'DALL¡¤E 2023-03-11 14.41.40 - photo of part of a car.png', 'DALL¡¤E 2023-03-11 14.42.56 - photo of part of a car.png', 'DALL¡¤E 2023-03-11 14.37.35 - photo of part of a car.png', 'DALL¡¤E 2023-03-11 14.36.57 - photo of part of a car.png', 'DALL¡¤E 2023-03-11 14.43.02 - photo of part of a car.png', 'DALL¡¤E 2023-03-11 14.40.20 - photo of part of a car.png', 'DALL¡¤E 2023-03-11 14.43.59 - photo of part of a car.png', 'DALL¡¤E 2023-03-11 14.41.37 - photo of part of a car.png', 'DALL¡¤E 2023-03-11 14.41.14 - photo of part of a car.png', 'DALL¡¤E 2023-03-11 14.44.04 - photo of part of a car.png', 'DALL¡¤E 2023-03-11 14.41.18 - photo of part of a car.png', 'DALL¡¤E 2023-03-11 14.39.23 - photo of part of a car.png', 'DALL¡¤E 2023-03-11 14.43.28 - photo of part of a car.png', 'DALL¡¤E 2023-03-11 14.42.03 - photo of part of a car (1).png', 'DALL¡¤E 2023-03-11 14.40.47 - photo of part of a car.png', 'DALL¡¤E 2023-03-11 14.37.15 - photo of part of a car.png', 'DALL¡¤E 2023-03-11 14.35.43 - part of a car.png', 'DALL¡¤E 2023-03-11 14.37.09 - photo of part of a car.png', 'DALL¡¤E 2023-03-11 14.37.37 - photo of part of a car.png', 'DALL¡¤E 2023-03-11 14.40.50 - photo of part of a car.png', 'DALL¡¤E 2023-03-11 14.43.57 - photo of part of a car.png', 'DALL¡¤E 2023-03-11 14.44.02 - photo of part of a car.png', 'DALL¡¤E 2023-03-11 14.40.18 - photo of part of a car.png', 'DALL¡¤E 2023-03-11 14.35.41 - part of a car.png', 'DALL¡¤E 2023-03-11 14.41.11 - photo of part of a car.png', 'DALL¡¤E 2023-03-11 14.35.20 - part of a car.png', 'DALL¡¤E 2023-03-11 14.45.10 - photo of part of a car.png', 'DALL¡¤E 2023-03-11 14.42.03 - photo of part of a car.png', 'DALL¡¤E 2023-03-11 14.37.01 - photo of part of a car.png', 'DALL¡¤E 2023-03-11 14.36.16 - photo of part of a car.png', 'DALL¡¤E 2023-03-11 14.45.14 - photo of part of a car.png', 'DALL¡¤E 2023-03-11 17.08.32 - a part of a car.png', 'DALL¡¤E 2023-03-11 17.08.39 - a part of a car.png', 'DALL¡¤E 2023-03-11 17.09.48 - a part of a car.png', 'DALL¡¤E 2023-03-11 17.09.46 - a part of a car.png', 'DALL¡¤E 2023-03-11 17.08.47 - a part of a car.png']\n"]}]},{"cell_type":"code","source":["random.seed(2023)\n","random.shuffle(img_n_list)\n","random.shuffle(img_ab_list)"],"metadata":{"id":"4U7cRO5pxlbg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 2) test 셋 추출"],"metadata":{"id":"RmRhrViWRXgL"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"TSwovHr2Fon1"},"outputs":[],"source":["test_n_list = img_n_list[:te_data_num[0]]\n","test_ab_list = img_ab_list[:te_data_num[1]]\n","\n","test_list =test_n_list+test_ab_list"]},{"cell_type":"code","source":["print(len(test_n_list))\n","print(len(test_ab_list))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hM23M1MbY12M","executionInfo":{"status":"ok","timestamp":1679288398716,"user_tz":-540,"elapsed":827,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"1e2041af-09a6-4362-e3a7-6e31a91190ad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["60\n","61\n"]}]},{"cell_type":"code","source":["for img_name in test_n_list:\n","    src_path = os.path.join(tr_n_path, img_name)\n","    dst_path = os.path.join(test_n_path, img_name)\n","    shutil.copy(src_path, dst_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":378},"id":"HUQ1H8qe8Ciu","executionInfo":{"status":"error","timestamp":1679288127354,"user_tz":-540,"elapsed":6,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"fc4c9545-9f6b-40b1-8770-df3281a08f00"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-72-7d0bd2710cba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msrc_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_n_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdst_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_n_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/lib/python3.9/shutil.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m     \u001b[0mcopymode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.9/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Datasets/Car_Images_train/normal/DALL¡¤E 2023-03-10 22.22.12 - photo of a part of car.png'"]}]},{"cell_type":"code","source":["for img_name in test_ab_list:\n","    src_path = os.path.join(tr_ab_path, img_name)\n","    dst_path = os.path.join(test_ab_path, img_name)\n","    shutil.copy(src_path, dst_path)"],"metadata":{"id":"YHaDxIpZ-HRA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(test_list))"],"metadata":{"id":"c00302hJyB9v"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AImO1ujiI2IY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679288411946,"user_tz":-540,"elapsed":415,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"6ca30051-36f7-4f2a-9fa5-ba2a5fb4ae80"},"outputs":[{"output_type":"stream","name":"stdout","text":["48\n","48\n"]}],"source":["# 추출 후 이미지 갯수 확인\n","print(len(val_n_list))\n","print(len(val_ab_list))"]},{"cell_type":"markdown","source":["#### 3) validation 셋 추출"],"metadata":{"id":"2V4mh3hxRpR2"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"zXYmEdCjAEDu"},"outputs":[],"source":["val_n_list = img_n_list[te_data_num[0]:val_data_num[0]+te_data_num[0]]\n","val_ab_list = img_ab_list[te_data_num[1]:val_data_num[1]+te_data_num[1]]\n","val_list=val_n_list+val_ab_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yIT85iSdM4U-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679288364675,"user_tz":-540,"elapsed":243,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"e8151fcc-5fae-4081-aae1-9b615df34fd3"},"outputs":[{"output_type":"stream","name":"stdout","text":["48\n","48\n"]}],"source":["# 추출 후 이미지 갯수 확인\n","# print(val_n_list)\n","print(len(val_n_list))\n","print(len(val_ab_list))"]},{"cell_type":"code","source":["train_n_list = img_n_list[val_data_num[0]+te_data_num[0]:]\n","train_ab_list = img_ab_list[val_data_num[1]+te_data_num[1]:]\n","train_list=train_n_list+train_ab_list"],"metadata":{"id":"0CQytYIc3-xy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(train_n_list))\n","print(len(train_ab_list))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KczSj9GnXdVy","executionInfo":{"status":"ok","timestamp":1679288478476,"user_tz":-540,"elapsed":556,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"34db21f8-40b2-478d-92f2-ceac69d08fe7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["194\n","194\n"]}]},{"cell_type":"code","source":["for img_name in val_n_list:\n","    src_path = os.path.join(tr_n_path, img_name)\n","    dst_path = os.path.join(val_n_path, img_name)\n","    shutil.copy(src_path, dst_path)"],"metadata":{"id":"IrEYPT1n-bd-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for img_name in val_ab_list:\n","    src_path = os.path.join(tr_ab_path, img_name)\n","    dst_path = os.path.join(val_ab_path, img_name)\n","    shutil.copy(src_path, dst_path)"],"metadata":{"id":"DYvnQv0e-fjn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(train_list)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f1za5NWD3_CB","executionInfo":{"status":"ok","timestamp":1679279912510,"user_tz":-540,"elapsed":264,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"4f446422-5352-4519-a4ab-8e4fb8cb762c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["387"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["for img_name in train_n_list:\n","    src_path = os.path.join(n_path, img_name)\n","    dst_path = os.path.join(tr_n_path, img_name)\n","    shutil.copy(src_path, dst_path)\n"],"metadata":{"id":"Rv1ConPJT1GQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for img_name in train_ab_list:\n","    src_path = os.path.join(ab_path, img_name)\n","    dst_path = os.path.join(tr_ab_path, img_name)\n","    shutil.copy(src_path, dst_path)"],"metadata":{"id":"OQmLecFoWV_6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","print(len(os.listdir(tr_n_path)))\n","print(len(os.listdir(tr_ab_path)))\n","print(len(os.listdir(test_n_path)))\n","print(len(os.listdir(test_ab_path)))\n","print(len(os.listdir(val_n_path)))\n","print(len(os.listdir(val_ab_path)))\n","print(len(os.listdir(n_path)))\n","print(len(os.listdir(ab_path)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LGydOjuhZjYo","executionInfo":{"status":"ok","timestamp":1679288696553,"user_tz":-540,"elapsed":263,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"e4ecd040-a131-4244-a969-dc7d3d33a286"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["194\n","194\n","60\n","61\n","48\n","48\n","302\n","303\n"]}]},{"cell_type":"markdown","metadata":{"id":"haSO004sgyyu"},"source":["### (2) 데이터 복사 및 이동\n","- **세부요구사항**\n","    - 분할된 데이터를 복사 이동합니다.\n","        - 새로운 폴더에 저장하는 데이터로 \"3.모델링I\"에서 사용합니다.\n","        - 기존 폴더는 \"4.모델링II > (1) Data Augmentation\"에서 사용합니다.\n","    - Training set | Validation set | Test set의 데이터를 **새로운 폴더**에 복사하세요.\n","        - 새로운 폴더 명\n","            * copy_images/trainset\n","            * copy_images/validset\n","            * copy_images/testset\n","        - 새로운 폴더에는 normal, abnormal 파일 모두를 복사합니다. \n","            * 파일을 구분하기 위해 abnormal 파일들은 파일명 앞에 접두사 'ab_'를 붙입시다.\n","        - os, shutil 모듈을 활용하세요."]},{"cell_type":"markdown","source":["#### 1) abnormal 파일 복사"],"metadata":{"id":"3UbNfTY4kOSZ"}},{"cell_type":"markdown","source":["#### 2) normal 파일 복사"],"metadata":{"id":"Nk6xITmTksyK"}},{"cell_type":"markdown","source":["* 복사하기 : shutil.copytree()"],"metadata":{"id":"zhkKqLfTkjGI"}},{"cell_type":"code","source":["copy_test_path='/content/drive/MyDrive/Datasets/copy_images/testset'\n","copy_train_path='/content/drive/MyDrive/Datasets/copy_images/trainset'\n","copy_val_path='/content/drive/MyDrive/Datasets/copy_images/validset'"],"metadata":{"id":"9gj5CCDDaNE8"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aTMVxJJJya98"},"outputs":[],"source":["data=[tr_n_path, tr_ab_path, test_n_path, test_ab_path, val_n_path, val_ab_path]\n","for i in range(6):\n","    for img_name in os.listdir(data[i]):\n","        src_path = os.path.join(data[i], img_name)\n","        if i == 0 or i== 1:\n","            dst_path = os.path.join(copy_train_path, img_name)\n","        elif i== 2 or i==3:\n","            dst_path = os.path.join(copy_test_path, img_name)\n","        else:\n","            dst_path = os.path.join(copy_val_path, img_name)\n","\n","        shutil.copy(src_path, dst_path)"]},{"cell_type":"markdown","source":["* abnormal 이미지 이름의 접두어 \"ab_\" 붙이기 : os.rename"],"metadata":{"id":"mU0T-ypHkV6D"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vw3DmdTS17RM"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["* 데이터 갯수 조회"],"metadata":{"id":"xzEXHZrqkz88"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ugNprP9d-Gti","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679360348748,"user_tz":-540,"elapsed":2235,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"220dd518-85e4-4a48-b4a6-eead40a18510"},"outputs":[{"output_type":"stream","name":"stdout","text":["388\n","96\n","121\n"]}],"source":["print(len(os.listdir(dataset_path+'copy_images/trainset/')))\n","print(len(os.listdir(dataset_path+'copy_images/validset/')))\n","print(len(os.listdir(dataset_path+'copy_images/testset/')))"]},{"cell_type":"markdown","metadata":{"id":"VfYDW1Pj7ZdU"},"source":["## 3.모델링 I\n","* **세부요구사항**\n","    * 모델링을 위한 데이터 구조 만들기\n","        * x : 이미지를 array로 변환합니다.\n","        * y : 이미지 갯수만큼 normal - 0, abnormal - 1 로 array를 만듭니다.\n","    * 모델을 최소 3개 이상 만들고 성능을 비교합니다.\n","        * 모델 학습 과정에 알맞은 보조 지표를 사용하세요.\n","        * 전처리 과정에서 생성한 Validation set을 적절하게 사용하세요.\n","        * Early Stopping을 반드시 사용하세요.\n","            * 최적의 가중치를 모델에 적용하세요."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"Rg553KIvxE6W","executionInfo":{"status":"ok","timestamp":1679459861212,"user_tz":-540,"elapsed":908,"user":{"displayName":"고재훈","userId":"16865552768439394557"}}},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.callbacks import EarlyStopping\n","from sklearn.metrics import classification_report, confusion_matrix"]},{"cell_type":"code","source":["import random, shutil, os\n","import numpy as np"],"metadata":{"id":"gF_nBn0VqMn7","executionInfo":{"status":"ok","timestamp":1679459861631,"user_tz":-540,"elapsed":421,"user":{"displayName":"고재훈","userId":"16865552768439394557"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wIfqg6e0xE6A"},"source":["### (1) X : image to array\n","- **세부요구사항**\n","    * 모델링을 위해서는 np.array 형태로 데이터셋을 만들어야 합니다.\n","    * Training set / Validation set / Test set의 X는 이미지 형태로 되어있습니다. \n","    * 이미지 파일을 불러와 train, valid, test 각각 array 형태로 변환해 봅시다.\n","        * 각 폴더로 부터 이미지 목록을 만들고\n","        * 이미지 한장씩 적절한 크기로 로딩하여 (keras.utils.load_img)\n","            * 이미지가 너무 크면 학습시간이 많이 걸리고, 메모리 부족현상이 발생될 수 있습니다.\n","            * 이미지 크기를 280 * 280 * 3 이내의 크기를 설정하여 로딩하시오.\n","            * array로 변환 (keras.utils.img_to_array, np.expand_dims)\n","        * 데이터셋에 추가합니다.(데이터셋도 array)"]},{"cell_type":"markdown","source":["#### 1) 이미지 목록 만들기\n","* train, validation, test 폴더로 부터 이미지 목록을 생성합니다."],"metadata":{"id":"FovkIeSDT367"}},{"cell_type":"code","source":["import os"],"metadata":{"id":"g9CLs2UbqA6k","executionInfo":{"status":"ok","timestamp":1679459824020,"user_tz":-540,"elapsed":377,"user":{"displayName":"고재훈","userId":"16865552768439394557"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","execution_count":8,"metadata":{"id":"X022f0QMxE6W","executionInfo":{"status":"ok","timestamp":1679459825859,"user_tz":-540,"elapsed":1498,"user":{"displayName":"고재훈","userId":"16865552768439394557"}}},"outputs":[],"source":["# 이미지 목록 저장\n","img_train_list = os.listdir(dataset_path+'copy_images/trainset/')\n","img_valid_list = os.listdir(dataset_path+'copy_images/validset/')\n","img_test_list = os.listdir(dataset_path+'copy_images/testset/')"]},{"cell_type":"code","source":[],"metadata":{"id":"o0eKzsrmxka4","executionInfo":{"status":"ok","timestamp":1679459825859,"user_tz":-540,"elapsed":4,"user":{"displayName":"고재훈","userId":"16865552768439394557"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"5xI3Ejzkxj6Z"}},{"cell_type":"code","execution_count":9,"metadata":{"id":"rgvW_LQfxE6X","executionInfo":{"status":"ok","timestamp":1679459825860,"user_tz":-540,"elapsed":4,"user":{"displayName":"고재훈","userId":"16865552768439394557"}}},"outputs":[],"source":["# 메모리, 처리시간을 위해서 이미지 크기 조정\n","img_size = 280 ## 사이즈 조정 가능"]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import load_img\n","from tensorflow.keras.preprocessing.image import img_to_array"],"metadata":{"id":"d1ubg6Kxv-8y","executionInfo":{"status":"ok","timestamp":1679459825860,"user_tz":-540,"elapsed":4,"user":{"displayName":"고재훈","userId":"16865552768439394557"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"yYa7X4nHmwsS"}},{"cell_type":"markdown","source":["#### 2) 이미지들을 배열 데이터셋으로 만들기"],"metadata":{"id":"LSt88mjPV33u"}},{"cell_type":"code","execution_count":96,"metadata":{"id":"rhEdBiKfxE6Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679467740664,"user_tz":-540,"elapsed":21378,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"d81883b4-74a9-492f-c2a2-ad067733127b"},"outputs":[{"output_type":"stream","name":"stdout","text":["(388, 280, 280, 3)\n"]}],"source":["images = []\n","labels = []\n","\n","for path in img_train_list:\n","    img = load_img(dataset_path+'copy_images/trainset/'+path)\n","    img = img.resize((280,280))\n","    img = img_to_array(img)\n","    \n","    images.append(img)\n","\n","x_train = np.array(images)\n","\n","print(x_train.shape)"]},{"cell_type":"code","source":["images = []\n","labels = []\n","\n","for path in img_test_list:\n","    img = load_img(dataset_path+'copy_images/testset/'+path)\n","    img = img.resize((280,280))\n","    img = img_to_array(img)\n","    \n","    images.append(img)\n","\n","x_test = np.array(images)\n","\n","print(x_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zQ7kOvzhyXDb","executionInfo":{"status":"ok","timestamp":1679467747321,"user_tz":-540,"elapsed":6673,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"0fadb8be-bc6b-45ad-d215-bcf7b23b633d"},"execution_count":97,"outputs":[{"output_type":"stream","name":"stdout","text":["(121, 280, 280, 3)\n"]}]},{"cell_type":"code","source":["images = []\n","labels = []\n","\n","for path in img_valid_list:\n","    img = load_img(dataset_path+'copy_images/validset/'+path)\n","    img = img.resize((280,280))\n","    img = img_to_array(img)\n","    \n","    images.append(img)\n","\n","x_val = np.array(images)\n","\n","print(x_val.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F-ufge0Jyisa","executionInfo":{"status":"ok","timestamp":1679467751889,"user_tz":-540,"elapsed":4589,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"9ca4817f-a517-4e9f-b48d-354ac9ea4a04"},"execution_count":98,"outputs":[{"output_type":"stream","name":"stdout","text":["(96, 280, 280, 3)\n"]}]},{"cell_type":"markdown","metadata":{"id":"doUM37LxxE6Z"},"source":["### (2) y : 클래스 만들기\n","- **세부요구사항**\n","    - Training set / Validation set / Test set의 y를 생성합니다.\n","        - 각각 normal, abnormal 데이터의 갯수를 다시 확인하고\n","        - normal을 0, abnormal을 1로 지정합니다."]},{"cell_type":"code","execution_count":17,"metadata":{"id":"8nl1Uv9UxE6b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679459936314,"user_tz":-540,"elapsed":13,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"ed641ae5-5096-4044-ab8b-677917266f5d"},"outputs":[{"output_type":"stream","name":"stdout","text":["388\n","194\n","---\n","96\n","48\n","---\n","121\n","61\n"]}],"source":["# 데이터 갯수 확인\n","print( len(img_train_list) )\n","print( len([val for val in img_train_list if val.startswith('ab_')]) )\n","print('---')\n","print( len(img_valid_list) )\n","print( len([val for val in img_valid_list if val.startswith('ab_')]) )\n","print('---')\n","print( len(img_test_list) )\n","print( len([val for val in img_test_list if val.startswith('ab_')]) )"]},{"cell_type":"markdown","source":["* y_train, y_valid, y_test 만들기\n","    * normal, abnormal 데이터의 갯수를 다시 확인하고 normal을 0, abnormal을 1로 지정합니다."],"metadata":{"id":"HIfaCLlNn04C"}},{"cell_type":"code","execution_count":18,"metadata":{"id":"YVrPQdhTxE6b","executionInfo":{"status":"ok","timestamp":1679459936315,"user_tz":-540,"elapsed":12,"user":{"displayName":"고재훈","userId":"16865552768439394557"}}},"outputs":[],"source":["y_train=[]\n","for i in img_train_list :\n","    if i.startswith('ab_'):\n","        y_train.append(1)\n","    else:\n","        y_train.append(0)\n","\n","y_train=np.array(y_train)"]},{"cell_type":"code","source":["y_val=[]\n","for i in img_valid_list :\n","    if i.startswith('ab_'):\n","        y_val.append(1)\n","    else:\n","        y_val.append(0)\n","\n","y_val=np.array(y_val)"],"metadata":{"id":"TDt9jqfJ04GS","executionInfo":{"status":"ok","timestamp":1679459936315,"user_tz":-540,"elapsed":12,"user":{"displayName":"고재훈","userId":"16865552768439394557"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["y_test=[]\n","for i in img_test_list :\n","    if i.startswith('ab_'):\n","        y_test.append(1)\n","    else:\n","        y_test.append(0)\n","\n","y_test=np.array(y_test)"],"metadata":{"id":"VPEbpA8204NP","executionInfo":{"status":"ok","timestamp":1679459936315,"user_tz":-540,"elapsed":11,"user":{"displayName":"고재훈","userId":"16865552768439394557"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["print(y_train.shape, y_test.shape, y_val.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UWKATp7huBfa","executionInfo":{"status":"ok","timestamp":1679459936316,"user_tz":-540,"elapsed":12,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"d75f2620-dc4a-4d0e-869f-ed5b88c9022b"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["(388,) (121,) (96,)\n"]}]},{"cell_type":"markdown","metadata":{"id":"Z586wXFu7ZgT"},"source":["### (3) 모델1\n","- **세부요구사항**\n","    - Conv2D, MaxPooling2D, Flatten, Dense 레이어들을 이용하여 모델을 설계\n","    - 학습시 validation_data로 validation set을 사용하시오.\n","    - 반드시 Early Stopping 적용\n","    - 평가시, confusion matrix, accuracy, recall, precision, f1 score 등을 이용하시오."]},{"cell_type":"markdown","source":["min-max scaling"],"metadata":{"id":"58eyUhmaDjkm"}},{"cell_type":"code","source":["min_n, max_n = x_train.min(), x_train.max()\n","x_train = (x_train - min_n) / (max_n - min_n)\n","x_test = (x_test - min_n) / (max_n - min_n)\n","x_val = (x_val - min_n) / (max_n - min_n)"],"metadata":{"id":"JvhItU98Djrm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["to_categorical"],"metadata":{"id":"xIOGREtVDj2G"}},{"cell_type":"code","source":["class_n = len(np.unique(y_train))"],"metadata":{"id":"Zr1BlgyiDj7P","executionInfo":{"status":"ok","timestamp":1679459936316,"user_tz":-540,"elapsed":6,"user":{"displayName":"고재훈","userId":"16865552768439394557"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.utils import to_categorical\n","y_train = to_categorical(y_train, class_n)\n","y_test = to_categorical(y_test, class_n)\n","y_val = to_categorical(y_val, class_n)"],"metadata":{"id":"S3UCoMiCDj-F","executionInfo":{"status":"ok","timestamp":1679459936317,"user_tz":-540,"elapsed":7,"user":{"displayName":"고재훈","userId":"16865552768439394557"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["스탠다드\n"],"metadata":{"id":"r1LV-yeaDkAa"}},{"cell_type":"code","source":[],"metadata":{"id":"ORUiu8o00qsf","executionInfo":{"status":"aborted","timestamp":1679459851164,"user_tz":-540,"elapsed":10,"user":{"displayName":"고재훈","userId":"16865552768439394557"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mean_n = x_train.mean()\n","std_n = x_train.std()\n","\n","x_train = (x_train - mean_n) / std_n\n","x_test = (x_test - mean_n) / std_n\n","x_val = (x_val - mean_n) / std_n"],"metadata":{"id":"3TQknnJeDkCr","executionInfo":{"status":"ok","timestamp":1679468158257,"user_tz":-540,"elapsed":1426,"user":{"displayName":"고재훈","userId":"16865552768439394557"}}},"execution_count":103,"outputs":[]},{"cell_type":"code","source":["x_test .mean(), x_test.std()"],"metadata":{"id":"LSQWgbndDkE_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679459936751,"user_tz":-540,"elapsed":4,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"342e6ef5-1f51-41dc-f71f-ae59a310acf5"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.08334001, 1.0730253)"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":[],"metadata":{"id":"HzoI4yfVDkHI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9AOCiFQnDkJA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"y6CzoUGbDkL7"}},{"cell_type":"markdown","source":["#### 1) 구조 설계"],"metadata":{"id":"NIvIO6RKa0mp"}},{"cell_type":"code","execution_count":38,"metadata":{"id":"7TtIIz6XJQ5E","executionInfo":{"status":"ok","timestamp":1679460485479,"user_tz":-540,"elapsed":627,"user":{"displayName":"고재훈","userId":"16865552768439394557"}}},"outputs":[],"source":["from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.layers import Dense, Input, Flatten, BatchNormalization, Dropout, Conv2D, AvgPool2D\n","from tensorflow.keras.models import Model"]},{"cell_type":"markdown","source":["#### 2) 학습\n","* EarlyStopping 설정하고 학습시키기"],"metadata":{"id":"DHM91_bha3Kc"}},{"cell_type":"code","execution_count":26,"metadata":{"id":"BnrTSupKa42f","executionInfo":{"status":"ok","timestamp":1679459971099,"user_tz":-540,"elapsed":339,"user":{"displayName":"고재훈","userId":"16865552768439394557"}}},"outputs":[],"source":["from tensorflow.keras.callbacks import EarlyStopping"]},{"cell_type":"code","source":["es = EarlyStopping(monitor = 'val_loss',\n","                   min_delta = 0,\n","                   patience = 15,\n","                   verbose = 1)"],"metadata":{"id":"JdvCnJTvE_Y7","executionInfo":{"status":"ok","timestamp":1679459971955,"user_tz":-540,"elapsed":4,"user":{"displayName":"고재훈","userId":"16865552768439394557"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["x_train.shape, y_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"70telyEbE_fo","executionInfo":{"status":"ok","timestamp":1679459971956,"user_tz":-540,"elapsed":4,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"cc38ca60-c5d4-4b62-a618-7780baa6142a"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((388, 280, 280, 3), (388, 2))"]},"metadata":{},"execution_count":28}]},{"cell_type":"markdown","source":["#### 3) test set으로 예측하고 평가하기\n","* 평가는 confusion_matrix, classification_report 활용"],"metadata":{"id":"zage6-Z0a6DX"}},{"cell_type":"markdown","source":["# 데이터를 넣어서 학습시키자!\n","history = model.fit(x_train, y_train,\n","                    epochs = 10000, verbose = 1,\n","                    callbacks = [es], validation_data =(x_val,y_val))"],"metadata":{"id":"4xkFFlFdbBZb"}},{"cell_type":"code","source":["######################\n","#########주현#########\n","######################\n","import tensorflow as tf\n","\n","model_path='/content/drive/MyDrive/Datasets/first_model.h5'\n","# 모델 파일 불러오기\n","model = tf.keras.models.load_model(model_path)\n","\n","model.summary()"],"metadata":{"id":"gY2NVaGe722J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679450592387,"user_tz":-540,"elapsed":4595,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"b718fc55-355f-414e-ab27-98d98292e9ec"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 278, 278, 16)      448       \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 276, 276, 16)      2320      \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 274, 274, 16)      2320      \n","                                                                 \n"," batch_normalization (BatchN  (None, 274, 274, 16)     64        \n"," ormalization)                                                   \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 137, 137, 16)     0         \n"," )                                                               \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 135, 135, 32)      4640      \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 133, 133, 32)      9248      \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 131, 131, 32)      9248      \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 131, 131, 32)     128       \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 65, 65, 32)       0         \n"," 2D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 135200)            0         \n","                                                                 \n"," dense (Dense)               (None, 512)               69222912  \n","                                                                 \n"," dense_1 (Dense)             (None, 1024)              525312    \n","                                                                 \n"," dropout (Dropout)           (None, 1024)              0         \n","                                                                 \n"," dense_2 (Dense)             (None, 2)                 2050      \n","                                                                 \n","=================================================================\n","Total params: 69,778,690\n","Trainable params: 69,778,594\n","Non-trainable params: 96\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, classification_report\n","y_pred = model.predict(x_test)\n","y_pred.shape\n","single_y_pred = y_pred.argmax(axis=1)\n","single_y_pred.shape\n","print(y_test.shape)\n","single_test_y = y_test.argmax(axis=1)\n","print(single_test_y.shape)\n","print(confusion_matrix(single_test_y, single_y_pred))\n","print(classification_report(single_test_y, single_y_pred))"],"metadata":{"id":"Y0q_Y1rkDblV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4y9O88CzDbpY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jQzdvxowDbsm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"D33-RewDDbu1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vgneqgs8Dbxy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Lu_gNnTqDbzv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3LckirOi96lM","executionInfo":{"status":"ok","timestamp":1679382007870,"user_tz":-540,"elapsed":496,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"bbe4a231-081b-45d0-b7e8-212d560ead10"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 278, 278, 16)      448       \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 276, 276, 16)      2320      \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 274, 274, 16)      2320      \n","                                                                 \n"," batch_normalization (BatchN  (None, 274, 274, 16)     64        \n"," ormalization)                                                   \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 137, 137, 16)     0         \n"," )                                                               \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 135, 135, 32)      4640      \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 133, 133, 32)      9248      \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 131, 131, 32)      9248      \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 131, 131, 32)     128       \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 65, 65, 32)       0         \n"," 2D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 135200)            0         \n","                                                                 \n"," dense (Dense)               (None, 512)               69222912  \n","                                                                 \n"," dense_1 (Dense)             (None, 1024)              525312    \n","                                                                 \n"," dropout (Dropout)           (None, 1024)              0         \n","                                                                 \n"," dense_2 (Dense)             (None, 2)                 2050      \n","                                                                 \n","=================================================================\n","Total params: 69,778,690\n","Trainable params: 69,778,594\n","Non-trainable params: 96\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h0r3eJoyzJOd","executionInfo":{"status":"ok","timestamp":1679379209599,"user_tz":-540,"elapsed":642,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"2717719d-1116-4b10-8b0f-aa228d3e8cce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 278, 278, 16)      448       \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 276, 276, 16)      2320      \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 274, 274, 16)      2320      \n","                                                                 \n"," batch_normalization (BatchN  (None, 274, 274, 16)     64        \n"," ormalization)                                                   \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 137, 137, 16)     0         \n"," )                                                               \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 135, 135, 32)      4640      \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 133, 133, 32)      9248      \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 131, 131, 32)      9248      \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 131, 131, 32)     128       \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 65, 65, 32)       0         \n"," 2D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 135200)            0         \n","                                                                 \n"," dense (Dense)               (None, 512)               69222912  \n","                                                                 \n"," dense_1 (Dense)             (None, 1024)              525312    \n","                                                                 \n"," dropout (Dropout)           (None, 1024)              0         \n","                                                                 \n"," dense_2 (Dense)             (None, 2)                 2050      \n","                                                                 \n","=================================================================\n","Total params: 69,778,690\n","Trainable params: 69,778,594\n","Non-trainable params: 96\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["######################\n","#########세연#########\n","######################\n","import tensorflow as tf\n","\n","model_path='/content/drive/MyDrive/Datasets/Lenet(0.87).h5'\n","# 모델 파일 불러오기\n","model = tf.keras.models.load_model(model_path)\n","\n","from sklearn.metrics import confusion_matrix, classification_report\n","y_pred = model.predict(x_test)``\n","y_pred.shape\n","single_y_pred = y_pred.argmax(axis=1)\n","single_y_pred.shape\n","print(y_test.shape)\n","single_test_y = y_test.argmax(axis=1)\n","print(single_test_y.shape)\n","print(confusion_matrix(single_test_y, single_y_pred))\n","print(classification_report(single_test_y, single_y_pred))"],"metadata":{"id":"NgifnhNp727q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679460107811,"user_tz":-540,"elapsed":4414,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"225725a0-5efb-4ebc-ffaa-18b0f2527d97"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 0s 21ms/step\n","(121, 2)\n","(121,)\n","[[58  2]\n"," [10 51]]\n","              precision    recall  f1-score   support\n","\n","           0       0.85      0.97      0.91        60\n","           1       0.96      0.84      0.89        61\n","\n","    accuracy                           0.90       121\n","   macro avg       0.91      0.90      0.90       121\n","weighted avg       0.91      0.90      0.90       121\n","\n"]}]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HRmLBxpzvp74","executionInfo":{"status":"ok","timestamp":1679462154088,"user_tz":-540,"elapsed":840,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"71b6566f-e111-42f2-93fa-5284d8fe25b8"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 280, 280, 3)]     0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 280, 280, 6)       456       \n","                                                                 \n"," average_pooling2d (AverageP  (None, 140, 140, 6)      0         \n"," ooling2D)                                                       \n","                                                                 \n"," batch_normalization (BatchN  (None, 140, 140, 6)      24        \n"," ormalization)                                                   \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 136, 136, 16)      2416      \n","                                                                 \n"," average_pooling2d_1 (Averag  (None, 68, 68, 16)       0         \n"," ePooling2D)                                                     \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 68, 68, 16)       64        \n"," hNormalization)                                                 \n","                                                                 \n"," flatten (Flatten)           (None, 73984)             0         \n","                                                                 \n"," dense (Dense)               (None, 120)               8878200   \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 120)              480       \n"," hNormalization)                                                 \n","                                                                 \n"," dense_1 (Dense)             (None, 84)                10164     \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 84)               336       \n"," hNormalization)                                                 \n","                                                                 \n"," dropout (Dropout)           (None, 84)                0         \n","                                                                 \n"," dense_2 (Dense)             (None, 2)                 170       \n","                                                                 \n","=================================================================\n","Total params: 8,892,310\n","Trainable params: 8,891,858\n","Non-trainable params: 452\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"wLSv7cnD7293"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9-EQFVkCbBZc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679376492312,"user_tz":-540,"elapsed":19273,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"f0d77341-58c3-4898-fba7-492977dacb33"},"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 0s 77ms/step\n","(121, 2)\n","(121,)\n","[[52  8]\n"," [38 23]]\n","              precision    recall  f1-score   support\n","\n","           0       0.58      0.87      0.69        60\n","           1       0.74      0.38      0.50        61\n","\n","    accuracy                           0.62       121\n","   macro avg       0.66      0.62      0.60       121\n","weighted avg       0.66      0.62      0.60       121\n","\n"]}],"source":["from sklearn.metrics import confusion_matrix, classification_report\n","y_pred = model.predict(x_test)\n","y_pred.shape\n","single_y_pred = y_pred.argmax(axis=1)\n","single_y_pred.shape\n","print(y_test.shape)\n","single_test_y = y_test.argmax(axis=1)\n","print(single_test_y.shape)\n","print(confusion_matrix(single_test_y, single_y_pred))\n","print(classification_report(single_test_y, single_y_pred))"]},{"cell_type":"markdown","metadata":{"id":"qRoacK2mcLPb"},"source":["### (4) 모델2\n","- **세부요구사항**\n","    - Conv2D, MaxPooling2D, Flatten, Dense 레이어들을 이용하여 모델을 설계\n","    - 학습시 validation_data로 validation set을 사용하시오.\n","    - 반드시 Early Stopping 적용\n","    - 평가시, confusion matrix, accuracy, recall, precision, f1 score 등을 이용하시오."]},{"cell_type":"markdown","source":["#### 1) 구조 설계"],"metadata":{"id":"5WTwG8NFoLBQ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"UHu5gey1oLBR"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["#### 2) 학습\n","* EarlyStopping 설정하고 학습시키기"],"metadata":{"id":"DqTzgRTroLBR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"lcVDXnpQoLBR"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UAhXnGmXoLBS"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["#### 3) test set으로 예측하고 평가하기\n","* 평가는 confusion_matrix, classification_report 활용"],"metadata":{"id":"qxZ0U7K1oLBS"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ShruikbsoLBS"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v8MC8l07oLBS"},"outputs":[],"source":[]},{"cell_type":"code","source":[],"metadata":{"id":"G7FVsFiCFSGa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MRqzBw8eccwj"},"source":["### (5) 모델3\n","- **세부요구사항**\n","    - Conv2D, MaxPooling2D, Flatten, Dense 레이어들을 이용하여 모델을 설계\n","    - 학습시 validation_data로 validation set을 사용하시오.\n","    - 반드시 Early Stopping 적용\n","    - 평가시, confusion matrix, accuracy, recall, precision, f1 score 등을 이용하시오."]},{"cell_type":"markdown","source":["#### 1) 구조 설계"],"metadata":{"id":"LtNd8u5RoNJo"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"KM-Npn6WoNJo"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["#### 2) 학습\n","* EarlyStopping 설정하고 학습시키기"],"metadata":{"id":"4zgVkXLHoNJo"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"gTlUNbkhoNJo"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T4GYo0dboNJo"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["#### 3) test set으로 예측하고 평가하기\n","* 평가는 confusion_matrix, classification_report 활용"],"metadata":{"id":"uZV9zbsroNJo"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sc9UmjZ0oNJo"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aP-p0_y9oNJo"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"AxUpfhJ1xXle"},"source":["## 4.모델링 II\n","* **세부요구사항**\n","    - 성능을 높이기 위해서 다음의 두가지를 시도해 봅시다.\n","        - Data Augmentation을 통해 데이터를 증가 시킵니다.\n","            - ImageDataGenerator를 사용합니다.\n","        - 사전 학습된 모델(Transfer Learning)을 가져다 사용해 봅시다.\n","            - VGG16(이미지넷)을 사용해 봅시다."]},{"cell_type":"markdown","metadata":{"id":"ouCRBdKPxCut"},"source":["### (1) Data Augmentation\n","- **세부요구사항**\n","    * 모델 학습에 이용할 이미지 데이터를 증강시키세요.\n","    * Keras의 ImageDataGenerator를 이용\n","        - [ImageDataGenerator document](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator)\n","\n","    * image generator를 이용하여 학습\n","        * 모델 구조는 이미 생성한 1,2,3 중 하나를 선택하여 학습\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"qe6yjs8F7Zox","executionInfo":{"status":"ok","timestamp":1679447913608,"user_tz":-540,"elapsed":2857,"user":{"displayName":"고재훈","userId":"16865552768439394557"}}},"outputs":[],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"wYae9YFt8Q03","executionInfo":{"status":"ok","timestamp":1679447969191,"user_tz":-540,"elapsed":1217,"user":{"displayName":"고재훈","userId":"16865552768439394557"}}},"outputs":[],"source":["img_size = 280 ## 사이즈 조정 가능\n","\n","train_path = dataset_path+'Car_Images_train/'\n","valid_path = dataset_path+'Car_Images_val/'"]},{"cell_type":"markdown","source":["#### 1) ImageGenerator 생성\n","* ImageDataGenerator 함수 사용\n","    * 주요 옵션\n","        * rotation_range: 무작위 회전을 적용할 각도 범위\n","        * zoom_range: 무작위 줌을 적용할 범위 [1-zoom_range, 1+zoom_range]\n","        * horizontal_flip: 무작위 좌우반전을 적용할지 여부\n","        * vertical_flip: 무작위 상하반전을 적용할지 여부\n","        * rescale: 텐서의 모든 값을 rescale 값으로 나누어줌 (이 경우에는 255로 나누어서 0~1사이의 값으로 변경)"],"metadata":{"id":"IP4jIyTGfXD_"}},{"cell_type":"code","execution_count":37,"metadata":{"id":"LKPPSwYn7Zrj","executionInfo":{"status":"ok","timestamp":1679448536174,"user_tz":-540,"elapsed":350,"user":{"displayName":"고재훈","userId":"16865552768439394557"}}},"outputs":[],"source":["train_datagen =  ImageDataGenerator(\n","                    rotation_range=10,\n","                    width_shift_range=0.1,\n","                    height_shift_range=0.1,\n","                    shear_range=0.1,\n","                    zoom_range=0.1,\n","                    fill_mode ='wrap'\n","                    )\n","\n","valid_datagen =   ImageDataGenerator(\n","                    rotation_range=10,\n","                    width_shift_range=0.1,\n","                    height_shift_range=0.1,\n","                    shear_range=0.1,\n","                    zoom_range=0.1,\n","                    fill_mode ='wrap'\n","                    )\n"]},{"cell_type":"markdown","source":["#### 2) 경로로 부터 이미지 불러 올 준비\n","* .flow_from_directory 이용\n","    * 디렉토리에서 이미지를 가져와서 데이터 증강을 적용하고 batch 단위로 제공하는 generator를 생성합니다.\n","    * 이미지를 불러올 때 target_size로 크기를 맞추고, \n","    * class_mode로 이진 분류(binary)를 수행하도록 지정합니다.\n"],"metadata":{"id":"dKwSYYkufanb"}},{"cell_type":"code","execution_count":39,"metadata":{"id":"0bwvQ4hHSCwY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679448540417,"user_tz":-540,"elapsed":576,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"134b1e8a-9d46-440b-802a-156fdf0d3179"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 388 images belonging to 3 classes.\n","Found 96 images belonging to 3 classes.\n"]}],"source":["train_generator = train_datagen.flow_from_directory(directory = train_path,\n","                                                   target_size = (280,280),\n","                                                   class_mode = 'categorical',\n","                                                   shuffle = True)\n","\n","\n","valid_generator = valid_datagen.flow_from_directory(directory=valid_path,\n","                                                 target_size = (280, 280),\n","                                                 class_mode = 'categorical',\n","                                                 shuffle = True)\n"]},{"cell_type":"code","source":["history = model.fit(train_generator,\n","                    epochs = 10000, verbose = 1,batch_size = 100,\n","                    callbacks = [es], validation_data = [valid_generator])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ZVI3zCx-5mc6","executionInfo":{"status":"error","timestamp":1679448346923,"user_tz":-540,"elapsed":10131,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"d632202a-0e12-4a9a-81dc-e0182dadb104"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10000\n"]},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-0bc6ea41efe2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(train_generator,\n\u001b[0m\u001b[1;32m      2\u001b[0m                     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     callbacks = [es], validation_data = [valid_generator])\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'binary_crossentropy/logistic_loss/mul' defined at (most recent call last):\n    File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.9/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/ioloop.py\", line 687, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/ioloop.py\", line 740, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 821, in inner\n      self.ctx_run(self.run)\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 782, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n      self.do_execute(\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-36-0bc6ea41efe2>\", line 1, in <module>\n      history = model.fit(train_generator,\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1024, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1082, in compute_loss\n      return self.compiled_loss(\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/losses.py\", line 152, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/losses.py\", line 284, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/losses.py\", line 2176, in binary_crossentropy\n      backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/usr/local/lib/python3.9/dist-packages/keras/backend.py\", line 5680, in binary_crossentropy\n      return tf.nn.sigmoid_cross_entropy_with_logits(\nNode: 'binary_crossentropy/logistic_loss/mul'\nrequired broadcastable shapes\n\t [[{{node binary_crossentropy/logistic_loss/mul}}]] [Op:__inference_train_function_3182]"]}]},{"cell_type":"markdown","metadata":{"id":"g4RPCjU5f662"},"source":["#### 3) 학습\n","- **세부요구사항**\n","    - Conv2D, MaxPooling2D, Flatten, Dense 레이어들을 이용하여 모델을 설계\n","    - 학습시 train_generator 이용. \n","    - validation_data = valid_generator 지정\n","    - Early Stopping 적용\n","    - 평가시, confusion matrix, accuracy, recall, precision, f1 score 등을 이용하시오."]},{"cell_type":"markdown","source":["* 구조 설계"],"metadata":{"id":"wVMLsXw6f663"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"_W7rqgH1f663"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["* 학습\n","    * EarlyStopping 설정하기\n","    * 학습 데이터에 train_generator, validation_data=valid_generator 사용"],"metadata":{"id":"nw2_G7zdf663"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6m5mRE9Nf663"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yCWzBSYqf663"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["#### 4) 성능 평가\n","* 평가는 confusion_matrix, classification_report 활용"],"metadata":{"id":"BdKiY1uIf663"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1qjnvt0lf663"},"outputs":[],"source":[]},{"cell_type":"code","source":["######################\n","#########효국#########\n","######################\n","import tensorflow as tf\n","\n","model_path='/content/drive/MyDrive/Datasets/first_model.h5'\n","# 모델 파일 불러오기\n","model = tf.keras.models.load_model(model_path)\n","\n","from sklearn.metrics import confusion_matrix, classification_report\n","y_pred = model.predict(x_test)\n","y_pred.shape\n","single_y_pred = y_pred.argmax(axis=1)\n","single_y_pred.shape\n","print(y_test.shape)\n","single_test_y = y_test.argmax(axis=1)\n","print(single_test_y.shape)\n","print(confusion_matrix(single_test_y, single_y_pred))\n","print(classification_report(single_test_y, single_y_pred))"],"metadata":{"id":"P-Ltwafe7241","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679380287479,"user_tz":-540,"elapsed":3723,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"901d3b46-7b51-4406-f461-8e05d15fa44f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 0s 32ms/step\n","(121, 2)\n","(121,)\n","[[51  9]\n"," [18 43]]\n","              precision    recall  f1-score   support\n","\n","           0       0.74      0.85      0.79        60\n","           1       0.83      0.70      0.76        61\n","\n","    accuracy                           0.78       121\n","   macro avg       0.78      0.78      0.78       121\n","weighted avg       0.78      0.78      0.78       121\n","\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bBl4Do0af663"},"outputs":[],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","source":["idg = ImageDataGenerator(rotation_range=20,\n","                         width_shift_range=0.1,\n","                         height_shift_range=0.1,\n","                         zoom_range=0.1,\n","                         shear_range=0.1,\n","                         horizontal_flip=True,\n","                         vertical_flip=True)\n","\n","idg.fit(x_train)"],"metadata":{"id":"ygMHStki861P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"x6ixpON9864Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, concatenate, Dropout, Flatten\n","\n","model_path = '/content/drive/MyDrive/Datasets/first_model.h5'\n","model = tf.keras.models.load_model(model_path)\n","\n","inputs = model.input\n","\n","# 인셉션 레이어 추가\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, concatenate\n","\n","# 첫번째 브랜치\n","branch_a = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n","branch_a = MaxPooling2D((2, 2), strides=(2, 2), padding='same')(branch_a)\n","\n","# 두번째 브랜치\n","branch_b = Conv2D(32, (1, 1), activation='relu', padding='same')(inputs)\n","branch_b = Conv2D(32, (3, 3), activation='relu', padding='same')(branch_b)\n","branch_b = MaxPooling2D((2, 2), strides=(2, 2), padding='same')(branch_b)\n","\n","# 세번째 브랜치\n","branch_c = Conv2D(32, (1, 1), activation='relu', padding='same')(inputs)\n","branch_c = Conv2D(32, (5, 5), activation='relu', padding='same')(branch_c)\n","branch_c = MaxPooling2D((2, 2), strides=(2, 2), padding='same')(branch_c)\n","\n","# 네번째 브랜치\n","branch_d = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(inputs)\n","branch_d = Conv2D(32, (1, 1), activation='relu', padding='same')(branch_d)\n","branch_d = MaxPooling2D((2, 2), strides=(2, 2), padding='same')(branch_d)  \n","\n","# 모든 브랜치를 결합\n","x = concatenate([branch_a, branch_b, branch_c, branch_d])\n","\n","# 추가 레이어\n","x = Dropout(0.5)(x)\n","x = Dense(128, activation='relu')(x)\n","outputs = Dense(2, activation='sigmoid')(x)\n","\n","# 인셉션 모델 생성\n","inception_model = Model(inputs=model.input, outputs=outputs)\n","\n","# 기존 모델의 출력을 인셉션 모델의 입력으로 사용\n","outputs = inception_model(inputs=model.input)\n","\n","# 새로운 모델 생성\n","model = Model(inputs=model.input, outputs=outputs)"],"metadata":{"id":"Ydk20jYH869T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["single_test_y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g7VNAHRGK6XY","executionInfo":{"status":"ok","timestamp":1679385446439,"user_tz":-540,"elapsed":1120,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"86f0b1af-b3c2-4295-d74c-5512f8ba6b64"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["print(single_test_y.shape, single_y_pred.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WycqS5R7L7D1","executionInfo":{"status":"ok","timestamp":1679385960769,"user_tz":-540,"elapsed":493,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"23315b44-268c-4be3-f7f5-6acfb77e5c69"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(121,) (121, 140, 2)\n"]}]},{"cell_type":"code","source":["y_pred.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2zNddVSKNE9x","executionInfo":{"status":"ok","timestamp":1679386016602,"user_tz":-540,"elapsed":367,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"3f84fd0f-3ca6-4e05-d80b-c40fd359fcdd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(121, 140, 140, 2)"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, classification_report\n","y_pred = model.predict(x_test)\n","y_pred.shape\n","single_y_pred = y_pred.argmax(axis=1)\n","single_y_pred.shape\n","print(y_test.shape)\n","single_test_y = y_test.argmax(axis=1)\n","print(single_test_y.shape)\n","\n","print(confusion_matrix(single_test_y, single_y_pred))\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, concatenate, Dropout, Flatten\n","\n","model_path = '/content/drive/MyDrive/Datasets/first_model.h5'\n","model = tf.keras.models.load_model(model_path)\n","print(classification_report(single_test_y, single_y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":432},"id":"M7nRGy4p86__","executionInfo":{"status":"error","timestamp":1679386186814,"user_tz":-540,"elapsed":881,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"04f3bc84-5091-49a9-953c-f64898b62113"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 0s 97ms/step\n","(121, 2)\n","(121,)\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-57-d82edc9445a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_test_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_test_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msingle_y_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_test_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msingle_y_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \"\"\"\n\u001b[0;32m--> 317\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     96\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m     97\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and unknown targets"]}]},{"cell_type":"code","source":["from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, concatenate, Dropout, Flatten\n","from tensorflow.keras.applications.inception_v3 import InceptionV3\n","\n","model_path = '/content/drive/MyDrive/Datasets/first_model.h5'\n","model = tf.keras.models.load_model(model_path)\n","\n","input_layer = Input(shape=(280, 280, 3))\n","\n","base_model = InceptionV3(include_top=False, weights='imagenet', input_shape=(280,280,3))\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","x2 = base_model(input_layer)\n","x2 = ... # Inception 모델 구성\n","x2 = Dense(4, activation='relu')(x2) # 새로운 Dense 레이어\n","\n","# 기존 모델과 Inception 모델을 연결하여 최종 출력을 만듦\n","x = ... # 기존 모델의 출력\n","x = Concatenate()([x, x2]) # 기존 모델의 출력과 Inception 모델의 출력 연결\n","x = Dense(4, activation='relu')(x)\n","output_layer = Dense(2, activation='sigmoid')(x)\n","\n","model = Model(inputs=input_layer, outputs=output_layer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":396},"id":"SpkTdTVx87Co","executionInfo":{"status":"error","timestamp":1679386618920,"user_tz":-540,"elapsed":7477,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"ce8a5a28-6db6-4246-ab64-71ac328d1063"},"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-60-dd2b5f9b0e59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m \u001b[0;31m# Inception 모델 구성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 새로운 Dense 레이어\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;31m# which does not have a `shape` attribute.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Inputs to a layer should be tensors. Got: {x}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Inputs to a layer should be tensors. Got: <keras.engine.sequential.Sequential object at 0x7f30081ba9d0>"]}]},{"cell_type":"code","source":[],"metadata":{"id":"jgsTlvRE87Fy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mtGAbky187Ii"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XFfOMdxZ87LZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S1iv22vSxXle"},"source":["### (2) Transfer Learning\n","- **세부요구사항**\n","    * VGG16 모델은 1000개의 클래스를 분류하는 데 사용된 ImageNet 데이터셋을 기반으로 사전 학습된 가중치를 가지고 있습니다. \n","        * 따라서 이 모델은 이미지 분류 문제에 대한 높은 성능을 보입니다.\n","        * 이 모델은 보통 전이학습(transfer learning)에서 기본적으로 사용되며, 특히 대규모 데이터셋이 없을 때는 기본 모델로 사용되어 fine-tuning을 수행합니다.\n","    * VGG16 함수로 부터 base_model 저장\n"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"RnS12YhDxXle","executionInfo":{"status":"ok","timestamp":1679460062121,"user_tz":-540,"elapsed":236,"user":{"displayName":"고재훈","userId":"16865552768439394557"}}},"outputs":[],"source":["from tensorflow.keras.applications import VGG16"]},{"cell_type":"markdown","source":["#### 1) VGG16 불러와서 저장하기\n","* include_top=False로 설정하여 분류기를 제외하고 미리 학습된 가중치 imagenet을 로드합니다.\n","* .trainable을 True로 설정하여 모델의 모든 레이어들이 fine-tuning에 대해 업데이트되도록 합니다.\n"],"metadata":{"id":"d3kyvCwIiAfi"}},{"cell_type":"code","execution_count":31,"metadata":{"id":"kFf3IxbBGe9B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679460065677,"user_tz":-540,"elapsed":1295,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"133a9bb6-099a-4e41-8d1b-749e93bded15"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58889256/58889256 [==============================] - 0s 0us/step\n"]}],"source":["# base_model = VGG16(                 )\n","from tensorflow.keras.applications import VGG16\n","\n","# VGG16 모델 불러오기\n","base_model = VGG16(weights='imagenet', include_top=False, input_shape=(280, 280, 3))\n","\n","# 모든 레이어가 fine-tuning에 대해 업데이트되도록 trainable 설정\n","for layer in model.layers:\n","    layer.trainable = True\n"]},{"cell_type":"markdown","source":["#### 2) VGG16과 연결한 구조 설계\n","* VGG16을 불러와서 Flatten, Dense 등으로 레이어 연결하기"],"metadata":{"id":"D-JjBLZZiIxA"}},{"cell_type":"markdown","source":["### 모델 불러오기\n"],"metadata":{"id":"nvjlPtPQIFoZ"}},{"cell_type":"code","source":["model_path='/content/drive/MyDrive/Datasets/Lenet(0.87).h5'\n","model = tf.keras.models.load_model(model_path)"],"metadata":{"id":"w7gP-0BeIFsU","executionInfo":{"status":"ok","timestamp":1679468184253,"user_tz":-540,"elapsed":1628,"user":{"displayName":"고재훈","userId":"16865552768439394557"}}},"execution_count":104,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"9zS0DfEGIJIj"}},{"cell_type":"code","source":["model_path='/content/drive/MyDrive/Datasets/Lenet(0.87).h5'\n","base_model = tf.keras.models.load_model(model_path)\n","\n","# VGG16 모델 정의 (include_top=False로 설정하여 fully connected layer 제외)\n","vgg16 = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(280, 280, 3))\n","\n","x = vgg16.output\n","x = Flatten()(x)\n","x = Dense(512, activation='relu')(x)\n","predictions = Dense(2, activation='sigmoid')(x)\n","\n","\n","new_model = tf.keras.models.Model(inputs=vgg16.input, outputs=predictions)\n","\n","for layer in vgg16.layers:\n","    layer.trainable = False\n","\n","for layer in vgg16.layers[:-100]:\n","    layer.trainable = False\n","for layer in vgg16.layers[-100:]:\n","    layer.trainable = True\n","\n","new_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","history = new_model.fit(x_train, y_train, epochs = 10000, verbose = 1, callbacks = [es], validation_data =(x_val,y_val))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"monyKivWE-Gr","executionInfo":{"status":"ok","timestamp":1679468493946,"user_tz":-540,"elapsed":168243,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"819354f5-a714-45e5-fd7c-f8c6b50703d4"},"execution_count":106,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10000\n","13/13 [==============================] - 12s 663ms/step - loss: 604.9583 - accuracy: 0.5644 - val_loss: 0.6967 - val_accuracy: 0.4792\n","Epoch 2/10000\n","13/13 [==============================] - 8s 637ms/step - loss: 0.6725 - accuracy: 0.6521 - val_loss: 0.6928 - val_accuracy: 0.5833\n","Epoch 3/10000\n","13/13 [==============================] - 8s 642ms/step - loss: 0.6503 - accuracy: 0.6340 - val_loss: 1.1391 - val_accuracy: 0.5208\n","Epoch 4/10000\n","13/13 [==============================] - 8s 651ms/step - loss: 0.5705 - accuracy: 0.7191 - val_loss: 0.5692 - val_accuracy: 0.7292\n","Epoch 5/10000\n","13/13 [==============================] - 9s 659ms/step - loss: 0.5871 - accuracy: 0.7242 - val_loss: 0.9830 - val_accuracy: 0.5521\n","Epoch 6/10000\n","13/13 [==============================] - 8s 649ms/step - loss: 0.7113 - accuracy: 0.4948 - val_loss: 0.6161 - val_accuracy: 0.6979\n","Epoch 7/10000\n","13/13 [==============================] - 8s 644ms/step - loss: 0.5867 - accuracy: 0.7474 - val_loss: 0.6950 - val_accuracy: 0.6562\n","Epoch 8/10000\n","13/13 [==============================] - 8s 638ms/step - loss: 0.6592 - accuracy: 0.6469 - val_loss: 0.6934 - val_accuracy: 0.5000\n","Epoch 9/10000\n","13/13 [==============================] - 8s 623ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n","Epoch 10/10000\n","13/13 [==============================] - 8s 621ms/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n","Epoch 11/10000\n","13/13 [==============================] - 8s 622ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n","Epoch 12/10000\n","13/13 [==============================] - 8s 622ms/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6934 - val_accuracy: 0.5000\n","Epoch 13/10000\n","13/13 [==============================] - 8s 623ms/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n","Epoch 14/10000\n","13/13 [==============================] - 8s 628ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n","Epoch 15/10000\n","13/13 [==============================] - 8s 627ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n","Epoch 16/10000\n","13/13 [==============================] - 8s 630ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n","Epoch 17/10000\n","13/13 [==============================] - 8s 625ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n","Epoch 18/10000\n","13/13 [==============================] - 8s 626ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n","Epoch 19/10000\n","13/13 [==============================] - 8s 624ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n","Epoch 19: early stopping\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, classification_report\n","y_pred = new_model.predict(x_test)\n","y_pred.shape\n","single_y_pred = y_pred.argmax(axis=1)\n","single_y_pred.shape\n","print(y_test.shape)\n","single_test_y = y_test.argmax(axis=1)\n","print(single_test_y.shape)\n","print(confusion_matrix(single_test_y, single_y_pred))\n","print(classification_report(single_test_y, single_y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3DvISjWHD5JR","executionInfo":{"status":"ok","timestamp":1679464889350,"user_tz":-540,"elapsed":1170,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"30410979-dcfa-4859-b7ca-9e7a16e24931"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 1s 214ms/step\n","(121, 2)\n","(121,)\n","[[60  0]\n"," [11 50]]\n","              precision    recall  f1-score   support\n","\n","           0       0.85      1.00      0.92        60\n","           1       1.00      0.82      0.90        61\n","\n","    accuracy                           0.91       121\n","   macro avg       0.92      0.91      0.91       121\n","weighted avg       0.92      0.91      0.91       121\n","\n"]}]},{"cell_type":"code","source":["single_y_pred"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xeTnAD4lGKYK","executionInfo":{"status":"ok","timestamp":1679461143683,"user_tz":-540,"elapsed":590,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"b774191d-7eb9-419c-adea-372f91649641"},"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n","       0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n","       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n","       0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0])"]},"metadata":{},"execution_count":42}]},{"cell_type":"markdown","source":["## 이건 인셉션"],"metadata":{"id":"mBelNYUcGKa2"}},{"cell_type":"code","source":["from tensorflow.keras.applications.inception_v3 import InceptionV3\n","\n","# load the pre-trained InceptionV3 model without the top layer (include_top=False)\n","inception = InceptionV3(weights='imagenet', include_top=False, input_shape=(280, 280, 3))\n","\n","# freeze the pre-trained layers\n","for layer in inception.layers:\n","    layer.trainable = False\n","\n","# add custom layers on top of the pre-trained model\n","x = inception.output\n","x = tf.keras.layers.GlobalAveragePooling2D()(x)\n","x = tf.keras.layers.Dense(512, activation='relu')(x)\n","predictions = tf.keras.layers.Dense(2, activation='sigmoid')(x)\n","\n","# create the new model\n","new_model = tf.keras.models.Model(inputs=inception.input, outputs=predictions)\n","\n","for layer in inception.layers[:-100]:\n","    layer.trainable = False\n","for layer in inception.layers[-100:]:\n","    layer.trainable = True\n","\n","# compile the new model\n","new_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# train the new model\n","history = new_model.fit(x_train, y_train, epochs=10000, verbose=1, callbacks=[es], validation_data=(x_val,y_val))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nTAqC1plGKdT","executionInfo":{"status":"ok","timestamp":1679468664267,"user_tz":-540,"elapsed":159626,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"2e70cc01-4e62-4a98-d5ed-30efed45e07a"},"execution_count":107,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10000\n","13/13 [==============================] - 17s 295ms/step - loss: 0.3572 - accuracy: 0.8840 - val_loss: 0.6838 - val_accuracy: 0.9583\n","Epoch 2/10000\n","13/13 [==============================] - 2s 174ms/step - loss: 0.0430 - accuracy: 0.9845 - val_loss: 6.8309 - val_accuracy: 0.8125\n","Epoch 3/10000\n","13/13 [==============================] - 2s 174ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 6.5011 - val_accuracy: 0.8333\n","Epoch 4/10000\n","13/13 [==============================] - 2s 179ms/step - loss: 0.0348 - accuracy: 0.9923 - val_loss: 3.5796 - val_accuracy: 0.9167\n","Epoch 5/10000\n","13/13 [==============================] - 2s 175ms/step - loss: 0.0635 - accuracy: 0.9768 - val_loss: 4.7763 - val_accuracy: 0.9271\n","Epoch 6/10000\n","13/13 [==============================] - 2s 173ms/step - loss: 0.0546 - accuracy: 0.9923 - val_loss: 0.2599 - val_accuracy: 0.9583\n","Epoch 7/10000\n","13/13 [==============================] - 3s 200ms/step - loss: 0.0851 - accuracy: 0.9742 - val_loss: 0.6393 - val_accuracy: 0.9375\n","Epoch 8/10000\n","13/13 [==============================] - 3s 200ms/step - loss: 0.0448 - accuracy: 0.9948 - val_loss: 0.8536 - val_accuracy: 0.8021\n","Epoch 9/10000\n","13/13 [==============================] - 2s 178ms/step - loss: 0.0885 - accuracy: 0.9820 - val_loss: 2.0224 - val_accuracy: 0.5833\n","Epoch 10/10000\n","13/13 [==============================] - 2s 178ms/step - loss: 0.0303 - accuracy: 0.9974 - val_loss: 1.9554 - val_accuracy: 0.6771\n","Epoch 11/10000\n","13/13 [==============================] - 3s 201ms/step - loss: 0.0217 - accuracy: 0.9948 - val_loss: 0.3437 - val_accuracy: 0.8333\n","Epoch 12/10000\n","13/13 [==============================] - 3s 201ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9062\n","Epoch 13/10000\n","13/13 [==============================] - 2s 175ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9271\n","Epoch 14/10000\n","13/13 [==============================] - 2s 180ms/step - loss: 6.3745e-04 - accuracy: 1.0000 - val_loss: 0.2119 - val_accuracy: 0.9271\n","Epoch 15/10000\n","13/13 [==============================] - 3s 205ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2315 - val_accuracy: 0.9167\n","Epoch 16/10000\n","13/13 [==============================] - 3s 202ms/step - loss: 8.7810e-04 - accuracy: 1.0000 - val_loss: 0.2477 - val_accuracy: 0.9375\n","Epoch 17/10000\n","13/13 [==============================] - 3s 203ms/step - loss: 4.9477e-04 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.9375\n","Epoch 18/10000\n","13/13 [==============================] - 2s 177ms/step - loss: 7.7313e-04 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9375\n","Epoch 19/10000\n","13/13 [==============================] - 2s 180ms/step - loss: 3.7768e-04 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9375\n","Epoch 20/10000\n","13/13 [==============================] - 3s 207ms/step - loss: 2.3358e-04 - accuracy: 1.0000 - val_loss: 0.2965 - val_accuracy: 0.9271\n","Epoch 21/10000\n","13/13 [==============================] - 2s 175ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3325 - val_accuracy: 0.9271\n","Epoch 22/10000\n","13/13 [==============================] - 2s 174ms/step - loss: 1.1876e-04 - accuracy: 1.0000 - val_loss: 0.3233 - val_accuracy: 0.9271\n","Epoch 23/10000\n","13/13 [==============================] - 3s 200ms/step - loss: 4.4829e-04 - accuracy: 1.0000 - val_loss: 0.3091 - val_accuracy: 0.9271\n","Epoch 24/10000\n","13/13 [==============================] - 3s 200ms/step - loss: 2.3855e-04 - accuracy: 1.0000 - val_loss: 0.2785 - val_accuracy: 0.9271\n","Epoch 25/10000\n","13/13 [==============================] - 2s 183ms/step - loss: 2.0946e-04 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.9271\n","Epoch 26/10000\n","13/13 [==============================] - 2s 175ms/step - loss: 0.0046 - accuracy: 0.9974 - val_loss: 0.2463 - val_accuracy: 0.9375\n","Epoch 27/10000\n","13/13 [==============================] - 2s 174ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0936 - val_accuracy: 0.9688\n","Epoch 28/10000\n","13/13 [==============================] - 3s 201ms/step - loss: 9.1294e-04 - accuracy: 1.0000 - val_loss: 0.2086 - val_accuracy: 0.9688\n","Epoch 29/10000\n","13/13 [==============================] - 2s 173ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9792\n","Epoch 30/10000\n","13/13 [==============================] - 3s 206ms/step - loss: 3.4489e-04 - accuracy: 1.0000 - val_loss: 0.0251 - val_accuracy: 0.9792\n","Epoch 31/10000\n","13/13 [==============================] - 3s 200ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.1774 - val_accuracy: 0.9688\n","Epoch 32/10000\n","13/13 [==============================] - 3s 199ms/step - loss: 0.0950 - accuracy: 0.9639 - val_loss: 6.9458 - val_accuracy: 0.6771\n","Epoch 33/10000\n","13/13 [==============================] - 3s 199ms/step - loss: 0.1243 - accuracy: 0.9716 - val_loss: 37.3909 - val_accuracy: 0.5000\n","Epoch 34/10000\n","13/13 [==============================] - 2s 172ms/step - loss: 0.0542 - accuracy: 0.9845 - val_loss: 36.6180 - val_accuracy: 0.5000\n","Epoch 35/10000\n","13/13 [==============================] - 2s 182ms/step - loss: 0.1260 - accuracy: 0.9691 - val_loss: 2.8540 - val_accuracy: 0.8750\n","Epoch 36/10000\n","13/13 [==============================] - 3s 202ms/step - loss: 0.1180 - accuracy: 0.9845 - val_loss: 1.1573 - val_accuracy: 0.9271\n","Epoch 37/10000\n","13/13 [==============================] - 3s 199ms/step - loss: 0.0787 - accuracy: 0.9897 - val_loss: 0.4388 - val_accuracy: 0.9167\n","Epoch 38/10000\n","13/13 [==============================] - 2s 173ms/step - loss: 0.0489 - accuracy: 0.9923 - val_loss: 0.2641 - val_accuracy: 0.9062\n","Epoch 39/10000\n","13/13 [==============================] - 3s 200ms/step - loss: 0.0249 - accuracy: 0.9948 - val_loss: 0.1929 - val_accuracy: 0.9271\n","Epoch 40/10000\n","13/13 [==============================] - 2s 178ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1704 - val_accuracy: 0.9479\n","Epoch 41/10000\n","13/13 [==============================] - 3s 203ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.1343 - val_accuracy: 0.9583\n","Epoch 42/10000\n","13/13 [==============================] - 3s 200ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1451 - val_accuracy: 0.9583\n","Epoch 43/10000\n","13/13 [==============================] - 2s 174ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1211 - val_accuracy: 0.9583\n","Epoch 44/10000\n","13/13 [==============================] - 3s 200ms/step - loss: 0.0103 - accuracy: 0.9948 - val_loss: 0.1146 - val_accuracy: 0.9792\n","Epoch 45/10000\n","13/13 [==============================] - 2s 178ms/step - loss: 0.0179 - accuracy: 0.9923 - val_loss: 0.1072 - val_accuracy: 0.9792\n","Epoch 45: early stopping\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, classification_report\n","y_pred = new_model.predict(x_test)\n","y_pred.shape\n","single_y_pred = y_pred.argmax(axis=1)\n","single_y_pred.shape\n","print(y_test.shape)\n","single_test_y = y_test.argmax(axis=1)\n","print(single_test_y.shape)\n","print(confusion_matrix(single_test_y, single_y_pred))\n","print(classification_report(single_test_y, single_y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jff6oWt3GKgA","executionInfo":{"status":"ok","timestamp":1679468691660,"user_tz":-540,"elapsed":23122,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"29fd604e-5992-4b8a-aeeb-225e0d504a0c"},"execution_count":108,"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 2s 117ms/step\n","(121, 2)\n","(121,)\n","[[59  1]\n"," [ 6 55]]\n","              precision    recall  f1-score   support\n","\n","           0       0.91      0.98      0.94        60\n","           1       0.98      0.90      0.94        61\n","\n","    accuracy                           0.94       121\n","   macro avg       0.94      0.94      0.94       121\n","weighted avg       0.95      0.94      0.94       121\n","\n"]}]},{"cell_type":"markdown","source":["## EfficientNet "],"metadata":{"id":"75p7H2VeCGht"}},{"cell_type":"code","source":["import tensorflow as tf\n","import tensorflow_hub as hub\n","from tensorflow.keras.layers import Dense, Flatten, Input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","\n","# EfficientNet V2 모델 불러오기\n","efficientnet = \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_s/feature_vector/2\"\n","feature_extractor = hub.KerasLayer(efficientnet, input_shape=(280,280,3))\n","\n","# 입력층 정의하기\n","input_layer = Input(shape=(280, 280, 3))\n","\n","# 새로운 층 추가하기\n","x = feature_extractor(input_layer)\n","x = Flatten()(x)\n","x = Dense(1024, activation='relu')(x)\n","predictions = Dense(2, activation='sigmoid')(x)\n","\n","# 모델 생성하기\n","new_model = Model(inputs=input_layer, outputs=predictions)\n","\n","# EfficientNet V2 모델 동결하기\n","feature_extractor.trainable = False\n","\n","\n","# 모델 컴파일하기\n","new_model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# 모델 학습하기\n","history = new_model.fit(x_train, y_train, epochs = 10000, verbose = 1, callbacks = [es], validation_data =(x_val,y_val))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":245},"id":"xiU3RBILGKiO","executionInfo":{"status":"error","timestamp":1679468846923,"user_tz":-540,"elapsed":10250,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"2ae50e2e-535a-4339-972f-a5adfc736a73"},"execution_count":111,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-111-da03e6cb9e4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'KerasLayer' object has no attribute 'layers'"]}]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, classification_report\n","y_pred = new_model.predict(x_test)\n","y_pred.shape\n","single_y_pred = y_pred.argmax(axis=1)\n","single_y_pred.shape\n","print(y_test.shape)\n","single_test_y = y_test.argmax(axis=1)\n","print(single_test_y.shape)\n","print(confusion_matrix(single_test_y, single_y_pred))\n","print(classification_report(single_test_y, single_y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C_I1-_GZGKkr","executionInfo":{"status":"ok","timestamp":1679468804721,"user_tz":-540,"elapsed":15059,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"503672ee-d47e-4513-8ad2-2de180992737"},"execution_count":110,"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 3s 199ms/step\n","(121, 2)\n","(121,)\n","[[58  2]\n"," [ 6 55]]\n","              precision    recall  f1-score   support\n","\n","           0       0.91      0.97      0.94        60\n","           1       0.96      0.90      0.93        61\n","\n","    accuracy                           0.93       121\n","   macro avg       0.94      0.93      0.93       121\n","weighted avg       0.94      0.93      0.93       121\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"iMGNI0-hGKnR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ResNet\n"],"metadata":{"id":"aidq3Oi0GKpw"}},{"cell_type":"code","source":["from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.layers import Dense, Flatten\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","\n","model_path='/content/drive/MyDrive/Datasets/Lenet(0.87).h5'\n","base_model = tf.keras.models.load_model(model_path)\n","\n","# VGG16 모델 정의 (include_top=False로 설정하여 fully connected layer 제외)\n","base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(280, 280, 3))\n","\n","x = base_model.output\n","x = Flatten()(x)\n","x = Dense(1024, activation='relu')(x)\n","predictions = Dense(2, activation='sigmoid')(x)\n","\n","\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","# 기존 모델 동결하기\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","for layer in base_model.layers[:-100]:\n","    layer.trainable = False\n","for layer in base_model.layers[-100:]:\n","    layer.trainable = True\n","\n","new_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","history = new_model.fit(x_train, y_train, epochs = 10000, verbose = 1, callbacks = [es], validation_data =(x_val,y_val))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G8j9V-ljGKsI","executionInfo":{"status":"ok","timestamp":1679469063893,"user_tz":-540,"elapsed":73689,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"16be1de8-0658-4bcb-af52-6e47f4a821a8"},"execution_count":112,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10000\n","13/13 [==============================] - 16s 363ms/step - loss: 0.3597 - accuracy: 0.8196 - val_loss: 0.2218 - val_accuracy: 0.9167\n","Epoch 2/10000\n","13/13 [==============================] - 3s 236ms/step - loss: 0.1059 - accuracy: 0.9716 - val_loss: 0.2097 - val_accuracy: 0.9271\n","Epoch 3/10000\n","13/13 [==============================] - 3s 226ms/step - loss: 0.0461 - accuracy: 0.9897 - val_loss: 0.2093 - val_accuracy: 0.9271\n","Epoch 4/10000\n","13/13 [==============================] - 3s 232ms/step - loss: 0.0236 - accuracy: 0.9948 - val_loss: 0.1929 - val_accuracy: 0.9167\n","Epoch 5/10000\n","13/13 [==============================] - 3s 233ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.2087 - val_accuracy: 0.9479\n","Epoch 6/10000\n","13/13 [==============================] - 3s 234ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.2510 - val_accuracy: 0.9271\n","Epoch 7/10000\n","13/13 [==============================] - 3s 231ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.2220 - val_accuracy: 0.9375\n","Epoch 8/10000\n","13/13 [==============================] - 3s 230ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2583 - val_accuracy: 0.9375\n","Epoch 9/10000\n","13/13 [==============================] - 3s 232ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2391 - val_accuracy: 0.9479\n","Epoch 10/10000\n","13/13 [==============================] - 3s 235ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2504 - val_accuracy: 0.9479\n","Epoch 11/10000\n","13/13 [==============================] - 3s 233ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 0.9479\n","Epoch 12/10000\n","13/13 [==============================] - 3s 230ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2434 - val_accuracy: 0.9479\n","Epoch 13/10000\n","13/13 [==============================] - 3s 235ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2610 - val_accuracy: 0.9375\n","Epoch 14/10000\n","13/13 [==============================] - 3s 237ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2562 - val_accuracy: 0.9479\n","Epoch 15/10000\n","13/13 [==============================] - 3s 240ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2661 - val_accuracy: 0.9479\n","Epoch 16/10000\n","13/13 [==============================] - 3s 232ms/step - loss: 8.8250e-04 - accuracy: 1.0000 - val_loss: 0.2666 - val_accuracy: 0.9479\n","Epoch 17/10000\n","13/13 [==============================] - 3s 233ms/step - loss: 8.0473e-04 - accuracy: 1.0000 - val_loss: 0.2680 - val_accuracy: 0.9479\n","Epoch 18/10000\n","13/13 [==============================] - 3s 236ms/step - loss: 7.0798e-04 - accuracy: 1.0000 - val_loss: 0.2791 - val_accuracy: 0.9479\n","Epoch 19/10000\n","13/13 [==============================] - 3s 236ms/step - loss: 6.3903e-04 - accuracy: 1.0000 - val_loss: 0.2790 - val_accuracy: 0.9479\n","Epoch 19: early stopping\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, classification_report\n","y_pred = new_model.predict(x_test)\n","y_pred.shape\n","single_y_pred = y_pred.argmax(axis=1)\n","single_y_pred.shape\n","print(y_test.shape)\n","single_test_y = y_test.argmax(axis=1)\n","print(single_test_y.shape)\n","print(confusion_matrix(single_test_y, single_y_pred))\n","print(classification_report(single_test_y, single_y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"opKxmBFjDYfz","executionInfo":{"status":"ok","timestamp":1679469089053,"user_tz":-540,"elapsed":14669,"user":{"displayName":"고재훈","userId":"16865552768439394557"}},"outputId":"a36a8128-08ac-4f3b-9e17-b3540b2e411d"},"execution_count":114,"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 2s 204ms/step\n","(121, 2)\n","(121,)\n","[[58  2]\n"," [ 6 55]]\n","              precision    recall  f1-score   support\n","\n","           0       0.91      0.97      0.94        60\n","           1       0.96      0.90      0.93        61\n","\n","    accuracy                           0.93       121\n","   macro avg       0.94      0.93      0.93       121\n","weighted avg       0.94      0.93      0.93       121\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"5V5heiDxxXlf"},"source":["#### 3) 학습\n","- **세부요구사항**\n","    - 모델 학습 과정에 알맞은 보조 지표를 사용하세요.\n","    - 데이터\n","        * Image Generator를 연결하거나\n","        * 기존 train, validation 셋을 이용해도 됩니다.\n","        - Early Stopping을 반드시 사용하세요.\n","        - 최적의 가중치를 모델에 적용하세요."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CtqQIS-HxXlg"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5zg0L88Gwf4l"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["#### 4) 성능 평가"],"metadata":{"id":"BbhiWcS5i735"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ik4AFzCQi735"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zkkSsyMoi735"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PGuQMUJNxXSy"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}