{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1_04_CNN_exercise_notMNIST_small.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"B_iAjwPm_mYg"},"source":["# Letter recognition (small size)\n","\n","> Indeed, I once even proposed that the toughest challenge facing AI workers is to answer the question: “What are the letters ‘A’ and ‘I’? - [Douglas R. Hofstadter](https://web.stanford.edu/group/SHR/4-2/text/hofstadter.html) (1995)\n","\n","\n","## notMNIST\n","\n","\n","Data source: [notMNIST](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html) (you need to download `notMNIST_small.mat` file):\n","\n","![](http://yaroslavvb.com/upload/notMNIST/nmn.png)\n","\n","> some publicly available fonts and extracted glyphs from them to make a dataset similar to MNIST. There are 10 classes, with letters A-J taken from different fonts.\n","\n","> Approaching 0.5% error rate on notMNIST_small would be very impressive. If you run your algorithm on this dataset, please let me know your results.\n","\n","\n","## So, why not MNIST?\n","\n","Many introductions to image classification with deep learning start with MNIST, a standard dataset of handwritten digits. This is unfortunate. Not only does it not produce a “Wow!” effect or show where deep learning shines, but it also can be solved with shallow machine learning techniques. In this case, plain k-Nearest Neighbors produces more than 97% accuracy (or even 99.5% with some data preprocessing!). Moreover, MNIST is not a typical image dataset – and mastering it is unlikely to teach you transferable skills that would be useful for other classification problems\n","\n","> Many good ideas will not work well on MNIST (e.g. batch norm). Inversely many bad ideas may work on MNIST and no[t] transfer to real [computer vision]. - [François Chollet’s tweet](https://twitter.com/fchollet/status/852594987527045120)"]},{"cell_type":"code","metadata":{"id":"jcAAphar__K6"},"source":["!wget http://yaroslavvb.com/upload/notMNIST/notMNIST_small.mat"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5bJ8z5dnANsf"},"source":["import matplotlib.pyplot as plt\n","from scipy import io\n","import numpy as np\n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rsvxhuP0_mYt"},"source":["## Data Loading"]},{"cell_type":"code","metadata":{"id":"wb9UaA_P_mYu"},"source":["data = io.loadmat(\"notMNIST_small.mat\")\n","\n","# transform data\n","X = data['images']\n","y = data['labels']\n","resolution = 28\n","classes = 10\n","\n","X = np.transpose(X, (2, 0, 1))\n","\n","y = y.astype('int32')\n","X = X.astype('float32') / 255.\n","\n","# shape: (sample, x, y, channel)\n","X = X.reshape((-1, resolution, resolution, 1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IHYFpZ0L_mYw"},"source":["# looking at data; some fonts are strange\n","i = np.random.randint(0, 18723)\n","print(i)\n","plt.imshow( X[i,:,:,0] )\n","plt.title( \"ABCDEFGHIJ\"[y[i]] )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CeeDSEJv_mYz"},"source":["# random letters\n","rows = 6\n","fig, axs = plt.subplots(rows, classes, figsize=(classes, rows))\n","\n","for letter_id in range(10):\n","    letters = X[y == letter_id]\n","    for i in range(rows):\n","        ax = axs[i, letter_id]\n","        ax.imshow(letters[np.random.randint(len(letters)),:,:,0],\n","                  cmap='Greys', interpolation='none')\n","        ax.axis('off')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8xmR99PK_mY2"},"source":["# splitting data into training and test sets\n","x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2022)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CzL95VmTBHxx"},"source":["x_train.shape, y_train.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ghiwVWATe4I8"},"source":["## X : Min-Max Scaling"]},{"cell_type":"code","source":[""],"metadata":{"id":"PbzaORnB2Pnc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SyVgGB6lfCuj"},"source":["## Y : One-Hot Encoding"]},{"cell_type":"code","source":[""],"metadata":{"id":"vt_5va9g2Rdo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GnZHnb1uBJWj"},"source":["## Keras로 자유롭게 CNN 모델링\n","\n","1. [이 구조를 미니 버전으로 활용해봐도 좋다](https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F99DFA5415B38AC752E)\n","2. DropOut, BatchNormalization 등의 기능도 같이 활용해보자."]},{"cell_type":"code","source":[""],"metadata":{"id":"-ljvPeDC2UHu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fsbeDi79gj9-"},"source":["## Early Stopping을 이용한 학습\n","\n","1. validation_split = 0.2\n","2. 1 epoch 돌려가며 빠르게 학습되는 batch_size를 찾을 것\n","3. 5 epoch 전보다 val_loss가 개선되지 않았으면 멈추는 얼리스토핑"]},{"cell_type":"code","source":[""],"metadata":{"id":"PU9dUzJX2V-g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 예측값 생성"],"metadata":{"id":"lG1lgszsn6LT"}},{"cell_type":"code","source":["y_pred = "],"metadata":{"id":"gadVLHGFEF2i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 생성한 예측값을 y_test 구조와 같게 만든다"],"metadata":{"id":"3iMVX5V1n87z"}},{"cell_type":"code","source":["pred_array = np.zeros(shape=(y_pred.shape[0], y_pred.shape[1]))\n","idx = 0\n","\n","for arr_val in y_pred :\n","    # print(arr_val)\n","    pred_array[idx][arr_val.argmax()] = 1\n","    idx += 1"],"metadata":{"id":"sOHETOSmXMGM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred_array.shape"],"metadata":{"id":"hu0bJ8-jX2k2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 성능 평가"],"metadata":{"id":"VemY_QVsnX8y"}},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score"],"metadata":{"id":"ZdJc56bYYvFL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print( f'{accuracy_score(y_test, pred_array):.4f}' )"],"metadata":{"id":"613e1KwGZGjr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 문자 이미지 시각화"],"metadata":{"id":"QCwUg0VkmSo5"}},{"cell_type":"code","source":["import random as rd"],"metadata":{"id":"QnsHlbJPk6X3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["character = {0:'A', 1:'B', 2:'C', 3:'D', 4:'E', 5:'F', 6:'G', 7:'H', 8:'I', 9:'J'}"],"metadata":{"id":"Z6AOUZeYdTbb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 실제 성능 확인을 위해 반복 실행!"],"metadata":{"id":"A5-MY-a1msh1"}},{"cell_type":"code","source":["rand_n = rd.randrange(0, 3744)\n","\n","print(f'id = {rand_n}')\n","print(f'실제 문자 : {character[y_test[rand_n].argmax()]}')\n","print(f'모델의 문자 예측 : {character[y_pred[rand_n].argmax()]}' )\n","print(f'모델의 문자별 예측 확률 : {np.round(y_pred[rand_n]*100)}')\n","# print(f'모델의 문자들 총 확률 : {sum(np.round(y_pred[rand_n]*100))}')\n","\n","print('====================================================')\n","\n","if y_test[rand_n].argmax() == y_pred[rand_n].argmax() :\n","    print('정답')\n","else :\n","    print('오답')\n","\n","print('====================================================')\n","\n","plt.figure(figsize=(5,5))\n","plt.imshow(x_test[rand_n].reshape(28, 28), cmap='gray')\n","plt.title(\"ABCDEFGHIJ\"[y_test[rand_n].argmax()] )\n","plt.show()"],"metadata":{"id":"p0FVtl4tZW2h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 틀린 문자만 확인해봅시다!"],"metadata":{"id":"pN6iIv1WmxgJ"}},{"cell_type":"code","source":["t_f = ( y_test.argmax(axis=1) == y_pred.argmax(axis=1) )\n","false_id = np.where(t_f==False)[0]\n","false_n = len(false_id)\n","\n","id = false_id[rd.randrange(0, false_n)]\n","\n","print(f'id = {id}')\n","print(f'실제 문자 : {character[y_test[id].argmax()]}')\n","print(f'모델의 문자 예측 : {character[y_pred[id].argmax()]}' )\n","print(f'모델의 문자별 예측 확률 : {np.round(y_pred[id]*100)}')\n","# print(f'모델의 문자들 총 확률 : {sum(np.round(y_pred[rand_n]*100))}')\n","\n","print('====================================================')\n","\n","if y_test[id].argmax() == y_pred[id].argmax() :\n","    print('정답')\n","else :\n","    print('오답')\n","\n","print('====================================================')\n","\n","plt.figure(figsize=(5,5))\n","plt.imshow(x_test[id].reshape(28, 28), cmap='gray')\n","plt.title(\"ABCDEFGHIJ\"[y_pred[id].argmax()] )\n","plt.show()"],"metadata":{"id":"h3oXRzQuh4Af"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"ztZKaGvX11h5"},"execution_count":null,"outputs":[]}]}