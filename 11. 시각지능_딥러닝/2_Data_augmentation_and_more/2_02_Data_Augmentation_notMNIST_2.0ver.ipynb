{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"B_iAjwPm_mYg"},"source":["# Letter recognition (small size)\n","\n","> Indeed, I once even proposed that the toughest challenge facing AI workers is to answer the question: “What are the letters ‘A’ and ‘I’? - [Douglas R. Hofstadter](https://web.stanford.edu/group/SHR/4-2/text/hofstadter.html) (1995)\n","\n","\n","## notMNIST\n","\n","\n","Data source: [notMNIST](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html) (you need to download `notMNIST_small.mat` file):\n","\n","![](http://yaroslavvb.com/upload/notMNIST/nmn.png)\n","\n","> some publicly available fonts and extracted glyphs from them to make a dataset similar to MNIST. There are 10 classes, with letters A-J taken from different fonts.\n","\n","> Approaching 0.5% error rate on notMNIST_small would be very impressive. If you run your algorithm on this dataset, please let me know your results.\n","\n","\n","## So, why not MNIST?\n","\n","Many introductions to image classification with deep learning start with MNIST, a standard dataset of handwritten digits. This is unfortunate. Not only does it not produce a “Wow!” effect or show where deep learning shines, but it also can be solved with shallow machine learning techniques. In this case, plain k-Nearest Neighbors produces more than 97% accuracy (or even 99.5% with some data preprocessing!). Moreover, MNIST is not a typical image dataset – and mastering it is unlikely to teach you transferable skills that would be useful for other classification problems\n","\n","> Many good ideas will not work well on MNIST (e.g. batch norm). Inversely many bad ideas may work on MNIST and no[t] transfer to real [computer vision]. - [François Chollet’s tweet](https://twitter.com/fchollet/status/852594987527045120)"]},{"cell_type":"code","metadata":{"id":"jcAAphar__K6"},"source":["!wget http://yaroslavvb.com/upload/notMNIST/notMNIST_small.mat"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5bJ8z5dnANsf"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from scipy import io"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rsvxhuP0_mYt"},"source":["## Data Loading"]},{"cell_type":"code","source":["data = io.loadmat('notMNIST_small.mat')"],"metadata":{"id":"91gEjtm40JEf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data"],"metadata":{"id":"K9_CXfoU0R0-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* transform data"],"metadata":{"id":"vJhGrs481RyO"}},{"cell_type":"code","source":["x = data['images']\n","y = data['labels']"],"metadata":{"id":"jKDfly6r0Zlf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_trans = np.transpose(x, (2, 0, 1))"],"metadata":{"id":"I85RTmYE00NM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print( x.shape )\n","print( x_trans.shape )"],"metadata":{"id":"qJ7ee_pE1GXw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = np.transpose(x, (2, 0, 1))"],"metadata":{"id":"zQBRwhlo2DqN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* x, y 타입 변환"],"metadata":{"id":"ZwbnsiRX1cKA"}},{"cell_type":"code","metadata":{"id":"wb9UaA_P_mYu"},"source":["y = y.astype('int32')\n","x = x.astype('float32') #/ 255."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* reshape\n","\n","    - reshape.(sample, x, y, channel) 순서"],"metadata":{"id":"k5axBnMp1svP"}},{"cell_type":"code","source":["resolution = 28\n","\n","x = x.reshape((-1, resolution, resolution, 1))\n","x.shape"],"metadata":{"id":"wcE0-gXo1sjZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 랜덤하게 문자 시각화"],"metadata":{"id":"tXdMRm6D2Zef"}},{"cell_type":"code","metadata":{"id":"IHYFpZ0L_mYw"},"source":["# looking at data; some fonts are strange\n","rand_n = np.random.randint(0, 18723)\n","\n","plt.figure(figsize=(5,5))\n","plt.title( \"ABCDEFGHIJ\"[y[rand_n]] )\n","plt.imshow( x[rand_n, :, :, 0])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 랜덤하게 여러 문자 시각화"],"metadata":{"id":"bEz30DJU8Bt7"}},{"cell_type":"code","metadata":{"id":"CeeDSEJv_mYz"},"source":["# random letters\n","classes = 10\n","rows = 6\n","\n","fig, axs = plt.subplots(rows, classes, figsize=(classes, rows))\n","\n","for letter_id in range(10):\n","    letters = x[ y==letter_id ]\n","\n","    for i in range(rows):\n","        ax = axs[i, letter_id]\n","        ax.imshow(letters[np.random.randint(len(letters)), :, :, 0],\n","                  cmap='Greys', interpolation='none')\n","        ax.axis('off')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* train set / validation set / test set 분리"],"metadata":{"id":"vZaHfXvD9xE-"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split"],"metadata":{"id":"3_D1fiAh_I7K"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8xmR99PK_mY2"},"source":["# splitting data into training and test sets\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2023)\n","x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=2023)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CzL95VmTBHxx"},"source":["x_train.shape, y_train.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ghiwVWATe4I8"},"source":["## X : Min-Max Scaling"]},{"cell_type":"code","source":[],"metadata":{"id":"r9fpZ5Vysg7h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SyVgGB6lfCuj"},"source":["## Y : One-Hot Encoding"]},{"cell_type":"code","source":[],"metadata":{"id":"JmVH8g-8-fc8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fsbeDi79gj9-"},"source":["## **Data Augmentation**"]},{"cell_type":"code","metadata":{"id":"iVqUpxbWiyn7"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z-ysSY2XC6zD"},"source":["# 데이터 제너레이터를 선언함!  제너레이팅 규칙과 함께!\n","datagen = ImageDataGenerator(\n","        featurewise_center=False,  # set input mean to 0 over the dataset\n","        samplewise_center=False,   # set each sample mean to 0\n","        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","        samplewise_std_normalization=False,   # divide each input by its std\n","        zca_whitening=True,     # apply ZCA whitening\n","        rotation_range=20,      # randomly rotate images in the range (degrees, 0 to 180)\n","        zoom_range = 0.2,       # randomly zoom image \n","        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n","        height_shift_range=0.1, # randomly shift images vertically (fraction of total height)\n","        horizontal_flip=True,   # randomly flip images\n","        vertical_flip=True)     # randomly flip images\n","\n","# 어떤 데이터를 바탕으로 제너레이팅 할 것인지, 미리 알려줌! 필수!\n","datagen.fit(x_train)\n","\n","# 학습 할 때마다, '실시간'으로 데이터를 생성(뻥튀기 autmentation)하여 학습에 활용하고, 버리고를 반복할 준비!\n","train_gen = datagen.flow(x_train, y_train, batch_size=128)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GnZHnb1uBJWj"},"source":["## Keras로 자유롭게 CNN 모델링\n","\n","1. [이 구조를 미니 버전으로 활용해봐도 좋다](https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F99DFA5415B38AC752E)\n","2. DropOut, BatchNormalization 등의 기능도 같이 활용해보자.\n","3. 컨컨컨풀 컨컨컨풀 컨컨컨풀은 어떠한가!"]},{"cell_type":"code","source":[],"metadata":{"id":"63dyNaIesqvw"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6VUiCCwHjMbt"},"source":["model.fit(train_gen, epochs=1, validation_data=(x_val, y_val), verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k5Vd5BtJjgB1"},"source":["## Early Stopping을 이용한 학습\n","\n","위의 코드를 참고하여, 5 epoch 전보다 val_loss가 개선되지 않았으면 멈추는 얼리 스토핑 모델링을 하시오."]},{"cell_type":"code","source":[],"metadata":{"id":"uw44_-Dw-ma0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 예측값 생성"],"metadata":{"id":"lG1lgszsn6LT"}},{"cell_type":"code","source":["y_pred ="],"metadata":{"id":"gadVLHGFEF2i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 생성한 예측값을 y_test 구조와 같게 만든다"],"metadata":{"id":"3iMVX5V1n87z"}},{"cell_type":"code","source":["pred_array = np.zeros(shape=(y_pred.shape[0], y_pred.shape[1]))\n","idx = 0\n","\n","for arr_val in y_pred :\n","    # print(arr_val)\n","    pred_array[idx][arr_val.argmax()] = 1\n","    idx += 1"],"metadata":{"id":"sOHETOSmXMGM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred_array.shape"],"metadata":{"id":"hu0bJ8-jX2k2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 성능 평가"],"metadata":{"id":"VemY_QVsnX8y"}},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score"],"metadata":{"id":"ZdJc56bYYvFL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print( f'{accuracy_score(y_test, pred_array):.4f}' )"],"metadata":{"id":"613e1KwGZGjr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 문자 이미지 시각화"],"metadata":{"id":"QCwUg0VkmSo5"}},{"cell_type":"code","source":["import random as rd"],"metadata":{"id":"QnsHlbJPk6X3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["character = {0:'A', 1:'B', 2:'C', 3:'D', 4:'E', 5:'F', 6:'G', 7:'H', 8:'I', 9:'J'}"],"metadata":{"id":"Z6AOUZeYdTbb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 실제 성능 확인을 위해 반복 실행!"],"metadata":{"id":"A5-MY-a1msh1"}},{"cell_type":"code","source":["rand_n = rd.randrange(0, 3744)\n","\n","print(f'id = {rand_n}')\n","print(f'실제 문자 : {character[y_test[rand_n].argmax()]}')\n","print(f'모델의 문자 예측 : {character[y_pred[rand_n].argmax()]}' )\n","print(f'모델의 문자별 예측 확률 : {np.round(y_pred[rand_n]*100)}')\n","# print(f'모델의 문자들 총 확률 : {sum(np.round(y_pred[rand_n]*100))}')\n","\n","print('====================================================')\n","\n","if y_test[rand_n].argmax() == y_pred[rand_n].argmax() :\n","    print('정답')\n","else :\n","    print('오답')\n","\n","print('====================================================')\n","\n","plt.figure(figsize=(5,5))\n","plt.imshow(x_test[rand_n].reshape(28, 28), cmap='gray')\n","plt.title(\"ABCDEFGHIJ\"[y_test[rand_n].argmax()] )\n","plt.show()"],"metadata":{"id":"p0FVtl4tZW2h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 틀린 문자만 확인해봅시다!"],"metadata":{"id":"pN6iIv1WmxgJ"}},{"cell_type":"code","source":["t_f = ( y_test.argmax(axis=1) == y_pred.argmax(axis=1) )\n","false_id = np.where(t_f==False)[0]\n","false_n = len(false_id)\n","\n","id = false_id[rd.randrange(0, false_n)]\n","\n","print(f'id = {id}')\n","print(f'실제 문자 : {character[y_test[id].argmax()]}')\n","print(f'모델의 문자 예측 : {character[y_pred[id].argmax()]}' )\n","print(f'모델의 문자별 예측 확률 : {np.round(y_pred[id]*100)}')\n","# print(f'모델의 문자들 총 확률 : {sum(np.round(y_pred[rand_n]*100))}')\n","\n","print('====================================================')\n","\n","if y_test[id].argmax() == y_pred[id].argmax() :\n","    print('정답')\n","else :\n","    print('오답')\n","\n","print('====================================================')\n","\n","plt.figure(figsize=(5,5))\n","plt.imshow(x_test[id].reshape(28, 28), cmap='gray')\n","plt.title(\"ABCDEFGHIJ\"[y_pred[id].argmax()] )\n","plt.show()"],"metadata":{"id":"h3oXRzQuh4Af"},"execution_count":null,"outputs":[]}]}